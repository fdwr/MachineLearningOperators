<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>ML Operator Formulas</title>
<style>
body
{
  font-family: Calibri, Segoe UI, sans-serif;
  background-color: #FFFFFF;
}
table tr:nth-child(odd) td{
  background-color: #FFFFFF;
}
table tr:nth-child(even) td{
  background-color: #F8F8FF;
}
td
{
  white-space: pre; /*not pre-wrap;*/
  vertical-align: top;
}
th {
  background: #E8E8FF;
  position: sticky;
  top: 0; /* Don't forget this, required for the stickiness */
}
details {
  display: inline;
  white-space: pre; /*not pre-wrap;*/
}
summary {
  display: inline;
  white-space: pre; /*not pre-wrap;*/
  cursor: zoom-in;
}
summary::after {
  content: " details...";
  color: blue;
}

/* Hide expandable content by default */
.elementwiseOperator { visibility: collapse; }
.activationOperator { visibility: collapse; }
.reorganizationOperator { visibility: collapse; }
.poolingOperator { visibility: collapse; }
.controlFlowOperator { visibility: collapse; }
.reductionOperator { visibility: collapse; }
.normalizationOperator { visibility: collapse; }
.generationOperator { visibility: collapse; }
.randomOperator { visibility: collapse; }
.matrixMultiplicationOperator { visibility: collapse; }
.imagingOperator { visibility: collapse; }
.aggregateOperator { visibility: collapse; }
.uncategorizedOperator { visibility: collapse; }

/* visibility: collapse doesn't appear to work as expected for columns using Chrome. So use display: none instead. */
.detailsColumn { display: none; }
.webnnColumn { display: none; }
.onnxColumn { display: none; }
.dmlColumn { display: none; }
.xnnPackColumn { display: none; }
.stableHloColumn { display: none; }
.tosaColumn { display: none; }
.numpyColumn { display: none; }
.tensorFlowColumn { display: none; }
.tensorFlowLiteColumn { display: none; }
.pytorchColumn { display: none; }
.coreMlColumn { display: none; }
.bnnsColumn { display: none; }
.mpsColumn { display: none; }
.mlxColumn { display: none; }
.ncnnColumn { display: none; }
.cntkColumn { display: none; }
.openVinoColumn { display: none; }
.oneDnnColumn { display: none; }
.annColumn { display: none; }
.futureColumn { display: none; }

/* Show hidden content when the checkbox is checked */
#toggleElementwiseOperators:checked ~ * .elementwiseOperator { visibility: visible; }
#toggleActivationOperators:checked ~ * .activationOperator { visibility: visible; }
#toggleReorganizationOperators:checked ~ * .reorganizationOperator { visibility: visible; }
#togglePoolingOperators:checked ~ * .poolingOperator { visibility: visible; }
#toggleControlFlowOperators:checked ~ * .controlFlowOperator { visibility: visible; }
#toggleReductionOperators:checked ~ * .reductionOperator { visibility: visible; }
#toggleNormalizationOperators:checked ~ * .normalizationOperator { visibility: visible; }
#toggleGenerationOperators:checked ~ * .generationOperator { visibility: visible; }
#toggleRandomOperators:checked ~ * .randomOperator { visibility: visible; }
#toggleMatrixMultiplicationOperators:checked ~ * .matrixMultiplicationOperator { visibility: visible; }
#toggleImagingOperators:checked ~ * .imagingOperator { visibility: visible; }
#toggleAggregateOperators:checked ~ * .aggregateOperator { visibility: visible; }
#toggleUncategorizedOperators:checked ~ * .uncategorizedOperator { visibility: visible; }

#toggleDetailsColumn:checked ~ * .detailsColumn { display: table-cell; }
#toggleWebnnColumn:checked ~ * .webnnColumn { display: table-cell; }
#toggleOnnxColumn:checked ~ * .onnxColumn { display: table-cell; }
#toggleDmlColumn:checked ~ * .dmlColumn { display: table-cell; }
#toggleXnnPackColumn:checked ~ * .xnnPackColumn { display: table-cell; }
#toggleStableHloColumn:checked ~ * .stableHloColumn { display: table-cell; }
#toggleTosaColumn:checked ~ * .tosaColumn { display: table-cell; }
#toggleNumpyColumn:checked ~ * .numpyColumn { display: table-cell; }
#toggleTensorFlowColumn:checked ~ * .tensorFlowColumn { display: table-cell; }
#toggleTensorFlowLiteColumn:checked ~ * .tensorFlowLiteColumn { display: table-cell; }
#togglePytorchColumn:checked ~ * .pytorchColumn { display: table-cell; }
#toggleCoreMlColumn:checked ~ * .coreMlColumn { display: table-cell; }
#toggleBnnsColumn:checked ~ * .bnnsColumn { display: table-cell; }
#toggleMpsColumn:checked ~ * .mpsColumn { display: table-cell; }
#toggleMlxColumn:checked ~ * .mlxColumn { display: table-cell; }
#toggleNcnnColumn:checked ~ * .ncnnColumn { display: table-cell; }
#toggleCntkColumn:checked ~ * .cntkColumn { display: table-cell; }
#toggleOpenVinoColumn:checked ~ * .openVinoColumn { display: table-cell; }
#toggleAnnColumn:checked ~ * .annColumn { display: table-cell; }
#toggleOneDnnColumn:checked ~ * .oneDnnColumn { display: table-cell; }
</style>
</head>
<body>

<h1>Links</h1>
<ul>
<li>This document
<ul>
  <li><a href="https://fdwr.github.io/MachineLearningOperators/OperatorFormulas.html">Original document location</a><br/></li>
  <li><a href="https://github.com/fdwr/MachineLearningOperators/">GitHub repo</a><br/></li>
</ul>
</li>
<li><a href="#DataTypes">Data Types table</a></li>
<li><a href="#Operators">Operator Formulas table</a></li>
</ul>
<br/>

<h1>Notation</h1>
<ul style="list-style: inside; padding-left: 0;">
<li>Any multiplication signs '*' mean elementwise multiplication (per NumPy, PyTorch, TensorFlow).</li>
<li>Any matrix style compound dot product will explicitly use MatMul() rather than '*' to avoid unacceptable notation ambiguity.</li>
<li>Any addition signs '+' mean elementwise addition, never the horrible notation abuse of concatenation.</li>
<li>All exp() and log() use the natural logarithm 2.718281828 (not base 10 or 2).</li>
<li>The pseudocode below uses a few undefined functions, but their trivial behavior should be obvious to implement. e.g. min, max, ones, zeroes, iif, assert</li>
<li>Data type field components are listed in logical bit order (not backwards right-to-left order).</li>
</ul>
<br/>

<noscript>*This checkbox will not work without Javascript enabled:<br/></noscript>
<input type="checkbox" id="toggleAllOperators" checked="checked" onclick="toggleAllOperatorsOfIdSuffix(this, 'Operators')"/><label for="toggleAllOperators">&lt;All operator categories&gt;</label><br/>
<input type="checkbox" id="toggleElementwiseOperators" checked="checked"/><label for="toggleElementwiseOperators">Elementwise operators (pointwise operation, input.dimensions == output.dimensions)</label><br/>
<input type="checkbox" id="toggleActivationOperators" checked="checked"/><label for="toggleActivationOperators">Activation operators (signal <a href="https://en.wikipedia.org/wiki/Activation_function">remapping function</a>)</label><br/>
<input type="checkbox" id="toggleReorganizationOperators" checked="checked"/><label for="toggleReorganizationOperators">Reorganization operators (data movement, no value calculations)</label><br/>
<input type="checkbox" id="toggleReductionOperators" checked="checked"/><label for="toggleReductionOperators">Reduction operators (reduce multiple inputs to output via a formula)</label><br/>
<input type="checkbox" id="togglePoolingOperators" checked="checked"/><label for="togglePoolingOperators">Pooling operators (overlapping reduction)</label><br/>
<input type="checkbox" id="toggleNormalizationOperators" checked="checked"/><label for="toggleNormalizationOperators">Normalization operators (normalize values based on neighbors)</label><br/>
<input type="checkbox" id="toggleControlFlowOperators" checked="checked"/><label for="toggleControlFlowOperators">Control flow operators (graph level branches and loops)</label><br/>
<input type="checkbox" id="toggleGenerationOperators" checked="checked"/><label for="toggleGenerationOperators">Generation operators (generate data)</label><br/>
<input type="checkbox" id="toggleRandomOperators" checked="checked"/><label for="toggleRandomOperators">Random operators (random number values)</label><br/>
<input type="checkbox" id="toggleMatrixMultiplicationOperators" checked="checked"/><label for="toggleMatrixMultiplicationOperators">Matrix multiplication (multiply and sum)</label><br/>
<input type="checkbox" id="toggleImagingOperators" checked="checked"/><label for="toggleImagingOperators">Imaging operators (for image manipulation)</label><br/>
<input type="checkbox" id="toggleAggregateOperators" checked="checked"/><label for="toggleAggregateOperators">Aggregate operators (multiple combined operators in tiny graph)</label><br/>
<input type="checkbox" id="toggleUncategorizedOperators" checked="checked"/><label for="toggleUncategorizedOperators">Uncategorized operators (no clear category to assign)</label><br/>
<br/>

<noscript>*This checkbox will not work without Javascript enabled:<br/></noscript>
<input type="checkbox" id="toggleAllColumns" checked="checked" onclick="toggleAllOperatorsOfIdSuffix(this, 'Column')"/><label for="toggleAllColumns">All library columns</label><br/>
<input type="checkbox" id="toggleDetailsColumn" checked="checked"/><label for="toggleDetailsColumn">Details</label><br/>
<input type="checkbox" id="toggleWebnnColumn" checked="checked"/><label for="toggleWebnnColumn">WebNN (W3C <b>Web</b> <b>N</b>eural <b>N</b>etwork) <a href="https://www.w3.org/TR/webnn/">(info)</a></label><br/>
<input type="checkbox" id="toggleOnnxColumn" checked="checked"/><label for="toggleOnnxColumn">ONNX (<b>O</b>pen <b>N</b>eural <b>N</b>etwork E<b>x</b>change) <a href="https://onnx.ai/">(info)</a> <a href="https://onnx.ai/onnx/operators/index.html">(ops)</a></label><br/>
<input type="checkbox" id="toggleDmlColumn" checked="checked"/><label for="toggleDmlColumn">DirectML (Microsoft <b>Direct</b> <b>M</b>achine <b>L</b>earning) <a href="https://learn.microsoft.com/en-us/windows/ai/directml/dml-intro">(info)</a> <a href="https://learn.microsoft.com/en-us/windows/win32/api/directml/ne-directml-dml_operator_type">(ops)</a></label><br/>
<input type="checkbox" id="toggleXnnPackColumn" checked="checked"/><label for="toggleXnnPackColumn">XNNPACK (Google <b>X</b> <b>N</b>eural <b>N</b>etwork <b>Pack</b>age) <a href="https://github.com/google/XNNPACK">(info)</a></label><br/>
<input type="checkbox" id="toggleStableHloColumn" checked="checked"/><label for="toggleStableHloColumn">StableHLO (OpenXLA <b>Stable</b> <b>H</b>igh <b>L</b>evel <b>O</b>ptimizer) <a href="https://github.com/openxla/stablehlo/blob/main/docs/spec.md">(info)</a></label><br/>
<input type="checkbox" id="toggleTosaColumn" checked="checked"/><label for="toggleTosaColumn">TOSA (ARM <b>T</b>ensor <b>O</b>perator <b>S</b>et <b>A</b>rchitecture) <a href="https://mlir.llvm.org/docs/Dialects/TOSA/">(info)</a></label><br/>
<input type="checkbox" id="toggleNumpyColumn" checked="checked"/><label for="toggleNumpyColumn">NumPy (<b>Num</b>erical <b>Py</b>thon) <a href="https://numpy.org/">(info)</a> <a href="https://numpy.org/doc/stable/reference/routines.html">(ops)</a></label><br/>
<input type="checkbox" id="toggleTensorFlowColumn" checked="checked"/><label for="toggleTensorFlowColumn">TensorFlow (Google's TensorFlow) <a href="https://www.tensorflow.org/">(info)</a></label><br/>
<input type="checkbox" id="toggleTensorFlowLiteColumn" checked="checked"/><label for="toggleTensorFlowLiteColumn">TensorFlow Lite (Google's TensorFlowLite) <a href="https://www.tensorflow.org/">(info)</a></label><br/>
<input type="checkbox" id="togglePytorchColumn" checked="checked"/><label for="togglePytorchColumn">PyTorch (<b>Py</b>thon <b>Torch</b>, originally by Meta) <a href="https://pytorch.org/">(info)</a> <a href="https://pytorch.org/docs/stable/torch.html">(ops)</a> <a href="https://pytorch.org/docs/stable/nn.html">NN ops</a></label><br/>
<input type="checkbox" id="toggleCoreMlColumn" checked="checked"/><label for="toggleCoreMlColumn">CoreML (Apple <b>Core</b> <b>M</b>achine <b>L</b>earning) <a href="https://developer.apple.com/machine-learning/core-ml/">(info)</a> <a href="https://apple.github.io/coremltools/mlmodel/Format/NeuralNetwork.html">(ops)</a></label><br/>
<input type="checkbox" id="toggleBnnsColumn" checked="checked"/><label for="toggleBnnsColumn">BNNS (Apple <b>B</b>asic <b>N</b>eural <b>N</b>etwork <b>S</b>ubroutines) <a href="https://developer.apple.com/documentation/accelerate/bnns">(info)</a></label><br/>
<input type="checkbox" id="toggleMpsColumn" checked="checked"/><label for="toggleMpsColumn">MPS (Apple <b>M</b>etal <b>P</b>erformance <b>S</b>haders) <a href="https://developer.apple.com/documentation/metalperformanceshaders">(info)</a></label><br/>
<input type="checkbox" id="toggleMlxColumn" checked="checked"/><label for="toggleMlxColumn">MLX (Apple <b>M</b>achine <b>L</b>earning E<b>x</b>plore) <a href="https://ml-explore.github.io/mlx/build/html/python/ops.html">(info)</a></label><br/>
<input type="checkbox" id="toggleNcnnColumn" checked="checked"/><label for="toggleNcnnColumn">NCNN (Tencent <b>N</b>eon <b>C</b>onvolutional <b>N</b>eural <b>N</b>etwork) <a href="https://github.com/Tencent/ncnn/">(info)</a> <a href="https://github.com/Tencent/ncnn/blob/54a9a563e9913d3142782dac0e497f2be50075b5/docs/developer-guide/operators.md">(ops)</a></label><br/>
<input type="checkbox" id="toggleCntkColumn" checked="checked"/><label for="toggleCntkColumn">CNTK (Microsoft <b>C</b>og<b>n</b>itive <b>T</b>ool<b>k</b>it) <a href="https://github.com/microsoft/CNTK">(info)</a> <a href="https://microsoft.github.io/CNTK-R/reference/index.html">(ops)</a></label><br/>
<input type="checkbox" id="toggleOpenVinoColumn" checked="checked"/><label for="toggleOpenVinoColumn">OpenVINO (Intel <b>V</b>isual <b>I</b>nference and <b>N</b>eural Network <b>O</b>ptimization) <a href="https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html">(info)</a> <a href="https://docs.openvino.ai/2023.0/api/ie_python_api/_autosummary/openvino.runtime.opset1.html">(ops)</a></label><br/>
<input type="checkbox" id="toggleOneDnnColumn" checked="checked"/><label for="toggleOneDnnColumn">OneDNN (Intel <b>D</b>eep <b>N</b>eural <b>N</b>etwork Library <a href="https://oneapi-src.github.io/oneDNN/group_dnnl_api_primitives.html">(ops)</a></label><br/>
<input type="checkbox" id="toggleAnnColumn" checked="checked"/><label for="toggleAnnColumn">Android NDK (Google <b>N</b>neural Network <b>D</b>evelopment <b>K</b>it) <a href="https://developer.android.com/ndk/guides">(info)</a> <a href="https://developer.android.com/ndk/reference/group/neural-networks">(ops)</a></label><br/>
<br/>

<br/><br/>
<h1 id="DataTypes">Data Types</h1>

<table border="1" cellpadding="1" cellspacing="0" style="border-collapse:collapse; border:none">
  <tbody>
    <tr>
      <th style="width:12em">Categories</th>
      <th>Name</th>
      <th class="detailsColumn" valign="top">Details</th>
      <th class="webnnColumn"><span title="Updated 2024-01-19"><a href="https://www.w3.org/TR/webnn/#enumdef-mloperanddatatype">WebNN</a></span></th>
      <th class="onnxColumn"><span title="Updated 2024-01-19"><a href="https://github.com/onnx/onnx/blob/8a782415a69faf626abc032ff6b2a16187e13c4f/onnx/onnx.proto#L485">ONNX</a></span></th>
      <th class="dmlColumn"><span title="Updated 2024-01-19"><a href="https://learn.microsoft.com/en-us/windows/win32/api/directml/ne-directml-dml_tensor_data_type">DML</a></span></th>
      <th class="xnnPackColumn"><span title="Updated 2024-01-19"><a href="https://github.com/google/XNNPACK/blob/03d2a24b53f18103a2bb0f62e2c7123c5cea8890/include/xnnpack.h#L211-L232">XNNPACK</a></span></th>
      <th class="stableHloColumn"><span title="Updated 2024-01-19"><a href="https://github.com/openxla/stablehlo/blob/main/docs/spec.md#types">StableHLO</a></span></th>
      <th class="tosaColumn"><span title="Updated 2024-01-19"><a href="https://www.mlplatform.org/tosa/tosa_spec.html">TOSA</a></span></th>
      <th class="numpyColumn"><span title="Updated 2024-01-19"><a href="https://numpy.org/devdocs/user/basics.types.html">NumPy</a></span></th>
      <th class="tensorFlowColumn"><span title="Updated 2024-01-19"><a href="https://www.tensorflow.org/api_docs/python/tf/dtypes">TensorFlow</a></span></th>
      <th class="tensorFlowLiteColumn"><span title="Updated 2024-08-01"><a href="https://www.tensorflow.org/api_docs/python/tf/dtypes">TensorFlow Lite</a></span></th>
      <th class="pytorchColumn"><span title="Updated 2024-01-19"><a href="https://pytorch.org/docs/stable/tensor_attributes.html">PyTorch</a></span></th>
      <th class="coreMlColumn"><span title="Updated 2024-01-19"><a href="https://chromium-review.googlesource.com/c/chromium/src/+/5075312/12/services/webnn/coreml/ModelFormat/FeatureTypes.proto">CoreML</a></span></th>
      <th class="bnnsColumn"><span title="Updated 2024-01-19"><a href="https://github.com/alexey-lysiuk/macos-sdk/blob/6c1513f5b0667b76e24aaadcad130e90c545f046/MacOSX14.0.sdk/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/Headers/BNNS/bnns_constants.h#L33-L91">BNNS</a></span></th>
      <th class="mpsColumn"><span title="Updated 2024-01-19"><a href="https://developer.apple.com/documentation/metalperformanceshadersgraph/mpsgraphtensor/3564663-datatype">MPS</a></span></th>
      <th class="mlxColumn"><span title="Updated 2024-01-19"><a href="https://ml-explore.github.io/mlx/build/html/python/data_types.html">MLX</a></span></th>
      <th class="ncnnColumn"><span title="Updated 2024-01-19"><a href="https://github.com/Tencent/ncnn/blob/54a9a563e9913d3142782dac0e497f2be50075b5/docs/developer-guide/operators.md#cast">NCNN</a></span></th>
      <th class="cntkColumn"><span title="Updated 2024-01-19"><a href="https://github.com/microsoft/CNTK/blob/ae9c9c7c5f9e6072cc9c94c254f816dbdc1c5be6/Source/CNTKv2LibraryDll/API/CNTKLibrary.h#L82">CNTK</a></span></th>
      <th class="openVinoColumn"><span title="Updated 2024-01-19"><a href="https://docs.openvino.ai/2023.0/groupov_element_cpp_api.html#doxid-group-ov-element-cpp-api">OpenVINO</a></span></th>
      <th class="oneDnnColumn"><span title="Updated 2024-01-19"><a href="https://oneapi-src.github.io/oneDNN/enum_dnnl_data_type_t.html">OneDNN</a></span></th>
      <th class="annColumn"><span title="Updated 2024-03-26"><a href="https://developer.android.com/ndk/reference/group/neural-networks#operandcode">ANN</a></span></th>
      <th class="futureColumn">(for future additions)</th>
    </tr>
    <tr>
      <td>Integer Unsigned</td>
      <td>uint1</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">x</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">i1 (bool)</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">?</td>
      <td class="openVinoColumn">ov::element::Type_t::u1</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Unsigned</td>
      <td>uint4</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">x</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">ui4</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">?</td>
      <td class="openVinoColumn">ov::element::Type_t::u4</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Unsigned</td>
      <td>uint8</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">uint8</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.UINT8</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_UINT8</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">ui8</td>
      <td class="tosaColumn">tosa.uint8_t</td>
      <td class="numpyColumn">numpy.uint8 / ubyte</td>
      <td class="tensorFlowColumn">tensorflow.uint8</td>
      <td class="tensorFlowLiteColumn">tensorflow.uint8</td>
      <td class="pytorchColumn">torch.uint8</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">BNNSDataTypeUInt8</td>
      <td class="mpsColumn">MPSDataType.uInt8</td>
      <td class="mlxColumn">mx.uint8</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">CNTK.DataType.UChar</td>
      <td class="openVinoColumn">ov::element::Type_t::u8</td>
      <td class="oneDnnColumn">dnnl_data_type_t::dnnl_u8</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Unsigned</td>
      <td>uint16</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.UINT16</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_UINT16</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">ui16</td>
      <td class="tosaColumn">tosa.uint16_t</td>
      <td class="numpyColumn">numpy.uint16 / ushort</td>
      <td class="tensorFlowColumn">tensorflow.uint16</td>
      <td class="tensorFlowLiteColumn">tensorflow.uint16</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">BNNSDataTypeUInt16</td>
      <td class="mpsColumn">MPSDataType.uInt16</td>
      <td class="mlxColumn">mx.uint16</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">ov::element::Type_t::u16</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Unsigned</td>
      <td>uint32</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">uint32</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.UINT32</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_UINT32</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">ui32</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">numpy.uint32 / uintc</td>
      <td class="tensorFlowColumn">tensorflow.uint32</td>
      <td class="tensorFlowLiteColumn">tensorflow.uint32</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">BNNSDataTypeUInt32</td>
      <td class="mpsColumn">MPSDataType.uInt32</td>
      <td class="mlxColumn">mx.uint32</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">ov::element::Type_t::u32</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">ANEURALNETWORKS_UINT32</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Unsigned</td>
      <td>uint48</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">x</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">x</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Signed</td>
      <td>uint64</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">uint64</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.UINT64</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_UINT64</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">ui64</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">numpy.uint64 / uint</td>
      <td class="tensorFlowColumn">tensorflow.uint64</td>
      <td class="tensorFlowLiteColumn">tensorflow.uint64</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">BNNSDataTypeUInt64</td>
      <td class="mpsColumn">MPSDataType.uInt64</td>
      <td class="mlxColumn">mx.uint64</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">ov::element::Type_t::u64</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Signed</td>
      <td>int4</td>
      <td class="detailsColumn">int=3, sign=1, twos complement</td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">x</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">si4</td>
      <td class="tosaColumn">tosa.int4_t</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">ov::element::Type_t::i4</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Signed</td>
      <td>int8</td>
      <td class="detailsColumn">int=7, sign=1, twos complement</td>
      <td class="webnnColumn">int8</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.INT8</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_INT8</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">si8</td>
      <td class="tosaColumn">tosa.int8_t</td>
      <td class="numpyColumn">numpy.int8 / byte</td>
      <td class="tensorFlowColumn">tensorflow.int8</td>
      <td class="tensorFlowLiteColumn">tensorflow.int8</td>
      <td class="pytorchColumn">torch.int8</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">BNNSDataTypeInt8</td>
      <td class="mpsColumn">MPSDataType.int8</td>
      <td class="mlxColumn">mx.int8</td>
      <td class="ncnnColumn">int8</td>
      <td class="cntkColumn">CNTK.DataType.Int8</td>
      <td class="openVinoColumn">ov::element::Type_t::i8</td>
      <td class="oneDnnColumn">dnnl_data_type_t::dnnl_s8</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Signed</td>
      <td>int16</td>
      <td class="detailsColumn">int=15, sign=1, twos complement</td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.INT16</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_INT16</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">si16</td>
      <td class="tosaColumn">tosa.int16_t</td>
      <td class="numpyColumn">numpy.int16 / short</td>
      <td class="tensorFlowColumn">tensorflow.int16</td>
      <td class="tensorFlowLiteColumn">tensorflow.int16</td>
      <td class="pytorchColumn">torch.int16 / short</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">BNNSDataTypeInt16</td>
      <td class="mpsColumn">MPSDataType.int16</td>
      <td class="mlxColumn">mx.int16</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">CNTK.DataType.Int16</td>
      <td class="openVinoColumn">ov::element::Type_t::i16</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Signed</td>
      <td>int32</td>
      <td class="detailsColumn">int=31, sign=1, twos complement</td>
      <td class="webnnColumn">int32</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.INT32</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_INT32</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">si32</td>
      <td class="tosaColumn">tosa.int32_t</td>
      <td class="numpyColumn">numpy.int32 / intc</td>
      <td class="tensorFlowColumn">tensorflow.int32</td>
      <td class="tensorFlowLiteColumn">tensorflow.int32</td>
      <td class="pytorchColumn">torch.int32 / int</td>
      <td class="coreMlColumn">ArrayFeatureType.ArrayDataType.INT32</td>
      <td class="bnnsColumn">BNNSDataTypeInt32</td>
      <td class="mpsColumn">MPSDataType.int32</td>
      <td class="mlxColumn">mx.int32</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">ov::element::Type_t::i32</td>
      <td class="oneDnnColumn">dnnl_data_type_t::dnnl_s32</td>
      <td class="annColumn">ANEURALNETWORKS_INT32</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Signed</td>
      <td>int48</td>
      <td class="detailsColumn">int=47, sign=1, twos complement</td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">x</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">x</td>
      <td class="tosaColumn">tosa.int48_t</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Integer Signed</td>
      <td>int64</td>
      <td class="detailsColumn">int=63, sign=1, twos complement</td>
      <td class="webnnColumn">int64</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.INT64</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_INT64</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">si64</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">numpy.int64 / int_</td>
      <td class="tensorFlowColumn">tensorflow.int64</td>
      <td class="tensorFlowLiteColumn">tensorflow.int64</td>
      <td class="pytorchColumn">torch.int64 / long</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">BNNSDataTypeInt64</td>
      <td class="mpsColumn">MPSDataType.int64</td>
      <td class="mlxColumn">mx.int64</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">ov::element::Type_t::i64</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float8f3e4s1Fn</td>
      <td class="detailsColumn">frac=3 exp=4 sign=1 <a href="https://arxiv.org/abs/2209.05433">(1)</a> <a href="https://arxiv.org/pdf/2206.02915.pdf">(2)</a> <a href="https://onnx.ai/onnx/technical/float8.html">(3)</a>, has nan, no inf</td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.FLOAT8E4M3FN</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">f8E4M3FN</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">dnnl_data_type_t::dnnl_f8_e4m3</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float8f3e4s1FnUz</td>
      <td class="detailsColumn">frac=3 exp=4 sign=1 <a href="https://arxiv.org/abs/2209.05433">(1)</a> <a href="https://arxiv.org/pdf/2206.02915.pdf">(2)</a> <a href="https://onnx.ai/onnx/technical/float8.html">(3)</a>, has nan, no inf, no negative zero</td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.FLOAT8E4M3FNUZ</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">f8E4M3FNUZ</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float8f2e5s1</td>
      <td class="detailsColumn">frac=2 exp=5 sign=1 <a href="https://arxiv.org/abs/2209.05433">(1)</a> <a href="https://arxiv.org/pdf/2206.02915.pdf">(2)</a> <a href="https://onnx.ai/onnx/technical/float8.html">(3)</a>, has nan, has inf, has negative zero</td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.FLOAT8E5M2</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">f8E5M2</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">dnnl_data_type_t::dnnl_f8_e5m2</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float8f2e5s1FnUz</td>
      <td class="detailsColumn">frac=2 exp=5 sign=1 <a href="https://arxiv.org/abs/2209.05433">(1)</a> <a href="https://arxiv.org/pdf/2206.02915.pdf">(2)</a> <a href="https://onnx.ai/onnx/technical/float8.html">(3)</a>, has nan, no inf, no negative zero</td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.FLOAT8E5M2FNUZ</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">f8E5M2FNUZ</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float8f2e5bias4s1FnUz</td>
      <td class="detailsColumn">frac=2 exp=5 sign=1 <a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/65fc9fb4897a89789352e211ca2d398f-Paper.pdf">(1)</a> TODO: Figure out details</td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">x</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">f8E4M3B11FNUZ</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float16f10e5s1 IEEE</td>
      <td class="detailsColumn">frac=10 exp=5 sign=1</td>
      <td class="webnnColumn">float16</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.FLOAT16</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_FLOAT16</td>
      <td class="xnnPackColumn">xnn_datatype_fp16</td>
      <td class="stableHloColumn">f16</td>
      <td class="tosaColumn">tosa.fp16_t</td>
      <td class="numpyColumn">numpy.float16 / half</td>
      <td class="tensorFlowColumn">tensorflow.float16 / half</td>
      <td class="tensorFlowLiteColumn">tensorflow.float16 / half</td>
      <td class="pytorchColumn">torch.float16 / half</td>
      <td class="coreMlColumn">ArrayFeatureType.ArrayDataType.FLOAT16</td>
      <td class="bnnsColumn">BNNSDataTypeFloat16</td>
      <td class="mpsColumn">MPSDataType.float16</td>
      <td class="mlxColumn">mx.float16</td>
      <td class="ncnnColumn">float16</td>
      <td class="cntkColumn">CNTK.DataType.Float16</td>
      <td class="openVinoColumn">ov::element::Type_t::f16</td>
      <td class="oneDnnColumn">dnnl_data_type_t::dnnl_f16</td>
      <td class="annColumn">ANEURALNETWORKS_FLOAT16</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float16f7e8s1 Brain</td>
      <td class="detailsColumn">frac=7 exp=8 sign=1</td>
      <td class="webnnColumn">x</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.BFLOAT16</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">bf16</td>
      <td class="tosaColumn">tosa.bf16_t</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">tensorflow.bfloat16</td>
      <td class="tensorFlowLiteColumn">tensorflow.bfloat16</td>
      <td class="pytorchColumn">torch.bfloat16</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">BNNSDataTypeBFloat16</td>
      <td class="mpsColumn">MPSDataType.bFloat16</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">bfloat16</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">ov::element::Type_t::bf16</td>
      <td class="oneDnnColumn">dnnl_data_type_t::dnnl_bf16</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float32f23e8s1 IEEE</td>
      <td class="detailsColumn">frac=23 exp=8 sign=1</td>
      <td class="webnnColumn">float32</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.FLOAT</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_FLOAT32</td>
      <td class="xnnPackColumn">xnn_datatype_fp32</td>
      <td class="stableHloColumn">f32</td>
      <td class="tosaColumn">tosa.fp32_t</td>
      <td class="numpyColumn">numpy.float32 / single</td>
      <td class="tensorFlowColumn">tensorflow.float32 / float</td>
      <td class="tensorFlowLiteColumn">tensorflow.float32 / float</td>
      <td class="pytorchColumn">torch.float32 / float</td>
      <td class="coreMlColumn">ArrayFeatureType.ArrayDataType.FLOAT32</td>
      <td class="bnnsColumn">BNNSDataTypeFloat32</td>
      <td class="mpsColumn">MPSDataType.float32</td>
      <td class="mlxColumn">mx.float32</td>
      <td class="ncnnColumn">float32</td>
      <td class="cntkColumn">CNTK.DataType.Float</td>
      <td class="openVinoColumn">ov::element::Type_t::f32</td>
      <td class="oneDnnColumn">dnnl_data_type_t::dnnl_f32</td>
      <td class="annColumn">ANEURALNETWORKS_FLOAT32</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float64f52e11s1 IEEE</td>
      <td class="detailsColumn">frac=52 exp=11 sign=1</td>
      <td class="webnnColumn">float64</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.DOUBLE</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_FLOAT64</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">f64</td>
      <td class="tosaColumn">tosa.fp64_t</td>
      <td class="numpyColumn">numpy.float64 / double / float_</td>
      <td class="tensorFlowColumn">tensorflow.float64 / double</td>
      <td class="tensorFlowLiteColumn">tensorflow.float64 / double</td>
      <td class="pytorchColumn">torch.float64 / double</td>
      <td class="coreMlColumn">ArrayFeatureType.ArrayDataType.DOUBLE</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">CNTK.DataType.Double</td>
      <td class="openVinoColumn">ov::element::Type_t::f64</td>
      <td class="oneDnnColumn">dnnl_data_type_t::dnnl_f64</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float16 x 2</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">NA</td>
      <td class="onnxColumn">x</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">x</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">x</td>
      <td class="tensorFlowLiteColumn">x</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">MPSDataType.complexFloat16</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float32 x 2</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">NA</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.COMPLEX64</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">x</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">numpy.complex64 / singlecomplex</td>
      <td class="tensorFlowColumn">tensorflow.complex64</td>
      <td class="tensorFlowLiteColumn">tensorflow.complex64</td>
      <td class="pytorchColumn">torch.complex64 / cfloat</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">MPSDataType.complexFloat32</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Float Signed</td>
      <td>float64 x 2</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">NA</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.COMPLEX128</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">x</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">numpy.complex128 / doublecomplex</td>
      <td class="tensorFlowColumn">tensorflow.complex128</td>
      <td class="tensorFlowLiteColumn">tensorflow.complex128</td>
      <td class="pytorchColumn">torch.complex128 / cdouble</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>Boolean</td>
      <td>bool8</td>
      <td class="detailsColumn">typically just lowest bit is used, but anything != 0 is true</td>
      <td class="webnnColumn">uint8</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.BOOL</td>
      <td class="dmlColumn">DML_TENSOR_DATA_TYPE_UINT8</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">x</td>
      <td class="tosaColumn">tosa.bool_t</td>
      <td class="numpyColumn">numpy.bool</td>
      <td class="tensorFlowColumn">tensorflow.bool</td>
      <td class="tensorFlowLiteColumn">tensorflow.bool</td>
      <td class="pytorchColumn">torch.bool</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">BNNSDataTypeBoolean (bit size?)</td>
      <td class="mpsColumn">MPSDataType.bool (bit size?)</td>
      <td class="mlxColumn">bool_</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">ov::element::Type_t::boolean</td>
      <td class="oneDnnColumn">dnnl_data_type_t::dnnl_boolean</td>
      <td class="annColumn">ANEURALNETWORKS_BOOL8</td>
      <td class="futureColumn">?</td>
    </tr>
    <tr>
      <td>String</td>
      <td>string8</td>
      <td class="detailsColumn">array of char8's (typically UTF-8)</td>
      <td class="webnnColumn">NA</td>
      <td class="onnxColumn">ONNX.TensorProto.DataType.STRING</td>
      <td class="dmlColumn">x</td>
      <td class="xnnPackColumn">x</td>
      <td class="stableHloColumn">x</td>
      <td class="tosaColumn">x</td>
      <td class="numpyColumn">x</td>
      <td class="tensorFlowColumn">tensorflow.string</td>
      <td class="tensorFlowLiteColumn">tensorflow.string</td>
      <td class="pytorchColumn">x</td>
      <td class="coreMlColumn">x</td>
      <td class="bnnsColumn">x</td>
      <td class="mpsColumn">x</td>
      <td class="mlxColumn">x</td>
      <td class="ncnnColumn">x</td>
      <td class="cntkColumn">x</td>
      <td class="openVinoColumn">x</td>
      <td class="oneDnnColumn">x</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    <!--
    <tr>
      <td>categories</td>
      <td>name</td>
      <td class="detailsColumn"></td>
      <td class="webnnColumn">?</td>
      <td class="onnxColumn">?</td>
      <td class="dmlColumn">?</td>
      <td class="xnnPackColumn">?</td>
      <td class="stableHloColumn">?</td>
      <td class="tosaColumn">?</td>
      <td class="numpyColumn">?</td>
      <td class="tensorFlowColumn">?</td>
      <td class="tensorFlowLiteColumn">?</td>
      <td class="pytorchColumn">?</td>
      <td class="coreMlColumn">?</td>
      <td class="bnnsColumn">?</td>
      <td class="mpsColumn">?</td>
      <td class="mlxColumn">?</td>
      <td class="ncnnColumn">?</td>
      <td class="cntkColumn">?</td>
      <td class="openVinoColumn">?</td>
      <td class="oneDnnColumn">?</td>
      <td class="annColumn">?</td>
      <td class="futureColumn">?</td>
    </tr>
    -->
  </tbody>
</table>

<!-- ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -->

<h1 id="Operators">Operators</h1>

<table border=1 cellspacing=0 cellpadding=1 style='border-collapse:collapse; border:none'>
  <tr>
    <th style="width:15em">Categories</th>
    <th>Name</th>
    <th class="detailsColumn" valign="top">Details/Formula</th>
    <th class="webnnColumn"><a href="https://www.w3.org/TR/webnn/">WebNN</a></th>
    <th class="onnxColumn"><a href="https://onnx.ai/onnx/operators/index.html">ONNX</a></th>
    <th class="dmlColumn"><a href="https://learn.microsoft.com/en-us/windows/win32/api/directml/ne-directml-dml_operator_type">DML</a></th>
    <th class="xnnPackColumn">XNNPACK</th>
    <th class="stableHloColumn"><a href="https://github.com/openxla/stablehlo/blob/main/docs/spec.md">StableHLO</a></th>
    <th class="tosaColumn"><a href="https://mlir.llvm.org/docs/Dialects/TOSA/">TOSA</a></th>
    <th class="numpyColumn"><a href="https://numpy.org/doc/stable/reference/routines.html">NumPy</a></th>
    <th class="tensorFlowColumn">TensorFlow</th>
    <th class="tensorFlowLiteColumn">TensorFlowLite</th>
    <th class="pytorchColumn"><a href="https://pytorch.org/docs/stable/torch.html">PyTorch</a></th>
    <th class="coreMlColumn"><a href="https://apple.github.io/coremltools/mlmodel/Format/NeuralNetwork.html">CoreML</a></th>
    <th class="bnnsColumn">BNNS</th>
    <th class="mpsColumn">MPS</th>
    <th class="mlxColumn"><a href="https://ml-explore.github.io/mlx/build/html/python/ops.html">MLX</a></th>
    <th class="ncnnColumn"><a href="https://github.com/Tencent/ncnn/blob/54a9a563e9913d3142782dac0e497f2be50075b5/docs/developer-guide/operators.md">NCNN</a></th>
    <th class="cntkColumn"><a href="https://microsoft.github.io/CNTK-R/reference/index.html">CNTK</a></th>
    <th class="openVinoColumn"><a href="https://docs.openvino.ai/2023.0/api/ie_python_api/_autosummary/openvino.runtime.opset1.html">OpenVINO</a></th>
    <th class="oneDnnColumn"><a href="https://oneapi-src.github.io/oneDNN/group_dnnl_api_primitives.html">OneDNN</a></th>
    <th class="annColumn"><a href="https://developer.android.com/ndk/reference/group/neural-networks">ANN</a></th>
    <th class="futureColumn">(for future additions)</th>
    <th>Precision</th>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise</td>
    <td>Elementwise Generic</td>
    <td class="detailsColumn"><code><details><summary>function elementwiseNullary(functor, dataType, dimensions)</summary>
    output = new Tensor(dataType, dimensions)
    for each coordinate in output.coordinates
        output[coordinate] = functor()
    endfor
    return output
endfunction

</details>
<details><summary>function elementwiseUnary(input, functor)</summary>
    output = new Tensor(input.dataType, input.dimensions)
    for each coordinate in input.coordinates
        output[coordinate] = functor(input[coordinate])
    endfor
    return output
endfunction

</details>
<details><summary>function elementwiseBinary(a, b, functor)</summary>
    outputDimensions = broadcastDimensions(a.dimensions, b.dimensions)
    output = new Tensor(a.dataType, outputDimensions)
    aBroadcast = broadcast(a, outputDimensions) // Some implementations can directly use strides to avoid intermediates.
    bBroadcast = broadcast(b, outputDimensions)
    for each coordinate in input.coordinates
        output[coordinate] = functor(aBroadcast[coordinate], bBroadcast[coordinate])
    endfor
    return output
endfunction

</details>
<details><summary>function elementwiseTrinary(a, b, c, functor)</summary>
    outputDimensions = broadcastDimensions(a.dimensions, b.dimensions, c.dimensions)
    output = new Tensor(a.dataType, outputDimensions)
    aBroadcast = broadcast(a, outputDimensions) // Some implementations can directly use strides to avoid intermediates.
    bBroadcast = broadcast(b, outputDimensions)
    cBroadcast = broadcast(c, outputDimensions)
    for each coordinate in input.coordinates
        output[coordinate] = functor(aBroadcast[coordinate], bBroadcast[coordinate], cBroadcast[coordinate])
    endfor
    return output
endfunction</details></code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">NA</td>
    <td class="dmlColumn">NA</td>
    <td class="xnnPackColumn">NA</td>
    <td class="stableHloColumn">NA</td>
    <td class="tosaColumn">NA</td>
    <td class="numpyColumn">NA</td>
    <td class="tensorFlowColumn">NA</td>
    <td class="tensorFlowLiteColumn">NA</td>
    <td class="pytorchColumn">NA</td>
    <td class="coreMlColumn">NA</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">UnaryOp</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise</td>
    <td>Identity</td>
    <td class="detailsColumn"><code>function identity(input) = elementwiseUnary(input, (x) => x)</code></td>
    <td class="webnnColumn">identity</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Identity">Identity</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY or
DML_ACTIVATION_IDENTITY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">stablehlo.optimization_barrier</td>
    <td class="tosaColumn">tosa.identity</td>
    <td class="numpyColumn">numpy.identity</td>
    <td class="tensorFlowColumn">tf.identity</td>
    <td class="tensorFlowLiteColumn">tf.identity</td>
    <td class="pytorchColumn">torch.nn.Identity</td>
    <td class="coreMlColumn">CopyLayerParams</td>
    <td class="bnnsColumn">BNNSActivationFunctionIdentity</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">mlx.identity</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">activation_identity</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">dnnl::reorder</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="uncategorizedOperator">
    <td>Input</td>
    <td>Constant</td>
    <td class="detailsColumn"><code>function constant() = value</code></td>
    <td class="webnnColumn">constant</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Constant">Constant</a></td>
    <td class="dmlColumn">NA just provide the tensor data</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="uncategorizedOperator">
    <td>Input</td>
    <td>Constant Of Shape</td>
    <td class="detailsColumn"><code>function constantOfShape(scalarValue, newShape) = broadcast(scalarValue, newShape.dimensions)</code></td>
    <td class="webnnColumn">constant+expand</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#ConstantOfShape">ConstantOfShape</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY with zero strides to broadcast</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Add</td>
    <td class="detailsColumn"><code>function add(a, b) = elementwiseBinary(a, b, (x,y) => x + y)</code></td>
    <td class="webnnColumn">add</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Add">Add</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ADD</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Subtract</td>
    <td class="detailsColumn"><code>function subtract(a, b) = elementwiseBinary(a, b, (x,y) => x - y)</code></td>
    <td class="webnnColumn">sub</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sub">Sub</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SUBTRACT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Multiply</td>
    <td class="detailsColumn"><code>function multiply(a, b) = elementwiseBinary(a, b, (x,y) => x * y)</code></td>
    <td class="webnnColumn">mul</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mul">Mul</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MULTIPLY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Divide</td>
    <td class="detailsColumn"><code>function divide(a, b) = elementwiseBinary(a, b, (x,y) => x / y)</code></td>
    <td class="webnnColumn">div</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Div">Div</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_DIVIDE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Reciprocal</td>
    <td class="detailsColumn"><code>function reciprocal(input) = elementwiseUnary(input, (x) => 1 / x)</code></td>
    <td class="webnnColumn">reciprocal</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Reciprocal">Reciprocal</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_RECIP</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Modulus Truncate</td>
    <td class="detailsColumn"><code>function modulusTruncate(a, b) = elementwiseBinary(a, b, (x,y) => x - (y * floor(x / y)))  // Result sign follows divisor sign.</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mod">Mod fmod=0</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MODULUS_TRUNCATE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>2 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Modulus Floor</td>
    <td class="detailsColumn"><code>function modulusFloor(a, b) = elementwiseBinary(a, b, (x,y) => x - (y * trunc(x / y))  // Result sign follows dividend sign.</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mod">Mod fmod=1</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MODULUS_FLOOR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>2 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Power</td>
    <td class="detailsColumn"><code>function pow(x, exponent) = elementwiseBinary(x, exponent, (x, exponent) => powScalar(x, exponent))</code></td>
    <td class="webnnColumn">pow</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pow">Pow</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_POW</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Root</td>
    <td class="detailsColumn"><code>function root(x, exponent) = elementwiseBinary(x, exponent, (x, exponent) => root(x, exponent))
// OR                        pow(x, reciprocal(exponent))</code></td>
    <td class="webnnColumn">reciprocal and pow</td>
    <td class="onnxColumn">ONNX NA</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_RECIP & POW</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Square root</td>
    <td class="detailsColumn"><code>function sqrt(input) = elementwiseUnary(input, (x) => sqrt(x))
// OR                                                 pow(x, 1/2)</code></td>
    <td class="webnnColumn">sqrt</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sqrt">Sqrt</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SQRT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Exponent</td>
    <td class="detailsColumn"><code>function exp(input) = elementwiseBinary(input, (x) => exp(x))
// OR                                                 pow(2.71828, x)</code></td>
    <td class="webnnColumn">exp</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Exp">Exp</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_EXP</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Logarithm Natural</td>
    <td class="detailsColumn"><code>function logarithm(x, base) = elementwiseUnary(x, (x) => log(x, base))
function logarithmNatural(x) = logarithm(x, 2.71828)
function logarithmBase10(x) = logarithm(x, 10)
// OR                         elementwiseUnary(x, (x) => logNatural(x) / logNatural(2))
// Notes: recall log(exp(x)) == x, and log(x, b) == ln(x) / ln(b)</code></td>
    <td class="webnnColumn">log</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Log">Log</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOG</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Absolute</td>
    <td class="detailsColumn"><code>function absolute(input) = elementwiseUnary(input, (x) => abs(x))</code></td>
    <td class="webnnColumn">abs</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Abs">Abs</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ABS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Negate</td>
    <td class="detailsColumn"><code>function negate(input) = elementwiseUnary(input, (x) => -x)</code></td>
    <td class="webnnColumn">neg</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Neg">Neg</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_NEGATE<br/>DML_OPERATOR_ELEMENT_WISE_IDENTITY with scale = -1</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Ceiling</td>
    <td class="detailsColumn"><code>function ceiling(input) = elementwiseUnary(input, (x) => ceil(x))</code></td>
    <td class="webnnColumn">ceil</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Ceil">Ceil</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_CEIL</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Floor</td>
    <td class="detailsColumn"><code>function floor(input) = elementwiseUnary(input, (x) => floor(x))</code></td>
    <td class="webnnColumn">floor</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Floor">Floor</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_FLOOR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Clamp</td>
    <td class="detailsColumn"><code>function clamp(input, minValue, maxValue) = elementwiseUnary(input, (x) => min(max(x, maxValue), minValue))</code></td>
    <td class="webnnColumn">clamp</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Clip">Clip</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_CLIP</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Gauss Error Function</td>
    <td class="detailsColumn"><details><summary><code>function erf(input) = elementwiseUnary(input, (x) => 1/sqrt(pi) * integrate(i = -x to x, e ^ -(i^2)))
// OR                                                2/sqrt(pi) * integrate(i = 0 to x, e ^ -(i^2))</code></summary>
<code>
double f(double x)
{
    // Polynomial approximation constants.
    double a1 =  0.254829592;
    double a2 = -0.284496736;
    double a3 =  1.421413741;
    double a4 = -1.453152027;
    double a5 =  1.061405429;
    double p  =  0.3275911;

    // Save the sign of x.
    int sign = 1;
    if (x &lt; 0) sign = -1;
    x = fabs(x);

    // Approximate the formula A&S 7.1.26:
    // 2/sqrt(pi) * integrate(i = 0 to x, e ^ -(i^2))
    double t = 1.0/(1.0 + p*x);
    double y = 1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1) * t*expₑ(-x*x);
    return sign * y;
}</code></details></td>
    <td class="webnnColumn">erf</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Erf">Erf</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ERF</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Is Not a Number</td>
    <td class="detailsColumn"><code>function isNan(input) = elementwiseUnary(input, (x) => isNan(x))</code>
<code>isNan(float32 x) = (x.reinterpretAs(uint32) & 0x7FFFFFFF) &gt; 0x7F800000</code>

Any float32 value with all 1's for exponent and a nonzero mantissa is <a href="https://en.wikipedia.org/wiki/NaN">NaN</a>. The sign is ignored.
e.g. s1111111 10000000 0000000 00000001 : float32 NaN
e.g. s1111100 00000001 : float16 NaN</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#IsNaN">IsNan</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IS_NAN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Is Infinity</td>
    <td class="detailsColumn"><code>function isInfinity(input) = elementwiseUnary(input, (x) => isinf(x) && iif(x &gt; 0, detectPositive, detectNegative))
isinf(x) = (x.reinterpretAs(uint32) & 0x7FFFFFFF) == 0x7F800000</code>

Check for positive or negative infinity.
For infinity, test that all exponent bits are one, and all mantissa bits are 0:
</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.5.0/docs/Operators.md#IsInf">IsInf</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IS_INFINITY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Sign</td>
    <td class="detailsColumn"><code>function sign(input) = elementwiseUnary(input, (x) => if x &gt; 0 then 1 elif x &lt; 0 then -1 elif x == 0 then 0 else NaN)</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Sign">Sign</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SIGN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Equal</td>
    <td class="detailsColumn"><code>function equal(a, b) = elementwiseBinary(a, b, (x, y) => (x == y)</code></td>
    <td class="webnnColumn">equal</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Equal">Equal</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_EQUALS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Unequal</td>
    <td class="detailsColumn"><code>function unequal(a, b) = elementwiseBinary(a, b, (x, y) => (x != y))</code></td>
    <td class="webnnColumn">not(equal())</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Not">Not</a> and <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Equal">Equal</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_NOT and EQUALS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Greater</td>
    <td class="detailsColumn"><code>function greater(a, b) = elementwiseBinary(a, b, (x, y) => (x &gt; y))</code></td>
    <td class="webnnColumn">greater</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Greater">Greater</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_GREATER_THAN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Lesser</td>
    <td class="detailsColumn"><code>function lesser(a, b) = elementwiseBinary(a, b, (x, y) => (x &lt; y))</code></td>
    <td class="webnnColumn">lesser</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Less">Less</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_LESS_THAN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Greater or Equal</td>
    <td class="detailsColumn"><code>function greaterOrEqual(a, b) = elementwiseBinary(a, b, (x, y) => (x &gt; y))</code></td>
    <td class="webnnColumn">greaterOrEqual</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GreaterOrEqual">GreaterOrEqual</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_GREATER_THAN_OR_EQUAL</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Lesser or Equal</td>
    <td class="detailsColumn"><code>function lesserOrEqual(a, b) = elementwiseBinary(a, b, (x, y) => (x &lt; y))</code></td>
    <td class="webnnColumn">lesserOrEqual</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LessOrEqual">LessOrEqual</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_LESS_THAN_OR_EQUAL</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Bitwise</td>
    <td>Bitwise Not</td>
    <td class="detailsColumn"><code>function bitwiseNot(input) = elementwiseUnary(input, (x) => ~x)</code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseNot">BitwiseNot</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_NOT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Bitwise</td>
    <td>Bitwise And</td>
    <td class="detailsColumn"><code>function bitwiseAnd(a, b) = elementwiseBinary(a, b, (x, y) = > x &amp; y)</code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseAnd">BitwiseAnd</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_AND</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Bitwise</td>
    <td>Bitwise Or</td>
    <td class="detailsColumn"><code>function bitwiseOr(a, b) = elementwiseBinary(a, b, (x, y) = > x | y)</code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseOr">BitwiseOr</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_OR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Bitwise</td>
    <td>Bitwise Xor</td>
    <td class="detailsColumn"><code>function bitwiseXor(a, b) = elementwiseBinary(a, b, (x, y) = > x ^ y)</code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseXor">BitwiseXor</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_XOR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Bitwise</td>
    <td>Bitwise Left Shift</td>
    <td class="detailsColumn"><code>function bitwiseLeftShift(a, b) = elementwiseBinary(a, b, (x, y) = > x &lt;&lt; y)</code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseXor">BitShift</a> direction = LEFT</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_SHIFT_LEFT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Bitwise</td>
    <td>Bitwise Right Shift</td>
    <td class="detailsColumn"><code>function bitwiseRightShift(a, b) = elementwiseBinary(a, b, (x, y) = > x &gt;&gt; y)</code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseXor">BitShift</a> direction = RIGHT</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_SHIFT_Right</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Bitwise</td>
    <td>Bitwise Count</td>
    <td class="detailsColumn"><code>function bitwiseCount(input) = elementwiseBinary(input, (x) => (x & 1) + iif(x > 0, f(x >> 1), 0))</code>
Add one to count for each set bit in x.</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">NA</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_COUNT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Logical</td>
    <td>Logical Not</td>
    <td class="detailsColumn"><code>function logicalNot(input) = elementwiseBinary(input, (x) = > !x)</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Not">Not</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_NOT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">LogicalNotLayerParams</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Logical</td>
    <td>Logical And</td>
    <td class="detailsColumn"><code>function logicalAnd(a, b) = elementwiseBinary(a, b, (x, y) = > x &amp;&amp; y)</code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#And">And</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_AND</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Logical</td>
    <td>Logical Or</td>
    <td class="detailsColumn"><code>function logicalOr(a, b) = elementwiseBinary(a, b, (x, y) = > x || y)</code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Or">Or</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_OR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Logical</td>
    <td>Logical Xor</td>
    <td class="detailsColumn"><code>function logicalXor(a, b) = elementwiseBinary(a, b, (x, y) = > !!x xor !!y)</code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Xor">Xor</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_XOR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Sine</td>
    <td class="detailsColumn"><code>function sine(input) = elementwiseUnary(input, (x) = > sin(x))</code></td>
    <td class="webnnColumn">sin</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sin">Sin</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SIN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Cosine</td>
    <td class="detailsColumn"><code>function cosine(input) = elementwiseUnary(input, (x) = > cos(x))</code></td>
    <td class="webnnColumn">cos</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Cos">Cos</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_COS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Tangent</td>
    <td class="detailsColumn"><code>function tangent(input) = elementwiseUnary(input, (x) = > tan(x))</code></td>
    <td class="webnnColumn">tan</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Tan">Tan</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_TAN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Arcsine</td>
    <td class="detailsColumn"><code>function arcsine(input) = elementwiseUnary(input, (x) = > asin(x))</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Asin">Asin</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ASIN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Arccosine</td>
    <td class="detailsColumn"><code>function arccosine(input) = elementwiseUnary(input, (x) = > acos(x))</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Acos">Acos</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ACOS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Arctangent</td>
    <td class="detailsColumn"><code>function arctangent(input) = elementwiseUnary(input, (x) = > atan(x))</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Atan">Atan</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ATAN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Sine</td>
    <td class="detailsColumn"><code>function hyperbolicSine(input) = elementwiseUnary(input, (x) = > sinh(x))</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Sinh">Sinh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SINH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Cosine</td>
    <td class="detailsColumn"><code>function hyperbolicCosine(input) = elementwiseUnary(input, (x) = > cosh(x))</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Cosh">Cosh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_COSH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Tangent</td>
    <td class="detailsColumn"><code>function hyperbolicTangent(input) = elementwiseUnary(input, (x) = > tanh(x))</code>
<code>function hyperbolicTangent(X) = div(sub(1, exp(mul(X, -2)), add(1, exp(X, -2)))</code>
<code>// OR elementwise (1 - expₑ(-2 * x)) / (1 + expₑ(-2 * x))</code>
<code>// OR elementwise 2 / (1 + expₑ(-2 * x)) - 1</code>
<code>// OR elementwise (expₑ(x) - expₑ(-x)) / (expₑ(x) + expₑ(-x))</code></td>
    <td class="webnnColumn">tanh</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Tanh">Tanh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_TANH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Scaled Hyperbolic Tangent</td>
    <td class="detailsColumn"><code>function scaledHyperbolicTangent(input, alpha, beta) = mul(tanh(mul(input, beta)), alpha)</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#ScaledTanh">ScaledTanh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SCALED_TANH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Arccosine</td>
    <td class="detailsColumn"><code>function hyperbolicArccosine(input) = elementwiseUnary(input, (x) = > arccosh(x))</code>
<code>// OR elementwise logₑ(x + sqrt(x * x - 1))</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Acosh">Acosh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ACOSH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Arcsine</td>
    <td class="detailsColumn"><code>function hyperbolicArcsine(input) = elementwiseUnary(input, (x) = > arcsinh(x))</code>
<code>// OR elementwise logₑ(x + sqrt(x * x + 1))</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Asinh">Asinh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ASINH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Arctangent</td>
    <td class="detailsColumn"><code>function hyperbolicArctangent(input) = elementwiseUnary(input, (x) = > arctanh(x))</code>
<code>// OR elementwise logₑ((1 + x) / (1 - x)) / 2</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Atanh">Atanh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ATANH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>CosineGrad</td>
    <td class="detailsColumn"><code>function cosineGrad(dx, x) = elementwiseBinary(dx, x, (dx, x) = > mul(sin(x), dx))</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">Composed</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SIN &<br/>DML_OPERATOR_ELEMENT_WISE_MULTIPLY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Reduction</td>
    <td>Sum</td>
    <td class="detailsColumn"><code>funtion sum(a, b, ...) = elementwiseNnary((a, b, ...), f(x, y, ...) = x + y + …)</code></td>
    <td class="webnnColumn">add repeated</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sum">Sum</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ADD via repeated inputs</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>&lt; N-1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Reduction</td>
    <td>Mean</td>
    <td class="detailsColumn"><code>funtion mean(a, b, ...) = elementwiseNnary((a, b, ...), f(x, y, ...) = (x + y + …) / n)</code></td>
    <td class="webnnColumn">add repeated and div</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mean">Mean</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MEAN via repeated inputs</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Reduction</td>
    <td>Maximum</td>
    <td class="detailsColumn"><code>funtion maximum(a, b, ...) = elementwiseNnary((a, b, ...), f(x, y, ...) = max(x, y, …))</code></td>
    <td class="webnnColumn">max repeated</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Max">Max</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MAX via repeated inputs</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Threshold</td>
    <td class="detailsColumn"><code>funtion threshold(input, minValue) = elementwiseUnary(input, (x) => max(x, minValue))</code>

notes: Not equivalent to ThresholdedRelu.</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Max">Max</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_THRESHOLD</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Reduction</td>
    <td>Minimum</td>
    <td class="detailsColumn"><code>funtion minimum(a, b, ...) = elementwiseNnary((a, b, ...), f(x, y, ...) = min(x, y, …))</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Min">Min</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MIN via repeated inputs</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Quantization</td>
    <td>Quantize Linear</td>
    <td class="detailsColumn"><code>function quantizeLinear(input:float32, scale:float32, zeroPoint:int32)
    return clamp(add(round(input / scale), zeroPoint), 0, 255).cast(uint8)
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#QuantizeLinear">QuantizeLinear</a><br/>com.microsoft QuantizeLinear</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_QUANTIZE_LINEAR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Quantization</td>
    <td>Dequantize Linear</td>
    <td class="detailsColumn"><code>function dequantizeLinear(input:uint8, scale:float32, zeroPoint:uint8)
    return mul(sub(input, zeroPoint).cast(float32), scale)
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#DequantizeLinear">DequantizeLinear</a><br/>com.microsoft DequantizeLinear</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_DEQUANTIZE_LINEAR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn"><a href="https://www.tensorflow.org/api_docs/python/tf/quantization/dequantize">tf.quantization.dequantize</a></td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn"><a href="https://apple.github.io/coremltools/source/coremltools.converters.mil.mil.ops.defs.html#coremltools.converters.mil.mil.ops.defs.iOS16.constexpr_ops.constexpr_affine_dequantize">constexpr_affine_dequantize</a></td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Sigmoid</td>
    <td class="detailsColumn"><code>function sigmoid(input) = reciprocal(add(1, exp(negate(x)))))
// OR                     elementwiseUnary(input, x => 1 / (1 + expₑ(-x)))
// OR                     elementwiseUnary(input, x => expₑ(x) / (1 + expₑ(x)))</code></td>
    <td class="webnnColumn">sigmoid</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sigmoid">Sigmoid</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SIGMOID</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Hard Sigmoid</td>
    <td class="detailsColumn"><code>function hardSigmoid(input, scale = 0.2, offset = 0.5) = clamp(affine(input, scale, offset), 0, 1)</code>
<code>// OR elementwise max(0, min(x * scale + offset, 1))</code></td>
    <td class="webnnColumn">hardSigmoid</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#HardSigmoid">HardSigmoid</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_HARD_SIGMOID</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Hard Swish</td>
    <td class="detailsColumn"><code>function hardSwish(input, scale = 1/6, offset = 0.5) = mul(input, hardSigmoid(input, scale, offset))</code>
<code>// OR using limit=6 instead, elementwise x * max(0, min(limit, (x + (limit/2)))) / limit</code>

<code>function hardSwishAlways6(input) = hardSwish(input, 1/6, 0.5)</code></td>
    <td class="webnnColumn">hardSigmoid</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#HardSwish">HardSigmoid</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_HARD_SWISH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Clamp Positive (Rectified Linear Unit)</td>
    <td class="detailsColumn"><code>function clampPositive(input) = max(input, 0)</code>
<code>// OR elementwise if x &gt;= 0 then x else 0</code></td>
    <td class="webnnColumn">relu</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Relu">Relu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_RELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Leaky Rectified Linear Unit</td>
    <td class="detailsColumn"><code>function leakyRectifiedLinearUnit(input, alpha) = select(lesser(input, 0), mul(input, alpha), input)</code>
<code>// OR elementwise if x &gt;= 0 then x else alpha * x</code></td>
    <td class="webnnColumn">leakyRelu</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LeakyRelu">LeakyRelu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_LEAKY_RELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>&lt;= Mul precision</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Parameterized Rectified Linear Unit</td>
    <td class="detailsColumn"><code>function parameterizedRectifiedLinearUnit(input, slope) = select(greaterOrEqual(input, 0), input, mul(input, slope))</code>
<code>// OR elementwise if x &gt;= 0 then x else slope * x</code>
PRelu and LeakyRelu are identical, except one slope is an input tensor and one slope is a constant.</td>
    <td class="webnnColumn">prelu</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#PRelu">PRelu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_PARAMETERIZED_RELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Thresholded Rectified Linear Unit</td>
    <td class="detailsColumn"><code>function thresholdedRectifiedLinearUnit(input, alpha = 1) = select(greater(input, alpha), input, 0)</code>
<code>// OR elementwise if x &gt; alpha then x else 0</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ThresholdedRelu">ThresholdedRelu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_THRESHOLDED_RELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Exponential Linear Unit</td>
    <td class="detailsColumn"><code>function exponentialLinearUnit(input, alpha = 1)
    return select(greaterOrEqual(input, 0), input, mul(sub(exp(input), 1), alpha))
    // OR  add(clamp(input, 0, inf), clamp(mul(sub(exp(input), 1), alpha), -inf, 0))
    // OR  elementwiseUnary(input, (x) => if x &gt;= 0 then x else alpha * (expₑ(x) - 1))
endfunction</code></td>
    <td class="webnnColumn">elu</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Elu">Elu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_ELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Scaled Exponential Linear Unit</td>
    <td class="detailsColumn"><code>function scaledExponentialLinearUnit(input, alpha = 1.6732, gamma = 1.0507)
    return mul(elu(input, alpha), gamma)
    // OR  elementwise gamma * iif(x &gt; 0, x, alpha * (expₑ(x) - 1))
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Selu">Selu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SCALED_ELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Gaussian Error Linear Unit (<a href="https://arxiv.org/abs/1606.08415">ref</a>)</td>
    <td class="detailsColumn"><code>function guassianErrorLinearUnit(x) = mul(mul(x, 0.5), add(1.0, erf(div(x, sqrt(2)))))
// OR elementwise x * 0.5 * (1.0 + erf(x / sqrt(2)))</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Gelu">Gelu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_GELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator normalizationOperator">
    <td>Activation, Normalization</td>
    <td>Soft Maximum</td>
    <td class="detailsColumn">Raise all elements to e, and divide all the elements in each batch by that batch's sum.

<code>function softMax(input, axes)
    // Applies:
    // - DML_OPERATOR_ACTIVATION_SOFTMAX1
    expInput = exp(input)
    reducedExpInput = reduceSum(expInput, axis=axes, keepDimensions=1)
    return div(expInput, reducedExpInput)

    // Or for more numerical stability:
    // maxInput = reduceMax(input, axes, keepDimensions=1)
    // expInput = exp(input - maxInput)
    // reducedExpInput = reduceSum(expInput, axis=axes, keepDimensions=1)
    // return div(expInput, reducedExpInput)
endfunction

function softMax1D(input, axis) // Only handle a single axis, explicitly given.
    // Applies:
    // - ONNX Softmax-13
    // - torch.nn.Softmtax
    // - tf.nn.softmax
    // - NCNN Softmax
    // - MPS softMax
    // - mil.ops.defs.iOS15.activation.softmax
    return softMax(input, axes=[axis])
endfunction

function softMax1DRightmostAxis(input) // Only handle a single axis, implicitly rightmost dimension.
    // Applies:
    // - DML_OPERATOR_ACTIVATION_SOFTMAX(0)
    return softMax(input, axes=[1])
endfunction

function softmaxRightmostRange(input, firstAxis) // Only handles rightmost dimensions.
    // ONNX Softmax-11
    flattenedInput = flattenTo2D(input, firstAxis) // Flatten to 2D
    normalizedInput = softMax(flattenedInput, axes=[1])
    return reshape(normalizedInput, input.dimensions)
endfunction</code>

or per batch: <code>f(x) = expₑ(x) / sum(expₑ(X))</code>
or per batch for more numerical stability: <code>expₑ(x - max(X)) / sum(expₑ(x - max(X)))</code></td>
    <td class="webnnColumn">softmax</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softmax">Softmax</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SOFTMAX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Log Soft Maximum</td>
    <td class="detailsColumn"><code>function logSoftMaximum(input, axes)
    return log(softmax(input, axis))
    // OR  logₑ(expₑ(x - max(input)) / sum(expₑ(input - max(input))))
    // OR  (x - max(input)) - logₑ(x - max(input))))
endfunction

function logSoftMaximum1D(input, axis) // Only handle a single axis, explicitly given.
    return logSoftMaximum1D(input, [axis])
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LogSoftmax">LogSoftmax</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_LOG_SOFTMAX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Hard Maximum</td>
    <td class="detailsColumn"><code>function hardMaximum(x) = if x[i] == max(X) then 1 else 0</code>
*but only for first element along that axis</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Hardmax">Hardmax</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_HARDMAX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Soft Sign</td>
    <td class="detailsColumn"><code>function softSign(input) = div(input, add(abs(input), 1))</code></td>
    <td class="webnnColumn">softsign</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softsign">Softsign</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SOFTSIGN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Softplus</td>
    <td class="detailsColumn"><code>function softPlus(X) = log(add(exp(x), 1))</code></td>
    <td class="webnnColumn">softplus</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softplus">Softplus</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SOFTPLUS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Parametric Softplus</td>
    <td class="detailsColumn"><code>function parametricSoftPlus(input, alpha, beta) = mul(softplus(mul(input, beta)), alpha)</code>
<code>// OR elementwise logₑ(expₑ(x * beta) + 1) * alpha</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#ParametricSoftplus">ParametricSoftplus</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_PARAMETRIC_SOFTPLUS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Affine</td>
    <td class="detailsColumn"><code>function affine(input, alpha, beta) = add(mul(input, alpha), beta)</code></td>
    <td class="webnnColumn">linear</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#Affine">Affine</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_LINEAR<br/>DML_OPERATOR_ELEMENT_WISE_IDENTITY<br/>with scale and bias</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator elementwiseOperator">
    <td>Activation, Elementwise</td>
    <td>Symmetric signal shift</td>
    <td class="detailsColumn"><code>function symmetricSignalShift(input, threshold /*lambda*/, bias)
    return add(
        mul(input, greater(abs(input), threshold)),
        mul(sign(input), negate(bias))
    )
    // OR
    return select(
        greater(abs(input), threshold),
        sub(input, mul(sign(input), bias),
        0
    )
    // OR elementwise if x &lt; -threshold then y = x + bias
    //                elif x &gt; threshold then y = x - bias
    //                else y = 0
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#shrink">Shrink</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SHRINK</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="generationOperator randomOperator">
    <td>Generation, Random</td>
    <td>Random Normal</td>
    <td class="detailsColumn"><code>function randomNormal(scale, mean) = <a href="https://en.wikipedia.org/wiki/Marsaglia_polar_method">MarsagliaPolarTransform</a>(random(), random()) * scale + mean</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomNormal">RandomNormal</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Unpredictable</td>
  </tr>
 <tr class="generationOperator randomOperator">
    <td>Generation, Random</td>
    <td>Random Normal Like</td>
    <td class="detailsColumn"><code>function randomNormalLike(scale, mean) = <a href="https://en.wikipedia.org/wiki/Marsaglia_polar_method">MarsagliaPolarTransform</a>(random(), random()) * scale + mean</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomNormalLike">RandomNormalLike</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Unpredictable</td>
  </tr>
 <tr class="generationOperator randomOperator">
    <td>Generation, Random</td>
    <td>Random Uniform</td>
    <td class="detailsColumn"><code>function randomUniform(low, high, dataType, dimensions)  // see MT19937
    function f()
        range = high - low  // note inclusive end
        if dataType is integer then return (rand() % (range+1) + low
        if dataType is float then (rand() / randmax) * range + low
    endif
    return elementwiseNullary(f, dataType, dimensions)
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomUniform">RandomUniform</a><br/><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomUniformLike">RandomUniformLike</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Unpredictable</td>
  </tr>
  <tr class="generationOperator randomOperator">
    <td>Generation, Random</td>
    <td>Random Multinomial</td>
    <td class="detailsColumn">TODO: function randomMultinomial() = ...</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Multinomial">Multinomial</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Unpredictable</td>
  </tr>
 <tr class="generationOperator matrixMultiplicationOperator">
    <td>Generation, Matrix Multiplication</td>
    <td>Diagonal Matrix</td>
    <td class="detailsColumn">Notes: set 1's all along diagonal. In other words, all output[i, i+k] = 1, and every other element = 0.<code>

function eyeLike(input, outputDimensions, outputDataType, diagonalShift=0)
    assert(outputDimensions == input.dimensions)
    assert(outputDataType == input.dataType)
    output = new Tensor(outputDataType, outputDimensions)
    if not input exists
        input = zeros(outputDataType, outputDimensions)
    endif
    for each coordinate in output tensor coordinates
        output[coordinate] = if coordinate.h + diagonalShift == coordinate.w then 1 else 0
    endfor
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#EyeLike">EyeLike</a></td>
    <td class="dmlColumn">DML_OPERATOR_DIAGONAL_MATRIX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="generationOperator matrixMultiplicationOperator">
    <td>Generation, Matrix Multiplication</td>
    <td>Diagonal Matrix</td>
    <td class="detailsColumn"><code>TODO:</code></td>
    <td class="webnnColumn">triangular</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.9.0/docs/Operators.md#Trilu">Trilu</a></td>
    <td class="dmlColumn">DML_OPERATOR_DIAGONAL_MATRIX1</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="matrixMultiplicationOperator">
    <td>Matrix Multiplication</td>
    <td>Generic Matrix Multiplication</td>
    <td class="detailsColumn"><code>function matrixMultiplication(A, B, C, alpha, beta, transA, transB; Y)
    A2 = if(transA, transpose(A), A)
    B2 = if(transB, transpose(B), B)
    Y = add(mul(alpha, matMul(A2, B2)), mul(beta, C))
endfunction</code></td>
    <td class="webnnColumn">gemm</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Gemm">Gemm</a></td>
    <td class="dmlColumn">DML_OPERATOR_MATRIX_GEMM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
 <tr class="matrixMultiplicationOperator">
    <td>Matrix Multiplication</td>
    <td>Matrix Multiplication</td>
    <td class="detailsColumn"><code>for i=0..&lt;h do for j=0..&lt;w do y[i,j] = dot(A[i,0..w], B[0..h,j])</code>

TODO: Demonstrate via reduceSum of higher dimensional space.
It's essentially a ReduceSum(Mul(A.row, B.column)) per output element.
notes: A and B can be 1D vectors, which are treated as [1,W] and [H,1] matrices.
A and B can have batch count dimensions, where each 2D matrix is multiplied separately.
The batch count can be broadcast too.</td>
    <td class="webnnColumn">matmul</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MatMul">MatMul</a></td>
    <td class="dmlColumn">DML_OPERATOR_MATRIX_GEMM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
 <tr class="matrixMultiplicationOperator">
    <td>Matrix Multiplication</td>
    <td>Convolve</td>
    <td class="detailsColumn">Every output element is the convolution of the filter with the corresponding input elements.

  <code>out[j] = (x[i]*w[0]) + (x[i+1]*w[1]) + (x[i+2]*w[2]) + ... + (x[i+k-1]*w[k-1]) + b</code>

notes: 'steps' affects the size of steps over the input.
'dilations' affects the step of the filter, as if the filter had been resized with interceding zeroes between elements.
A dilation of 1 means no change (1:1 with filter), whereas dilation of 2 inserts lines of zeros between every filter line.
'pads' are not actually added to the input, just virtually treated as if zeros. <a href="https://github.com/vdumoulin/conv_arithmetic">vdumoulin convolution diagrams</a>
<code>
function convolve(input, filterWeights, windowDimensions, padding, dilations, strides)
    startPads = pads[0..pads.size/2]
    endPads = pads[pads.size/2..pads.size]
    // TODO: compute output size
    // output.dimensions = (input.dimensions + startPads + endPads) // todo: consider strides and kernel size
    for each outputCoordinate in output coordinates
        output[outputCoordinate] = convolveKernel(input, filterWeights, outputCoordinate * strides - startPads, dilations)
    endfor
endfunction

function convolveKernel(input, filterWeights, firstInputCoordinate, dilations)
    // 2D example only
    // TODO:Figure out what 'group' does and what 'M' is?
    result = 0
    // todo: How do 'M' and 'C' factor into this?
    for y=0..&lt;filterWeights.dimensions[2]
        for x=0..&lt;filterWeights.dimensions[3]
            inputCoordinate = firstInputCoordinate + ([y,x] * dilations)
            if (input.contains(inputCoordinate)) // check coordinates within tensor
                result += filterWeights[y,x] * input[inputCoordinate]
            endif
        endfor // x
    endfor // y
    return result
endfunction
</code></td>
    <td class="webnnColumn">conv</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv">Conv</a></td>
    <td class="dmlColumn">DML_OPERATOR_CONVOLUTION
    with DML_CONVOLUTION_MODE_CROSS_CORRELATION
    and DML_CONVOLUTION_DIRECTION_FORWARD</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
 <tr class="matrixMultiplicationOperator">
    <td>Matrix Multiplication</td>
    <td>Convolve Tranposed</td>
    <td class="detailsColumn">TODO: Here be dragons.
      questions: What is the difference between CONVOLUTION vs CORRELATION enum, and FORWARD vs BACKWARD?</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose">ConvTranspose</a></td>
    <td class="dmlColumn">DML_OPERATOR_CONVOLUTION
    with DML_CONVOLUTION_MODE_CROSS_CORRELATION
    and DML_CONVOLUTION_DIRECTION_BACKWARD</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
 <tr class="elementwiseOperator">
    <td>Data Conversion, Elementwise</td>
    <td>Cast</td>
    <td class="detailsColumn"><code>function cast(input) = elementwiseUnary(input, (x) => cast(x))</code></td>
    <td class="webnnColumn">cast</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Cast">Cast</a></td>
    <td class="dmlColumn">DML_OPERATOR_CAST</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>&lt; 1 ULP</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Transpose</td>
    <td class="detailsColumn">Reorder axes, such as X Y -&gt; Y X, or X Y Z -&gt; Z X Y.
<code>
function transpose(input, permutationAxes /*gather semantics*/)
    assert(permutationAxes.size == input.rank)
    rank = input.rank
    for i=0..&lt;rank do output.dimensions[i] = input.dimensions[permutationAxes[i]]
    outputCoordinate = repeat(rank, 0)
    for each inputCoordinate in input coordinates
        for i=0..&lt;rank do outputCoordinate[i] = inputCoordinate[permutationAxes[i]]
        output[outputCoordinate] = input[inputCoordinate]
    endfor
endfunction</code></td>
    <td class="webnnColumn">transpose</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Transpose">Transpose</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY with
    TENSOR_DESC that flips via permuted strides</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Broadcast</td>
    <td class="detailsColumn">Broadcast any single size dimensions up to the output dimension counts.
Similar to <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.broadcast_to.html">NumPy broadcast_to</a>.
<code>
function broadcast(input, targetDimensions)
    output.dimensions = broadcastDimensions(input.dimensions, targetDimensions)
    inputShape = padLeadingValues(input.dimensions, output.rank, 1)
    for each outputCoordinate in output coordinates
        for i=0..&lt;output.rank do inputCoordinate[i] = iif(inputShape[i] &gt; 1), outputCoordinate[i], 0)
        output[outputCoordinate] = inputData[inputCoordinate]
    endfor
endfunction</code></td>
    <td class="webnnColumn">expand</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#Expand">Expand</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY with
    TENSOR_DESC using zero strides along broadcast dimension</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Broadcast Dimensions</td>
    <td class="detailsColumn">Helper to compute the broadcasted output dimensions (1D tensor) from a list of multiple input dimensions.
Any single size dimensions are stretched to the output dimension size.
<code>
function broadcastDimensions(dimensionsList...)
    outputRank = 0
    for each dimensions in dimensionsList do outputRank = max(outputRank, dimensions.size) // Determine the largest rank
    broadcastedDimensions = ones([outputRank]) // [1,1,...]
    for each dimension in dimensions // Take the max of all dimensions.
        paddedDimensions = padLeadingValues(dimensions, outputRank, 1)
        for i=0..&lt;outputRank do
            assert(paddedDimensions[i] == broadcastedDimensions[i] || paddedDimensions[i] == 1 || broadcastedDimensions[i] == 1))
            broadcastedDimensions[i] = max(broadcastedDimensions[i], paddedDimensions[i])
        endfor
    endfor
    return broadcastedDimensions
endfunction

// Resize right-aligned by padding with leading values.
// e.g. paddingSize=4 with [H,W] -&gt; [1,1,H,W]
function padLeadingValues(values, paddedSize, padValue)
    // Right align. e.g. original dimensions=[H,W], paddedSize=4, padValue=1 -&gt; [1,1,H,W]
    paddingCount = max(paddedSize, values.size) - values.size
    paddedValues = values
    paddedValues.prepend(paddingCount, padValue)
    return paddedValues
endfunction</code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">NA</td>
    <td class="dmlColumn">NA</td>
    <td class="xnnPackColumn">NA</td>
    <td class="stableHloColumn">NA</td>
    <td class="tosaColumn">NA</td>
    <td class="numpyColumn">NA</td>
    <td class="tensorFlowColumn">NA</td>
    <td class="tensorFlowLiteColumn">NA</td>
    <td class="pytorchColumn">NA</td>
    <td class="coreMlColumn">NA</td>
    <td class="bnnsColumn">NA</td>
    <td class="mpsColumn">NA</td>
    <td class="mlxColumn">NA</td>
    <td class="ncnnColumn">NA</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Reshape</td>
    <td class="detailsColumn">Return tensor with a different view of the data, like a reinterpret cast using new dimensions that are element-count compatible.

  <code>function reshape(input, newDimensions)
    output = input
    output.dimensions = newDimensions
    return output
endfunction</code></td>
    <td class="webnnColumn">reshape</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Reshape">Reshape</a></td>
    <td class="dmlColumn">NA, no actual data change, just update the TENSOR_DESC</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Reshape To 2D</td>
    <td class="detailsColumn">Reinterpret the view of the tensor, reducing the dimensions from N to 2.
e.g. [1,2,3,4,5] with a split at axis 3 yields [1*2*3,4*5] -&gt; [6,20])

<code>
function flattenTo2D(input, axis)
    output = input
    oldDimensions = input.dimensions
    output.dimensions = join(reduceProduct(oldDimensions[0..axis]), reduceProduct(oldDimensions[axis..oldDimensions.size]))
    return output
endfunction

<b>ONNX</b>:
function flattenTo2D(input, axis)
    inputShape = Shape(input)
    shapeFrontHalf = Slice(inputShape; ends=axis)
    shapeBackHalf = Slice(inputShape; starts=axis)
    newShape = Concat(axis=0, ReduceProd(shapeFrontHalf), ReduceProd(shapeBackHalf))
    output = Reshape(input, newShape)
endfunction</code></td>
    <td class="webnnColumn">reshape (plus caller logic)</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Flatten">Flatten</a></td>
    <td class="dmlColumn">NA, no actual data change, just update the TENSOR_DESC</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Reshape Removing Ones</td>
    <td class="detailsColumn">Reinterpret the view of the tensor, removing 1's for deletable axes.

<code>function reshapeDeletingOnes(input, axes)
    output = input
    output.dimensions = deleteOnesInDimensions(input.dimensions, axes)
    return output
endfunction

function deleteOnesInDimensions(dimensions, axes)
    if axes is undefined
        axes = increasingSequence(0, dimensions.size) // Remove all 1's.
    else
        assert(allOf(dimensions, (d) => (d == 1)))
        axes = removeDuplicates(sortDescending(axes))
    endif

    newDimensions = dimensions
    for i in axes // work from back to front
        if newDimensions[i] == 1
            newDimensions.deleteAt(i)
        endif
    endfor
    return newDimensions
endfunction</code></td>
    <td class="webnnColumn">reshape (plus caller logic)</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Squeeze">Squeeze</a></td>
    <td class="dmlColumn">NA, just rearrange the TENSOR_DESC</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Reshape Inserting Ones</td>
    <td class="detailsColumn">Reinterpret the view of the tensor, filling in 1's for newly inserted axes.

<code>function reshapeInsertingOnes(input, axes)
    output = input
    output.dimensions = insertOnesInDimensions(input.dimensions, axes)
    return output
endfunction

function insertOnesInDimensions(dimensions, axes)
    // Note the axes are relative to their *final* index.
    // So dimensions = [3,4] with axes = [0,2] yields new dimensions = [1,3,1,4].
    newDimensions = dimensions
    axes = removeDuplicates(sort(axes))
    for i in axes
        newDimensions.insertAt(i, 1)
    endfor
    return newDimensions
endfunction

</code></td>
    <td class="webnnColumn">reshape (plus caller logic)</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Unsqueeze">Unsqueeze</a></td>
    <td class="dmlColumn">NA, just rearrange the TENSOR_DESC</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Reshape From Axes</td>
    <td class="detailsColumn">Reinterpret the view of the tensor, gathering dimensions from axes,
filling in 1's for filler dimensions.

<code>function reshapeFromAxes(input, newRank, axes)
    assert(input.rank == axes.size)
    assert(containsUniqueValues(axes))
    output = input
    output.dimensions = gatherValues(input.dimensions, axes, newRank, 1)
    return output
endfunction

function gatherValues(values, indices, newValuesSize, fillerValue)
    newValues = repeat(newValuesSize, fillerValue)
    for (i, gatherIndex) in indices
        newValues[i] = values[gatherIndex]
    endfor
endfunction</code></td>
    <td class="webnnColumn">reshape (plus caller logic)</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Reshape">Reshape</a> plus caller logic</td>
    <td class="dmlColumn">NA, just rearrange the TENSOR_DESC</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Reshape To Axes</td>
    <td class="detailsColumn">Reinterpret the view of the tensor, scattering dimensions to axes,
filling in 1's for filler dimensions.

<code>function reshapeToAxes(input, newRank, axes)
    assert(input.rank == axes.size)
    assert(containsUniqueValues(axes))
    output = input
    output.dimensions = scatterValues(input.dimensions, axes, newRank, 1)
    return output
endfunction

function scatterValues(values, indices, newValuesSize, fillerValue)
    newValues = repeat(newValuesSize, fillerValue)
    for (i, scatterIndex) in indices
        newValues[scatterIndex] = values[i]
    endfor
endfunction</code></td>
    <td class="webnnColumn">reshape (plus caller logic)</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Reshape">Reshape</a> plus caller logic</td>
    <td class="dmlColumn">NA, just rearrange the TENSOR_DESC</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Tile</td>
    <td class="detailsColumn">Repeat entire tensor along each axis by repeat counts.
<code>
function tile(input, repeats)
    assert(repeats.size == input.rank)
    for i=0..&lt;input.rank do assert(repeats[i] &gt; 0)
    outputDimensions = input.dimensions * repeats // elementwise multiply per axis
    output = new Tensor(input.dataType, outputDimensions)
    for each outputCoordinate in output
        for i=0..&lt;input.rank do inputCoordinate[i] = outputCoordinate[i] % input.dimensions[i]
        output[outputCoordinate] = inputData[inputCoordinate]
    endfor
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Tile">Tile</a></td>
    <td class="dmlColumn">DML_OPERATOR_TILE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Split</td>
    <td class="detailsColumn">Split input into multiple output tensors.</td>
    <td class="webnnColumn">split</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Split">Split</a></td>
    <td class="dmlColumn">DML_OPERATOR_SPLIT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Slice</td>
    <td class="detailsColumn">Crop the tensor to the given ranges for each axis.

<code>function slice(input, starts, ends, axes, steps)
    N = input.rank
    if axes.empty then axes = arange(0, N-1) // [0,1,2,...]
    if starts.empty then starts = zeroes(N) // [0,0,0,...]
    if ends.empty then ends = input.dimensions
    if steps.empty then steps = ones(N) // [1,1,1,...]
    assert(axes.size == input.rank || axes.size == 0)
    assert(starts.size == axes.size)
    assert(ends.size == axes.size)
    assert(steps.size == axes.size)
    starts = max(starts, zeroes(N))
    ends = min(ends, input.dimensions)
    ends = max(ends, starts)

    for i=0..&lt;N do output.dimensions[i] = ceil((ends[i] - starts[i]) / steps[i]) // negative steps unhandled!
    for each outputCoordinate in output
        for i=0..&lt;N do inputCoordinate[i] = outputCoordinate[i] * steps[i] + starts[i]
        output[outputCoordinate] = inputData[inputCoordinate]
    endfor
endfunction</code></td>
    <td class="webnnColumn">slice</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Slice">Slice</a></td>
    <td class="dmlColumn">DML_OPERATOR_SLICE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Concatenate</td>
    <td class="detailsColumn">Combine multiple tensors into large output tensor. e.g. {1,2,3} with {4,5} -&gt; {1,2,3,4,5}

<code>function concatenate(inputs, axis)
    sizesAlongAxis = []
    for each input in inputs
        sizesAlongAxis.append(input.dimensions[axis])
    endfor
    outputOffsets = cumulativeSum(axisSizes)
    for each inputIndex from 0 up to inputs.count
        input = inputs[inputIndex]
        outputOffset = outputOffset[inputIndex]
        for each index from 0 up to axis
            output[..., outputOffset + index, ...] = input[..., index, ...]
        endfor
    endfor
endfunction</code></td>
    <td class="webnnColumn">concat</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Concat">Concat</a></td>
    <td class="dmlColumn">DML_OPERATOR_JOIN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Gather</td>
    <td class="detailsColumn">TODO:</td>
    <td class="webnnColumn">gather</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Gather">Gather</a></td>
    <td class="dmlColumn">DML_OPERATOR_GATHER</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Gather Elements</td>
    <td class="detailsColumn">Return output tensor the same size as indices, filling with values from input indexed along the axis by indices.
<code>
function gatherElements(input, indices, axis)
  output = new Tensor(input.dataType, indices.dimensions)
  for each coordinate in indices tensor
      inputCoordinate = coordinate
      inputCoordinate[axis] = indices[coordinate]
      output[coordinate] = input[inputCoordinate]
  endfor
endfunction

output[i][j][k] = input[ index[i][j][k] ][j][k]  # if dim == 0
output[i][j][k] = input[i][ index[i][j][k] ][k]  # if dim == 1
output[i][j][k] = input[i][j][ index[i][j][k] ]  # if dim == 2
</code>

e.g.
<code>
input = [1,2,3,4,5,6]
indices = [0,0,1,5]
axis = 0
output = [1,1,2,6]

e.g.
input = [[1,2],[3,4],[5,6]]
indices = [[0,0],[1,0],[1,1]]
axis = 1
output = [[1,1], [4,3], [6,6]]
</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherElements">GatherElements</a></td>
    <td class="dmlColumn">DML_OPERATOR_GATHER_ELEMENTS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn"><a href="https://pytorch.org/docs/stable/torch.html#torch.gather">torch.gather</a></td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Gather Multidimensional</td>
    <td class="detailsColumn"><code>TODO:</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherND">GatherND</a></td>
    <td class="dmlColumn">DML_OPERATOR_GATHER_ND</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Scatter Elements</td>
    <td class="detailsColumn">Opposite of gather elements. Overwrites input values with updates into along the axis at the given indices.<br/>If two output element indices overlap, the last write wins in practice.
<code>
function scatterElements(input, indices, updates, axis)
    output = input
    for each coordinate in indices tensor
        outputCoordinate = coordinate
        outputCoordinate[axis] = indices[coordinate]
        output[outputCoordinate] = updates[coordinate]
    endfor
endfunction

output[ index[i][j][k] ][j][k] = input[i][j][k]  # if dim == 0
output[i][ index[i][j][k] ][k] = input[i][j][k]  # if dim == 1
output[i][j][ index[i][j][k] ] = input[i][j][k]  # if dim == 2
</code>

<code>
e.g.
data = [[1, 2, 3, 4, 5]] // data == input
indices = [[1, 3]]
updates = [[11, 21]]
axis = 1
output = [[1, 11, 3, 21, 5]]
</code>
  </td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.6.0/docs/Operators.md#ScatterElements">ScatterElements</a><br/><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.scatter_">torch.tensor.scatter_</a></td>
    <td class="dmlColumn">DML_OPERATOR_SCATTER_ELEMENTS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Scatter ND</td>
    <td class="detailsColumn"><code>TODO:</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.6.0/docs/Operators.md#ScatterND">ScatterND</a></td>
    <td class="dmlColumn">DML_OPERATOR_SCATTER_ND</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Pad</td>
    <td class="detailsColumn">Inflate the input with zeroes on the edges</td>
    <td class="webnnColumn">pad</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pad">Pad</a></td>
    <td class="dmlColumn">DML_OPERATOR_PADDING</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Space To Depth</td>
    <td class="detailsColumn">Rearrange blocks of elements.
<code>
channelCountDivBlockCount = channelCount / (blockSize * blockSize);
inputIndices = [
    outputIndices.batch,
    outputIndices.channel % channelCountDivBlockCount,
    (outputIndices.channel / channelCountDivBlockCount) / blockSize + (outputIndices.height * blockSize),
    (outputIndices.channel / channelCountDivBlockCount) % blockSize + (outputIndices.width  * blockSize)
]

output[outputIndices] = input[inputIndices];</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#SpaceToDepth">SpaceToDepth</a></td>
    <td class="dmlColumn">DML_OPERATOR_SPACE_TO_DEPTH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Depth To Space</td>
    <td class="detailsColumn">Rearrange blocks of elements.
<code>
channelCountDivBlockCount = channelCount / (blockSize * blockSize);
outputIndices = [
    inputIndices.batch,
    inputIndices.channel % channelCountDivBlockCount,
    (inputIndices.channel / channelCountDivBlockCount) / blockSize + (inputIndices.height * blockSize),
    (inputIndices.channel / channelCountDivBlockCount) % blockSize + (inputIndices.width  * blockSize)
]

output[outputIndices] = input[inputIndices];</code>

<b>NumPy:</b>
<code>
# Using DCR mode (depth/column/row)
b, c, h, w = x.shape
tmp = np.reshape(x, [b, blocksize, blocksize, c // (blocksize**2), h, w])
tmp = np.transpose(tmp, [0, 3, 4, 1, 5, 2])
y = np.reshape(tmp, [b, c // (blocksize**2), h * blocksize, w * blocksize])

# Using CRD mode (column/row/depth)
b, c, h, w = x.shape
tmp = np.reshape(x, [b, c // (blocksize ** 2), blocksize, blocksize, h, w])
tmp = np.transpose(tmp, [0, 1, 4, 2, 5, 3])
y = np.reshape(tmp, [b, c // (blocksize ** 2), h * blocksize, w * blocksize])</code></td>
    <td class="webnnColumn">reshape and transpose</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#DepthToSpace">DepthToSpace</a></td>
    <td class="dmlColumn">DML_OPERATOR_DEPTH_TO_SPACE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Dimensions (aka Shape, Sizes)</td>
    <td class="detailsColumn">Return the dimensions of the tensor as a 1D tensor.

<code>function dimensions(input) = input.dimensions</code></td>
    <td class="webnnColumn">MLOperandDescriptor::dimensions</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Shape">Shape</a></td>
    <td class="dmlColumn">NA, just read the TENSOR_DESC dimensions</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Element Count</td>
    <td class="detailsColumn"><code>function elementCount(input) = reduceProduct(input.dimensions, keepDimensions=false)</code>.

note: <code>Size</code> is unfortunately named, inconsistently so with <code>Resize-10</code> which accepts separate dimensions. 🙃
If you want the sizes of the tensor (N C H W) rather than just the total element count, called <code>Shape</code> instead.</td>
    <td class="webnnColumn">product(MLOperandDescriptor::dimensions)</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Size">Size</a></td>
    <td class="dmlColumn">NA, just compute the number of TENSOR_DESC elements</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Element Count Along Axes</td>
    <td class="detailsColumn"><code>function elementCountAlongAxes(inputDimensions, axes)
    return reduceProduct(gatherElements(input.dimensions, axes), keepDimensions=false)
endfunction</code></td>
    <td class="webnnColumn">product(MLOperandDescriptor::dimensions)</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Size">Size</a></td>
    <td class="dmlColumn">NA, just compute the number of TENSOR_DESC elements</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization mapping</td>
    <td>One Hot Along Axis</td>
    <td class="detailsColumn">Set all elements to 'off' values, then set one element to 'on' value along specified axis using index offset.

<code>function oneHot(indices, axis, axisLength, values)
    // Indices and output are broadcast compatible.
    // Indices has a dimension of size 1 at axis.
    // Output has a dimension of size axisLength at axis (opposite of reduction).
    // 1D values[2] contains {offValue, oneValue}.
    assert(indices.dimensions[axis] == 1)
    outputDimensions = indices.dimensions
    outputDimensions[axis] = axisLength
    defaultValues = broadcast(values[0], outputDimensions)
    return scatterElements(defaultValues, indices, values[1], axis)
endfunction

function oneHotExpandedOutput(indices, axis, axisLength, values)
    // Output is 1 dimension bigger than input, inserted at the axis.
    broadcastCompatibleDimensions = reshapeInsertingOnes(indices, [axis])
    broadcastCompatibleIndices = reshape(indices, broadcastCompatibleDimensions)
    return oneHot(broadcastCompatibleIndices, axis, axisLength, values)
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#OneHot">OneHot</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ONE_HOT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Top K Sorted Selection</td>
    <td class="detailsColumn"><code>function topK(input, axis, axisLength)
    // Order the entries along an axis, keeping a length of the top K.
    return slice(sortDecreasing(input, axis), starts=[0], ends=[axisLength], axes=[axis])
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#TopK">TopK</a></td>
    <td class="dmlColumn">DML_OPERATOR_TOP_K</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization, Elementwise, Selection</td>
    <td>Select elementwise<br/>("where" is a bad name)</td>
    <td class="detailsColumn"><code>function select(condition, trueValue, falseValue)
    elementwiseTrinary(condition, trueValue, falseValue, (c, t, f) => if c then t else f)
endfunction</code>

notes: A conditional per-element if statement. Can be used to implement composites that use logical operators (e.g. PRelu).</td>
    <td class="webnnColumn">where</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Where">Where</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IF</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">stablehlo.select</td>
    <td class="tosaColumn">tola.select</td>
    <td class="numpyColumn">numpy.where</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization, Selection</td>
    <td>Join Selected Slices</td>
    <td class="detailsColumn">A conditional slice/join along a specific axis. Has utterly nothing to do with data compression, despite the confusing name.</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Compress">Compress</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Reverse axes</td>
    <td class="detailsColumn">Reverse all the elements along the given axes.
<code>
function reverseAxes(input, axes)
  output = newTensor(input.dimensions, input.dataType)
  for each inputCoordinate in input tensor
      // Flip the coordinate along all applicable axes.
      outputCoordinates = inputCoordinates
      for each axis in axes
          outputCoordinates[axis] = output.dimensions[axis] - outputCoordinates[axis] - 1
      endfor

      output[outputCoordinate] = input[inputCoordinate]
  endfor
endfunction
</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/pull/1804">Reverse</a> <a href="https://github.com/onnx/onnx/pull/1882">(Reverted)</a></td>
    <td class="dmlColumn">DML_OPERATOR_SLICE1<br/>with negative strides</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Pool Generic</td>
    <td class="detailsColumn"><code>function poolGeneric(input, axes, windowDimensions, padding, strides, dilations, reductionFunction, initialValue)
    // Massage all axes-relative parameters to be directly compatible with input/output rank.
    expandedWindowDimensions = gatherValues(windowDimensions, axes, input.rank, 1)
    expandedPadding = gatherValues(padding, axes, input.rank, 0)
    expandedStrides = gatherValues(strides, axes, input.rank, 1)
    expandedDilations = gatherValues(dilations, axes, input.rank, 1)

    // Compute the output tensor size based on window size/padding/strides/dilations.
    filterExtents = ((expandedWindowDimensions - 1) * expandedDilations) + 1
    paddedDimensions = input.dimensions + expandedPadding.leading + expandedPadding.trailing
    outputDimensions = (paddedDimensions - filterExtents + 1) / expandedStrides
    output = new Tensor(input.type, outputDimensions)

    // Reduce input along active axes.
    for each outputCoordinate in output coordinates
        // For each input in the window, apply the reduction function
        outputValue = initialValue
        for each (inputCoordinate, inputValue) in local input window
            outputValue = reductionFunction(outputValue, input[inputCoordinate])
        endfor
        output[outputCoordinate] = outputValue
    endfor
    return output
endfunction

function poolGenericWithIndices(input, axes, windowDimensions, padding, strides, dilations, indicesDataType, reductionFunction, initialValue)
    // TODO: Complete...
    // output = new Tensor(input.type, outputDimensions)
    // indices = new Tensor(indicesDataType, outputDimensions)

    return (output, indices)
endfunction</code>

TODO: Express pooling as higher dimension strided reduction.</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">?</td>
    <td class="dmlColumn">?</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Pool Sum</td>
    <td class="detailsColumn"><code>function poolSum(input, axes, windowDimensions, padding, strides, dilations)
    return poolGeneric(input, axes, windowDimensions, padding, strides, dilations, add, 0)
    // OR  convolve(input, filter = ones(windowDimensions), axes, windowDimensions, padding, strides, dilations)
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">?</td>
    <td class="dmlColumn">?</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Pool Average</td>
    <td class="detailsColumn"><code>function poolAverage(input, axes, windowDimensions, padding, strides, dilations)
    windowElementCount = elementCountAlongAxes(input.dimensions, axes)
    return div(poolSum(input, axes, windowDimensions, padding, strides, dilations), windowElementCount)
endfunction</code></td>
    <td class="webnnColumn">averagePool2d</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#AveragePool">AveragePool</a></td>
    <td class="dmlColumn">DML_OPERATOR_AVERAGE_POOLING</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Pool Average Spatial Dimensions Global</td>
    <td class="detailsColumn"><code>function poolAverageSpatialDimensionsGlobal(input)
    axes = increasingSequence(2, input.rank) // Skip N and C dimensions.
    return reduceAverage(input, axes, keepDimensions=true)
    // Alternately poolAverage with windowDimensions equal to the input sizes after N,C.
endfunction</code>

Average all spatial elements in each batch & channel.
So X[N C H W] reduces to Y[N C 1 1]

<b>ONNX GlobalAveragePool</b>:
<code>
InputShape = Shape(X)
SpatialDimensions = Slice(InputShape; starts=2) // skip leading N and C dimensions.
Output = AveragePool(X, kernel_shape=SpatialDimensions))</code></td>
    <td class="webnnColumn">averagePool2d / reduceAverage</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalAveragePool">GlobalAveragePool</a></td>
    <td class="dmlColumn">DML_OPERATOR_AVERAGE_POOLING</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Pool Maximum</td>
    <td class="detailsColumn"><code>function poolMaximum(input, axes, windowDimensions, padding, strides, dilations)
    return poolGeneric(input, axes, windowDimensions, padding, strides, dilations, max, -infinity)
endfunction</code></td>
    <td class="webnnColumn">maxPool2d</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxPool">MaxPool</a></td>
    <td class="dmlColumn">DML_OPERATOR_MAX_POOLING</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Pool Maximum Spatial Dimensions Global</td>
    <td class="detailsColumn"><code><code>function poolMaximumSpatialDimensionsGlobal(input)
    axes = increasingSequence(2, input.rank) // Skip N and C dimensions.
    return reduceMax(input, axes, keepDimensions=true)
    // Alternately poolMaximum with windowDimensions equal to the input sizes after N,C.
endfunction</code></code></td>
    <td class="webnnColumn">maxPool2d / reduceMax</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalMaxPool">GlobalMaxPool</a></td>
    <td class="dmlColumn">DML_OPERATOR_MAX_POOLING with output being 1 element</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Unpool Maximum</td>
    <td class="detailsColumn">Opposite of MaxPool.
Fill the output tensor of the given shape (either explicit or the input shape plus padding) with zeros.
Then write each value from the input tensor into the output tensor at the element offset from the corresponding indices array.</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#MaxUnpool">MaxUnpool</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
</tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Pool Lebesgue</td>
    <td class="detailsColumn"><code>function poolLebesgue(input, axes, windowDimensions, padding, strides, dilations, exponent)
    return root(poolSum(pow(input, exponent), axes, windowDimensions, padding, strides, dilations), exponent)
    // y = (x1^p + x2^p + ... + xn^p) ^ (1/p)
endfunction</code></td>
    <td class="webnnColumn">l2Pool2d</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LpPool">LpPool</a></td>
    <td class="dmlColumn">DML_OPERATOR_LP_POOLING</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Pool Lebesgue Spatial Dimensions Global</td>
    <td class="detailsColumn"><code>function poolLebesgueSpatialDimensionsGlobal(input, exponent)
    axes = increasingSequence(2, input.rank) // Skip N and C dimensions.
    return reduceLebesgue(input, axes, exponent, keepDimensions=true)
    // TODO: Add the above reduction function
endfunction</code>

So X[N C H W] reduces to Y[N C 1 1]
e.g. (3^2 + 4^2) ^ (1/2) = 5</td>
    <td class="webnnColumn">l2Pool2d</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalLpPool">GlobalLpPool</a></td>
    <td class="dmlColumn">DML_OPERATOR_LP_POOLING with output being 1 element</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Pool Maximum Region of Interest</td>
    <td class="detailsColumn">Apply MaxPool to given input within each numbered region:

[batch_index, w_offset_start, h_offset_start, w_offset_last_inclusive, h_offset_last_inclusive].
Then write the maximal value back to the output.
questions: Are x2 and y2 really supposed to be end-inclusive?
If so, how can that possibly work correctly with the spatial_scale attribute?
What's the point of the pooled_shape when each region has a specific size anyway?</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxRoiPool">MaxRoiPool</a></td>
    <td class="dmlColumn">DML_OPERATOR_ROI_POOLING (only POOLING_MAX is supported)</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce Generic</td>
    <td class="detailsColumn"><code><details><summary>function reduceGeneric(input, axes, keepDimensions, reductionFunction, initialValue)</summary>
    // Determine output tensor dimensions.
    outputDimensions = input.dimensions
    outputCoordinateMask = repeat(outputDimensions.size, 0xFFFFFFFF)
    output = new Tensor(input.type, input.dimensions, initialValue)
    for each axis in axes
        outputDimensions[axis] = 1
        outputCoordinateMask[axis] = 0
    endfor

    // Reduce input along active axes.
    for each (inputCoordinate, value) in input
        outputCoordinate = inputCoordinate & outputCoordinateMask
        previousValue = output[outputCoordinate]
        output[outputCoordinate] = reductionFunction(input, previousValue)
    endfor

    // Remove reduced dimensions (size 1) from output tensor if desired.
    if keepDimensions == false
        outputDimensions = deleteOnesInDimensions(outputDimensions, axes)
    endif
    output.dimensions = outputDimensions
    return output
endfunction</details></code></td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">NA</td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Sum</td>
    <td class="detailsColumn"><code>function reduceSum(input, axes, keepDimensions)
    return reduceGeneric(input, axes, keepDimensions, add, 0) // x[0] + x[1] + ... + x[n-1]
endfunction</code></td>
    <td class="webnnColumn">reduceSum</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceSum">ReduceSum</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_SUM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Mean</td>
    <td class="detailsColumn"><code>function reduceAverage(input, axes, keepDimensions)
    reducedElementCount = elementCountAlongAxes(input.dimensions, axes)
    return div(reduceSum(input, axes, keepDimensions), reducedElementCount)
endfunction</code></td>
    <td class="webnnColumn">reduceMean</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMean">ReduceMean</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_AVERAGE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Product</td>
    <td class="detailsColumn"><code>function reduceProduct(input, axes, keepDimensions)
    return reduceGeneric(input, axes, keepDimensions, mul, 1) // x[0] * x[1] * ... * x[n-1]
endfunction</code></td>
    <td class="webnnColumn">reduceProduct</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceProd">ReduceProd</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_MULTIPLY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Logarithm of Sum</td>
    <td class="detailsColumn"><code>function reduceSumLog(input, axes, keepDimensions)
    return log(reduceSum(input, axes, keepDimensions)) // logₑ(x[0] + x[1] + ... + x[n-1])
endfunction</code></td>
    <td class="webnnColumn">reduceLogSum</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceLogSum">ReduceLogSum</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_LOG_SUM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Logarithm of Sum of Exponents</td>
    <td class="detailsColumn"><code>function reduceExpSumLog(input, axes, keepDimensions)
    return log(reduceSum(exp(input), axes, keepDimensions)) // logₑ(expₑ(x[0]) + expₑ(x[1]) + ... + expₑ(x[n-1]))
endfunction</code></td>
    <td class="webnnColumn">reduceLogSumExp</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceLogSumExp">ReduceLogSumExp</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_LOG_SUM_EXP</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Sum of Squares</td>
    <td class="detailsColumn"><code>function reduceSumSquares(input, axes, keepDimensions)
    return reduceSum(pow(X, 2), axes, keepDimensions) // x[0]^2 + x[1]^2 + ... + x[n-1]^2
endfunction</code></td>
    <td class="webnnColumn">reduceSumSquare</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceSumSquare">ReduceSumSquare</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_SUM_SQUARE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Sum of Absolute Values</td>
    <td class="detailsColumn"><code>function reduceL1(input, axes, keepDimensions)
    return reduceSum(abs(input), axes, keepDimensions) // abs(x[0]) + abs(x[1]) + ... + abs(x[n-1])
endfunction</code></td>
    <td class="webnnColumn">reduceL1</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceL1">ReduceL1</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_L1</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to L2 Distance</td>
    <td class="detailsColumn"><code>function reduceL2(input, axes, keepDimensions)
    return sqrt(reduceSum(pow(X, 2), axes, keepDimensions)) // sqrt(x[0]^2 + x[1]^2 + ... + x[n-1]^2)
endfunction</code></td>
    <td class="webnnColumn">reduceL2</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceL2">ReduceL2</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_L2</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Maximum</td>
    <td class="detailsColumn"><code>function reduceMaximum(input, axes, keepDimensions)
    return reduceGeneric(input, axes, keepDimensions, max, -inf) // max(max(max(x[0], x[1]), x[2]), ..., x[n-1])
endfunction</code></td>
    <td class="webnnColumn">reduceMax</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMax">ReduceMax</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_MAX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Minimum</td>
    <td class="detailsColumn"><code>function reduceMaximum(input, axes, keepDimensions)
    return reduceGeneric(input, axes, keepDimensions, min, inf) // min(min(min(x[0], x[1]), x[2]), ..., x[n-1])
endfunction</code></td>
    <td class="webnnColumn">reduceMin</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMin">ReduceMin</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_MIN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Find Maximum Index</td>
    <td class="detailsColumn"><code>int32 {i j k ..} = maxindex(X Y Z …)</code></td>
    <td class="webnnColumn">argMax</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ArgMax">ArgMax</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_ARGMAX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Find Minimum Index</td>
    <td class="detailsColumn"><code>int32 {i j k ..} = minindex(X Y Z …)</code></td>
    <td class="webnnColumn">argMin</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ArgMin">ArgMin</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_ARGMIN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="imagingOperator">
    <td>Imaging Operators</td>
    <td>Resample</td>
    <td class="detailsColumn"><code>function resample(input, scales)
    outputDimensions = floor(input.dimensions * scales)
    output = new Tensor(input.dataType, outputDimensions)
    for each coordinate in output
        output[coordinate] = input[coordinate / scales]
    endfor
    return output
endfunction</code></td>
    <td class="webnnColumn">resample</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Resize">Resize</a></td>
    <td class="dmlColumn">DML_OPERATOR_RESAMPLE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="imagingOperator">
    <td>Imaging Operators</td>
    <td>Resample Up</td>
    <td class="detailsColumn"><code>resample(input, scales)</code></td>
    <td class="webnnColumn">resample</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Upsample">Upsample</a></td>
    <td class="dmlColumn">DML_OPERATOR_UPSAMPLE_2D</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="controlFlowOperator">
    <td>Control Flow</td>
    <td>If</td>
    <td class="detailsColumn"><code>f(cond, then_graph, else_graph, outputs...):
subgraph = cond ? then_graph : else_graph
outputs = subgraph(implictly_named_inputs_from_outer_graph)</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#If">If</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="controlFlowOperator">
    <td>Control Flow</td>
    <td>Loop</td>
    <td class="detailsColumn">TODO:</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Loop">Loop</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="controlFlowOperator">
    <td>Control Flow</td>
    <td>Scan</td>
    <td class="detailsColumn">TODO:</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Scan">Scan</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Mean Variance Normalization</td>
    <td class="detailsColumn">For each output element, subtract the mean, and divide by standard deviation.

<code>function meanVarianceNormalization(input, axes)
    // = (input - mean) / standardDeviation
    // = (input - mean) / sqrt(variance + epsilon)
    // = (input - mean(X)) / sqrt(mean((input - mean(input))^2))
    // = (input - mean(X)) / sqrt(mean(input^2) - mean(input)^2)
    centeredInput = sub(input, mean)
    mean = reduceAverage(input, axes, keepDimensions=true)
    meanSquared = pow(mean, 2)
    squareMeaned = reduceAverage(pow(input, 2), axes, keepDimensions=true)
    variance = sub(squareMeaned, meanSquared)
    standardDeviation = sqrt(add(varianceEpsilon, epsilon))
    return div(centeredInput, standardDeviation)
endfunction</code>

<details><summary>ONNX and NumPy</summary>

<b>ONNX:</b>
<code>exponent = Const(2.0)
epsilon = Const(1e-9)
inputMean = ReduceMean(input)
inputMeanSquared = Pow(inputMean, exponent)
inputSquared = Pow(input, exponent)
inputSquareMeaned = ReduceMean(inputSquared, keepdims=1)
variance = Sub(inputSquareMeaned, inputMeanSquared)
standardDeviation = Sqrt(variance)
inputCentered = Sub(input, inputMean)
standardDeviationWithEpsilon = Add(standardDeviation, epsilon)
X_MVN = Div(inputCentered, standardDeviationWithEpsilon)</code>

<b>NumPy:</b>
<code>inputMean = np.mean(input, axes, keepdims=1)
inputMeanSquared = np.power(inputMean, 2)
inputSquared = np.power(input, 2)
inputSquareMeaned = np.mean(inputSquared, axes, keepdims=1)
standardDeviation = np.sqrt(inputSquareMeaned - inputMeanSquared)
output = (input - inputMean) / (standardDeviation + 1e-9)</code>
</details></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MeanVarianceNormalization">MeanVarianceNormalization</a></td>
    <td class="dmlColumn">DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION1</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Spatial Normalization<br/>(independent batch&channel)</td>
    <td class="detailsColumn"><code>function instanceNormalization(input, scale, bias, axes)
    // Generic version
    // Applies: DirectML
    assert(isBroadcastCompatible(reshapedScale.dimensions, input.dimensions))
    assert(isBroadcastCompatible(reshapedBias.dimensions, input.dimensions))

    // scale * (input - mean) / sqrt(variance + epsilon) + reshapedBias
    return add(mul(scale, meanVarianceNormalization(input, axes)), bias)
endfunction

function instanceNormalizationSpatialDimensions(input, scale1D, bias1D)
    // Applies: ONNX, WebNN
    spatialAxes = [2 ... input.rank-1] // Exclude axes {0,1} for N and C.
    channelAxes = [1]
    // 1D scale is coerced to [batch size, C axis size, spatial dims...]
    // 1D bias is coerced to [batch size, C axis size, spatial dims...]
    reshapedScale = reshapeToAxes(scale1D, input.rank, channelAxes)
    reshapedBias = reshapeToAxes(bias1D, input.rank, channelAxes)
    return instanceNormalization(input, reshapedScale, reshapedBias, spatialAxes)
endfunction</code>

Mean and variance are computed across spatial dimensions DHW, independently per batch & channel (NC):

<code>axes = [2,3, ..., inputRank-1] // Exclude axes {0,1}
mean = (x0 + x1 + …) / xn;
variance = ((x0 - xmean)^2 + (x1 - xmean)^2 + …) / xn</code>

<b>ONNX:</b>
<code>mean = ReduceAverage(X, axes, keepdims=true)
variance = ReduceAverage(Pow(Sub(X, mean), 2), axes, keepdims=true)</code>

<b>NumPy:</b>
<code>mean = np.mean(x, axis=axes, keepdims=True)
variance = np.var(x, axis=axes, keepdims=True)</code></td>
    <td class="webnnColumn">instanceNormalization</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#InstanceNormalization">InstanceNormalization</a></td>
    <td class="dmlColumn">DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION1 with
    axes = [2,3,4,...] excluding (N,C)
DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION with
    acrossChannels=false
    normalizeVariance=true
    scale and bias provided</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Channel&Spatial Normalization<br/>(independent leading batches) <a href="https://arxiv.org/abs/1803.08494">ref</a></td>
    <td class="detailsColumn"><code>function layerNormalization(input, scale, bias, firstAxis)
    axes = [firstAxis...input.rank - 1]
    // Scale and bias are expected to already be broadcast-compatible with input.
    return add(mul(scale, meanVarianceNormalization(input, axes)), bias)
    // scale * (input - mean) / sqrt(variance + epsilon) + bias
endfunction

Mean and variance are computed across all dimensions from and after axis, independently per leading batches:

<code>axes = [axis, axis+1, ..., inputRank-1] // Exclude axes {0, ..., axis-1}
mean = (x0 + x1 + …) / xn;
variance = ((x0 - xmean)^2 + (x1 - xmean)^2 + …) / xn</code>

<b>ONNX:</b>
<code>mean = ReduceAverage(axes, keepdims=true)
variance = ReduceAverage(Pow(Sub(x, mean), 2), axes, keepdims=true)</code>

<b>NumPy:</b>
<code>mean = np.mean(x, axis=axes, keepdims=True)
variance = np.var(x, axis=axes, keepdims=True)</code></td>
    <td class="webnnColumn">layerNormalization</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#LayerNormalization">LayerNormalization</a></td>
    <td class="dmlColumn">DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION1 with
    axes = [firstAxis, firstAxis+1, ..., input.rank - 1].
DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION with
    acrossChannels=false
    normalizeVariance=true
    scale and bias provided</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Batch&Spatial Normalization<br/>(independent channels)</td>
    <td class="detailsColumn"><code>function batchAndSpatialNormalization(input, scale, bias, mean, var, epsilon, momentum)
    return scale * (input - mean) / sqrt(variance + epsilon) + bias
endfunction</code>

<code>function batchAndSpatialNormalization1DBias(input, scale, bias, mean, var, epsilon, momentum)
    // Assuming C == axis 1.
    return batchAndSpatialNormalization(input, scale, reshapeToAxes(bias, [1]), mean, var, epsilon, momentum)
endfunction</code>

Typically statistics are precomputed across batch <i>and</i> spatial dimensions NDHW
(and not just the batch dimension, as the name would misleadingly lead you believe).
So each channel C is independent.
Then they are reshaped to be broadcast-compatible with the input.

<code>axes = [0,2, ..., inputRank-1] // Exclude axes {1}, and everything except channel
mean = (x0 + x1 + …) / xn;
variance = ((x0 - xmean)^2 + (x1 - xmean)^2 + …) / xn</code>

<b>ONNX:</b>
<code>mean = ReduceAverage(axes, keepdims=true)
variance = ReduceAverage(Pow(Sub(x, mean), 2), axes, keepdims=true)</code>

<b>NumPy:</b>
<code>axes = allAxesExceptChannelAxes
mean = np.var(x, axis=axes, keepdims=True)
variance = np.mean(x, axis=axes, keepdims=True)</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BatchNormalization">BatchNormalization</a></td>
    <td class="dmlColumn">DML_OPERATOR_BATCH_NORMALIZATION</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Local Response Normalization</td>
    <td class="detailsColumn"><code>function localResponseNormalization(input, axes, windowDimensions, padding, scale, bias, exponent)
    regionAverages = averagePoolND(pow(input, 2), axes, windowDimensions, padding)
    return input / pow((regionAverages * scale + bias), exponent)
endfunction</code>

<code>function localResponseNormalizationSquare(input, axes, windowLength, scale, bias, exponent)
    // Only handles square reduction windows.
    windowDimensions = repeat(axes.size, [windowLength])
    leadingPadding = floor((windowLength - 1) / 2) // Center halfway around sliding window
    trailingPadding = ceil((windowLength - 1) / 2) // Center halfway around sliding window
    padding = repeat(axes.size * 2, [leadingPadding, trailingPadding])

    return localResponseNormalization(input, axes, windowDimensions, padding, scale, bias, exponent)
endfunction</code>

For each output element, sum all the corresponding inputs in a local window, considering scale, power, and bias.
Implementations support either 1D or 2D (some only support 1D).

<code>LRN(x, localSize, scaleAlpha, powerBeta, bias = 1) =
    x / (bias + (scaleAlpha / localSize) * sum(xi^2 for every xi in the local region)) ^ powerBeta</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LRN">LRN</a></td>
    <td class="dmlColumn">DML_OPERATOR_LOCAL_RESPONSE_NORMALIZATION</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Lebesgue Length Normalization</td>
    <td class="detailsColumn"><code>function lebesgueLengthNormalization(input, axes, exponent)
    reduced = reduceLp(input, axes, exponent, keepDimensions=1) // reduceL1 or reduceL2
    epsilon = 1e-9
    return div(input, add(sqrt(reduced), epsilon)) // reduced is implicitly expanded to X
endfunction</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LpNormalization">LpNormalization</a> (1D)</td>
    <td class="dmlColumn">DML_OPERATOR_LP_NORMALIZATION (1D)</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">L2NormalizeLayerParams (3D rightmost)</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="uncategorizedOperator">
    <td>Sparse tensor collation</td>
    <td>Nonzero Coordinates List</td>
    <td class="detailsColumn">Append the coordinates of every nonzero input value to a list, with coordinates stored interleaved.
So, not [[X1,Y1,Z1], [X2,Y2,Z2], …] but rather [[X1,X2,…], [Y1,Y1,…], [Z1,Z2,…]].

<code>function nonzeroCoordinatesList(input)
    coordinates = []
    for each (coordinate, i) in input:
        if x != 0 then:
          coordinates.append(coordinate)
        endif
    endfor
endfunction
</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#NonZero">Nonzero</a></td>
    <td class="dmlColumn">DML_OPERATOR_NONZERO_COORDINATES</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
 <tr class="uncategorizedOperator">
    <td>NGram</td>
    <td>Term Frequency Inverse<br/>Document Frequency Vectorizer</td>
    <td class="detailsColumn">Read input front to back, incrementing output histogram for each occurrence found of desired patterns.
It's basically a word count algorithm with the output histogram size equalling the number of words in the dictionary to find.</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#tfidfvectorizer">TfldfVectorizer</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
 <tr class="aggregateOperator">
    <td>Aggregate</td>
    <td>Einstein Summation</td>
    <td class="detailsColumn"><details><summary><code>reduceSum(multiply(a.reshape(aToProductshape)[aToProductStep], B.reshape(bToProductshape)[bToProductStep]), axes = reductionAxes)</code></summary>

<b>Links:</b>
- https://github.com/onnx/onnx/pull/2504
- https://ajcr.net/Basic-guide-to-einsum/
- https://numpy.org/devdocs/reference/generated/numpy.einsum.html
- https://www.tensorflow.org/api_docs/python/tf/einsum
- https://pytorch.org/docs/1.2.0/_modules/torch/functional.html
- https://numpy.org/doc/stable/reference/generated/numpy.dot.html
- https://numpy.org/doc/stable/reference/generated/numpy.matmul.html
- https://ajcr.net/Basic-guide-to-einsum/

Einsum combines tranposition/multiplication/sum reduction into a single operator using a concise string notation of comma separated input axes and an output (e.g. "i,j->ij" with two 1D inputs and a 2D output), which can represent the following operators: identity, diag, trace, transpose, sum, dot product, matmul, elementwise multiplication, inner product, outer product. For example:

- "i,j->ij" means product[i][j] = input0[i] * input1[j]; output[i][j] = product[i][j], two 1D vectors perpendicular to each other, broadcasted, and multiplied to yield a 2D tensor.
- "ij,jk->ik" means product[i][k][j] = input0[i][j] * input1[k][j]; output[i][k] = sum(product[i][k]) which is the classic matrix "multiplication" (np.matmul).
- "ij,i->" means product[i][j] = sum(input0[i][j] * input1[i]); output = sum(product, axis=(0,1)) where every element in a 2D input0 is multiplied by the corresponding row elements in 1D input1 and then all summed into a 0D output scalar.
These can all be expressed generically via...

ONNX general form:

<code>
ReduceSum(
    VariadicMul(
        Reproject(A, aAxesToProductAxes),
        Reproject(B, bAxesToProductAxes),
    ),
    reductionAxes,
    keepdims=false
)
</code>

Numpy Python general form:

<code>
np.sum(
    np.multiply(
        A.reshape(aToProductshape)[aToProductStep],
        B.reshape(bToProductshape)[bToProductStep],
    ),
    axis = reductionAxes
)
</code>

VariadicMul and Reproject are helper operators (not actual ONNX). VariadicMul is a variant of Mul that accepts arbitrary input tensors, like ONNX Sum is to Add. Reproject reprojects the input axes to be compatible with the axes order of the intermediate product, using a combination of Transpose, Unsqueeze, and Range+GatherElements along the diagonal (numpy.diag) depending on the input axes and notation.

Any of these steps may be a nop, which is how the generic form can represent any one of 10 operators. For example, if all output axes are expected (reductionAxes is empty), then the ReduceSum step is identity. If there is only one input tensor, then the VariadicMul is identity. If the input axes are homogenous and listed in the same order as the output tensor, then the Reproject step is identity.

<b>Parsing notation</b>
The difficult part isn't the execution (these fundamentals are already supported in DirectML) but rather parsing the input/output axes from the string and mapping them into actionable operations:

- Concatenate all the unique input axes in alphabetic order (ignore the output on the right of the arrow) to yield the intermediate product tensor's axes. "j,i" yields "ij". "ik,kj" yields "ijk". "cx,by,az" yields "abcxyz". Note the axes in the final output may only include axes found in the original inputs (else error), an axis name may not be reused more than once in the output (axes can be repeated in input assuming both uses have the same dimension size), and the output rank will be equal to or less than the product tensor rank. Note case matters, where aZ is reordered Za (since ASCII Z &lt; a).
- Extract the output axes after the arrow (e.g. the ij from i,j->ij). Mentally you can reorder things, putting the right side of the arrow on the left like normal assignment. So i,j->ij becomes ij = i,j.
- If there is no arrow output specified (e.g. "i,j", which differs from "i,j->" where an arrow explicitly yields a 0D scalar) then the output tensor shape defaults to the product tensor ("i,j" becomes "i,j->ij"). If any axis appears more than once in the input terms (either within the same input term or different terms), remove the axis from the output shape ("ik,ij" yields "jk", "iji" yields "j", "i,ik" yields "k", "i,i" yields scalar "").
- Multiply all comma delimited terms for the intermediate product. ij = i,j (originally i,j->ij) becomes ij = i * j, which means product[i][j] = input0[i] * input1[j].
- Normalize all inputs to be broadcast compatible. e.g. product[i][j] = input0[i][0] * input1[0][j]. Using ONNX, this would require a mix of operators (Unsqueeze, Transpose...) whereas with DirectML, these can all be expressed directly via strides.
- If any axes present in the intermediate product are missing from the final output then put those into reductionAxes (e.g. einsum('ij->j', A) is missing i, and einsum('ij,jk', A, B) with implicit output i,k is missing j). Then get the sum along the reduced axes, ReduceSum(product, axes=j, keepdims=false).
- Transpose the reduced sum to the final output order (e.g "i,j->ji" yields product[i][j] which is remapped to output[j][i]). Note this step doesn't actually need a separate tensor and can be folded into earlier steps, using output strides in the ReduceSum or reordering the input broadcast normalization.
- An efficient implementation would attempt to eliminate steps that yield identity or intermediates that can be handled better by another operator (e.g. for MatMul, the product tensor can be eliminated by using the MatMul operator instead).

<b>Examples:</b>

<code>
#E = np.einsum('ii->i', A)
A = np.array([[0,1,2],[3,4,5],[6,7,8]])
Areshaped = A.reshape([9])[0:9:4] # Or A2.diagonal().
product = np.multiply(Areshaped, identity) # Nop for only one input term.
np.sum(product, axis=()) # Nop given no output axes removed from product.
#Z = np.einsum('ij,kj->ik', A, B)
#Z = np.inner(A, B)
A = np.array([[0,1],[2,3]])
B = np.array([[1,2],[3,4]])
Areshaped = A.reshape([2,1,2])
Breshaped = B.reshape([1,2,2])
Z = np.multiply(Areshaped, Breshaped)
Z = Z.sum(Z, axis=2)
</code>

<b>More examples:</b>

Given...
<code>
A0 = np.array(2)
B0 = np.array(3)
A1 = np.array([0,1,2])
B1 = np.array([3,4,5])
A2 = np.array([[0,1],[2,3]])
B2 = np.array([[1,2],[3,4]])
A3 = np.array([[[0,1],[2,3]],[[4,5],[6,7]]])
B3 = np.array([[[1,2],[3,4]],[[5,6],[7,8]]])
</code>

<table>
<tr><th>Call signature</th><th>NumPy equivalent</th><th>Description</th></tr>
<tr><td>('i', A1)</td><td>A1</td><td>returns a view of A1</td></tr>
<tr><td>('i->', A1)</td><td>sum(A1)</td><td>sums the values of A1</td></tr>
<tr><td>('i,i->i', A1, B1)</td><td>A1 * B1</td><td>element-wise multiplication of A1 and B1</td></tr>
<tr><td>('i,i->', A1, B1)</td><td>inner(A1, B1) or dot(A1, B1)</td><td>inner product of A1 and B1</td></tr>
<tr><td>('i,i', A1, B1)</td><td>inner(A1, B1) or dot(A1, B1)</td><td>inner product of A1 and B1</td></tr>
<tr><td>('i,j->ij', A1, B1)</td><td>outer(A1, B1)</td><td>outer product of A1 and B1</td></tr>
<tr><td>('ij->ij', A2)</td><td>A2</td><td>returns a view of A2</td></tr>
<tr><td>('ij', A2)</td><td>A2</td><td>returns a view of A2</td></tr>
<tr><td>('ji', A2)</td><td>A2.T</td><td>view transpose of A2</td></tr>
<tr><td>('ji->ij', A2)</td><td>A2.T</td><td>view transpose of A2</td></tr>
<tr><td>('ii->i', A2)</td><td>diag(A2)</td><td>view main diagonal of A2</td></tr>
<tr><td>('ii->', A2)</td><td>trace(A2)</td><td>sums main diagonal of A2</td></tr>
<tr><td>('ij->', A2)</td><td>sum(A2)</td><td>sums the values of A2</td></tr>
<tr><td>('ij->j', A2)</td><td>sum(A2, axis=0)</td><td>sum down the columns of A2 (across rows)</td></tr>
<tr><td>('ij->i', A2)</td><td>sum(A2, axis=1)</td><td>sum horizontally along the rows of A2</td></tr>
<tr><td>('ij,ij->ij', A2, B2)</td><td>A2 * B2</td><td>element-wise multiplication of A2 and B2</td></tr>
<tr><td>('ij,ji->ij', A2, B2)</td><td>A2 * B2.transpose()</td><td>element-wise multiplication of A2 and B2.T</td></tr>
<tr><td>('ij,jk', A2, B2)</td><td>matmul(A2, B2) or dot(A2, B2)</td><td>matrix multiplication of A2 and B2</td></tr>
<tr><td>('ij,jk->ik', A2, B2)</td><td>matmul(A2, B2) or dot(A2, B2)</td><td>matrix multiplication of A2 and B2</td></tr>
<tr><td>('bij,bjk->bik', A2, B2)</td><td>matmul(A3, B3)</td><td>matrix multiplication of A3 and B3 (a stack of 2D matrices)</td></tr>
<tr><td>('bij,bkj->bik', A2, B2)</td><td>matmul(A3, transpose(B3))</td><td>matrix multiplication of A3 and B3 (a stack of 2D matrices)</td></tr>
<tr><td>('ij,kj->ik', A2, B2)</td><td>inner(A2, B2)</td><td>inner product of A2 and B2</td></tr>
<tr><td>('ij,kj->ikj', A2, B2)</td><td>A2[:, None] * B2</td><td>each row of A2 multiplied by B2</td></tr>
<tr><td>('ij,kl->ijkl', A2, B2)</td><td>A2[:, :, None, None] * B2</td><td>each value of A2 multiplied by B2</td></tr>
<tr><td>(',ij', 3, B2)</td><td></td><td>Scalar times array: array([[ 0, 3, 6], [ 9, 12, 15]])</td></tr>
<tr><td>("ij,j", A2, B1)</td><td>matvec(A2, B1)</td><td>Matrix and vector.</td></tr>
<tr><td>("ii,ii->i", A2, B2)</td><td>A2.diag() * B2.diag()</td><td>diagonals multiplied by each other</td></tr>
<tr><td>("ii,ii->", A2, B2)</td><td>dot(A2.diag(), B2.diag())</td><td>dot product of diagonals</td></tr>
</table>

For well known patterns, they can be mapped directly to better known operators: https://github.com/microsoft/onnxruntime/blob/4477f57ee3151287a9759bd09d269f0e258a9eda/onnxruntime/core/providers/dml/OperatorAuthorHelper/OperatorHelper.cpp#L1583-L1599
</details></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#EinSum">EinSum</a></td>
    <td class="dmlColumn">DML_OPERATOR_GEMM/TRANSPOSE/REDUCE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="aggregateOperator">
    <td>Aggregate</td>
    <td>Recurrent Neural Network</td>
    <td class="detailsColumn">Y = Activation(Clip(MatMul(X, Transpose(W)) + MatMul(Initial_h, Transpose(R)) + B), -clip, +clip)</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#RNN">RNN</a></td>
    <td class="dmlColumn">DML_OPERATOR_RNN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="aggregateOperator">
    <td>Aggregate</td>
    <td>Gated Recurrent Unit</td>
    <td class="detailsColumn">TODO: Need better summary.
Iteratively apply matrix multiplication.
<code>
Z = Activation1(Clip(MatMul(X, Transpose(W1)) + MatMul(Initial_h1, Transpose(R1)) + b1, -clip, +clip))
R = Activation1(Clip(MatMul(X, Transpose(W2)) + MatMul(Initial_h1, Transpose(R2)) + b2, -clip, +clip))
C = Mul(Initial_h1, R)
O = Activation2(Clip(MatMul(X, Transpose(W3)) + MatMul(Initial_h1, Transpose(R3)) + b3, -clip, +clip))
Y = Mul((1-Z), O) + Mul(Z, Initial_h1)

W = [W1, W2, W3];
b1 = B[0, :] + B[3*hidden_size, :];
b2 = B[1, :] + B[4*hidden_size, :];
b3 = B[2, :] + B[5*hidden_size, :];</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GRU">GRU</a></td>
    <td class="dmlColumn">DML_OPERATOR_GRU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="aggregateOperator">
    <td>Aggregate</td>
    <td>Gated Recurrent Unit Unit</td>
    <td class="detailsColumn">???</td>
    <td class="webnnColumn">gruCell</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.0/docs/Operators.md#GRUUnit">GRUUnit</a> (delete)</td>
    <td class="dmlColumn">NA</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="aggregateOperator">
    <td>Aggregate</td>
    <td>Long Short Term Memory</td>
    <td class="detailsColumn">TODO: Need better summary.
Iteratively apply matrix multiplication.
<code>
I = Activation1f(Clip(MatMul(X, Transpose(W1)) + MatMul(Initial_h1, Transpose(R1)) + Mul(p, initial_c) + b1), -clip, +clip)
F = Activation1f(Clip(MatMul(X, Transpose(W2)) + MatMul(Initial_h1, Transpose(R2)) + Mul(p, initial_c) + b2), -clip, +clip)
Z = Activation2g(Clip(MatMul(X, Transpose(W3)) + MatMul(Initial_h1, Transpose(R3)) + b3), -clip, +clip)
C = Mul(Initial_h1, F) + Mul(I, Z)
O = Activation2g(clip(MatMul(X, Transpose(W4)) + MatMul(Initial_h1, Transpose(R4)) + Mul(p, initial_c) + b4))
Y = Mul(Activation3h(C), O)
&nbsp;
W = [W1, W2, W3, W4];
b1 = B[0, :] + B[4*hidden_size, :];
b2 = B[1, :] + B[5*hidden_size, :];
b3 = B[2, :] + B[6*hidden_size, :];
b4 = B[3, :] + B[7*hidden_size, :];</code></td>
    <td class="webnnColumn">lstm</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LSTM">LSTM</a></td>
    <td class="dmlColumn">DML_OPERATOR_LSTM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="aggregateOperator">
    <td>Aggregate</td>
    <td>Long Short Term Memory Unit</td>
    <td class="detailsColumn">One occurence of LSTM</td>
    <td class="webnnColumn">lstmCell</td>
    <td class="onnxColumn">NA</td>
    <td class="dmlColumn">DML_OPERATOR_LSTM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="aggregateOperator">
    <td>Aggregate</td>
    <td>Multihead Attention</td>
    <td class="detailsColumn">TODO:</td>
    <td class="webnnColumn">X</td>
    <td class="onnxColumn">X</td>
    <td class="dmlColumn">DML_OPERATOR_MULTIHEAD_ATTENTION</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">X</td>
    <td class="tensorFlowLiteColumn">X</td>
    <td class="pytorchColumn">torch.nn.MultiheadAttention</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">mlx.nn.MultiHeadAttention</td>
    <td class="ncnnColumn">MultiHeadAttention</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise, Training</td>
    <td>Dropout</td>
    <td class="detailsColumn">For each element, randomly zero it or multiply it by 1 / (1 - ratio).

<code>f(X, ratio) = select(lesser(random(0, 0.9999), ratio), 0, mul(X, recip(sub(1, ratio)))),
f(x, ratio) = iif(random(0, 0.9999) &lt; ratio, 0, 1 / (1 - ratio) * x);</code>
For forward execution, ratio is 0, and so it's equivalent to: <code>f(X) = identity(X)</code>
notes: If probability = 1, then all zeroes. If 0, then identity. Selected randomly per element.</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Dropout">Dropout</a></td>
    <td class="dmlColumn">NA (can use identity, since not used during inference)</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Unpredictable</td>
  </tr>
  <tr class="uncategorizedOperator">
    <td>Deleted, Code Execution</td>
    <td>A TENsor Kernel</td>
    <td class="detailsColumn">???</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.0/docs/Operators.md#ATen">ATen</a> <i>experimental and deprecated</i></td>
    <td class="dmlColumn">NA</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Unpredictable</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math (Deleted)</td>
    <td>Scale Signal</td>
    <td class="detailsColumn"><code>function scaleSignal(X, scale) = mul(X, scale)</code></td>
    <td class="webnnColumn">mul</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.0/docs/Operators.md#Scale">Scale</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MULTIPLY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math (Deleted)</td>
    <td>Image Scaler</td>
    <td class="detailsColumn"><code>f(X) = add(mul(X, scale), reshapeToAxes(biasTensor, X.rank, [1])) // reshape bias to [1,C,1,1]</code>
<code>f(x, scale, bias) = x * scale + bias</code></td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#ImageScaler">ImageScaler</a></td>
    <td class="dmlColumn">DML_OPERATOR_VALUE_SCALE_2D</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization (Deleted)</td>
    <td>Crop</td>
    <td class="detailsColumn">Crop the tensor to the given ranges for each axis. Crop is confusing and redundant. Just use Slice.</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn"><a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#experimental-crop">Crop</a> (ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Slice">Slice</a> subset)?</td>
    <td class="dmlColumn">DML_OPERATOR_SLICE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="tensorFlowLiteColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="openVinoColumn">?</td>
    <td class="oneDnnColumn">?</td>
    <td class="annColumn">?</td>
    <td class="futureColumn"></td>
    <td>Exact</td>
  </tr>
</table>

<script>
    function toggleAllOperatorsOfIdSuffix(control, suffix)
    {
        let isChecked = control.checked;
        let inputs = document.getElementsByTagName("input");
        for (const input of inputs)
        {
            let name = input.id;
            if (name.endsWith(suffix))
            {
                input.checked = isChecked;
            }
        }
    }
</script>

</body>
</html>

<!-- ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -->

<!--

TODO: Add these

## ConvInteger

https://github.com/onnx/onnx/pull/1908

## MatMulInteger

https://github.com/onnx/onnx/pull/1908

## QLinearConv

https://github.com/onnx/onnx/pull/1908
## QLinearMatMul

https://github.com/onnx/onnx/pull/1908

## NonMaxSuppression

https://github.com/onnx/onnx/pull/1703
https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression
tf.image.non_max_suppression
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/non_max_suppression_op.cc

## StringNormalizer

https://github.com/onnx/onnx/pull/1745
https://github.com/onnx/onnx/blob/master/docs/Operators.md#StringNormalizer

## Resize (Resample=Upsample+Downsample)

https://github.com/onnx/onnx/pull/1773

Resample elements from the source to destination tensor, using the scale factors to compute the destination tensor size. Can use linear or nearest neighbor. Supports interpolation across multiple dimensions, not just 2D. So one can keep the same spatial size but interpolate across channels or across batches.

    samplesToInterpolate = 1 << rank
    samples.resize(samplesToInterpolate)

    for each outputCoordinate in output tensor
        // Offset the fractional component by the pixel center offsets.
        inputCoordinateFloat = (outputCoordinate + outputPixelOrigin) / scales
        inputCoordinateFractions = frac(inputCoordinateFloat) - inputPixelOrigin
        inputCoordinate = floor(inputCoordinateFloat)

        // If the lerp value is negative, adjust to lower pixel.
        inputCoordinate += where(inputCoordinateFractions < 0, -ones(rank), zeroes(rank))
        inputCoordinateFractions += where(inputCoordinateFractions < 0, ones(rank), zeroes(rank))

        // Read the surrounding samples from around the interpolated point.
        for sampleIndex = 0..<samplesToInterpolate
            inputCoordinate = clamp(SampleIndexToCoordinate(sampleIndex), zeroes(rank), input.dimensions - ones(rank))
            samples[sampleIndex] = input[inputCoordinate];
        endfor

        // Intepolate all pixels
        samplesLeftToInterpolate = samplesToInterpolate
        for axis = 0..<rank
            samplesLeftToInterpolate >>= 1
            for sampleIndex = 0..<samplesLeftToInterpolate
                samples[sampleIndex] = lerp(samples[sampleIndex], samples[sampleIndex + samplesLeftToInterpolate], inputCoordinateFractions[sampleIndex])
            endfor
        endfor

        output[outputCoordinate] = samples[0]
    endfor

## ThresholdedRelu (already supported)

https://github.com/onnx/onnx/pull/1856

    f(x) = if x > alpha then x else 0

## BitShift left/right elemntwise shift

https://github.com/onnx/onnx/pull/1931
https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitShift

    2 << 3 = 8
    8 >> 3 = 2

    // transparently apply broadcasting...
    for each coordinate in output tensor coordinates
        if direction == "LEFT"
            output[coordinate] = X[coordinate] << Y[coordinate]
        else if direction == "RIGHT"
            output[coordinate] = X[coordinate] >> Y[coordinate]
        endif
        // else error
    endif

## CumSum cumulative summation

https://github.com/onnx/onnx/pull/2030
https://github.com/onnx/onnx/blob/master/docs/Operators.md#CumSum
tf.math.cumsum
https://www.tensorflow.org/api_docs/python/tf/math/cumsum

Tally the cumulative summation along a given axis.
output size = input size
can proceed along any axis.

    cumsum([a, b, c])  -> [a, a + b, a + b + c]
    cumsum([a, b, c], reverse=true)  -> [a + b + c, b + c, c]
    cumsum([a, b, c], exclusive=true)  -> [0, a, a + b]

    x = [[0,1,3],
         [2,3,5]]
    axis = 0
    exclusive = false
    reverse = false // so go down along y axis
    output = [[0, 1, 3],
              [2, 4, 8]]

Pseudocode:

    int numberOfElementsAlongAxis = input.dimensions[axis]
    int numberOfSlivers = ElementCount(input) / numberOfElementsAlongAxis

    for i = 0..<numberOfSlivers
        int tally = 0
        auto coordinates = ComputeCoordinates(input.dimensions, i, axis)

        for j = 0..<numberOfElementsAlongAxis
            coordinates[axis] = if reverse then numberOfElementsAlongAxis - j else j

            inputValue = input[coordinates]
            if !exclusive
                tally += input[coordinates]
            endif
            output[coordinates] = tally
            if exclusive
                tally += input[coordinates]
            endif
        endfor
    endfor

## Det determinant

https://github.com/onnx/onnx/pull/2233
https://github.com/onnx/onnx/blob/master/docs/Operators.md#Det

Once factored into upper and lower diagonal matrices, or into "row echelon form" with all the lower diagonal being zeroes, the determinant is the product of all values along the diagonal.

## DynamicQuantizeLinear

https://github.com/onnx/onnx/pull/2187
https://github.com/onnx/onnx/blob/master/docs/Operators.md#DynamicQuantizeLinear

Compute the minimum and maximum element in the input. Then apply QuantizeLinear, rounding halves to nearest evens.

    xmax = max(ReduceMax(X), 0)
    xmin = min(ReduceMin(X), 0)
    y_scale = (xmax - xmin) / (qmax - qmin) // qmax - qmin is just 255 for uint8
    intermediate_zero_point = (qmin - min(x)) / (qmax - qmin)
    y_zero_point = cast(round(saturate(itermediate_zero_point)))

    for i = 0..<numberOfElements
        output[i] = saturate(roundNearestEvens(input[i] / y_scale) + y_zero_point)
    endfor

## GatherElements

https://github.com/onnx/onnx/pull/2143
https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherElements

## GatherND

https://github.com/onnx/onnx/pull/2106
https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherND

## Range

https://github.com/onnx/onnx/pull/2242
https://github.com/onnx/onnx/blob/master/docs/Operators.md#Range

Generate a 1D increasing/decreasing sequence of numbers.

``` c
    numberOfElements = max(ceil((limit - start) / delta ), 0)
    output.dimensions = [numberOfElements]

    for i = 0..<numberOfElements
        output[i] = start + (i * delta);
    endfor
```

Example 1 Inputs: `start = 3, limit = 9, delta = 3 Output: [3, 6]`
Example 2 Inputs: `start = 10, limit = 4, delta = -2 Output: [10, 8, 6]`

## Round

https://github.com/onnx/onnx/pull/2053
https://github.com/onnx/onnx/blob/master/docs/Operators.md#Round

For every element, round halves to nearest even.

``` c
    for i = 0..<numberOfElements
        output[i] = roundNearestEven(input[i]);
    endfor
```

## ScatterElements

https://github.com/onnx/onnx/pull/2143
https://github.com/onnx/onnx/blob/master/docs/Operators.md#ScatterElements

## ScatterND

https://github.com/onnx/onnx/pull/2220
https://github.com/onnx/onnx/blob/master/docs/Operators.md#ScatterND

## Unique

https://github.com/onnx/onnx/pull/2141
https://github.com/onnx/onnx/blob/master/docs/Operators.md#Unique

## ConcatFromSequence

https://github.com/onnx/onnx/pull/2249
https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConcatFromSequence

## SequenceAt

https://github.com/onnx/onnx/pull/2249
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceAt

## SequenceConstruct

https://github.com/onnx/onnx/pull/2249
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceConstruct

## SequenceEmpty

https://github.com/onnx/onnx/pull/2249
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceEmpty

## SequenceErase

https://github.com/onnx/onnx/pull/2249
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceErase

## SequenceInsert

https://github.com/onnx/onnx/pull/2249
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceInsert

## SequenceLength

https://github.com/onnx/onnx/pull/2249
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceLength

## SplitToSequence

https://github.com/onnx/onnx/pull/2249
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SplitToSequence

## Resize (with interpolation model)

https://github.com/onnx/onnx/pull/2057

## ReverseSequence

https://github.com/onnx/onnx/pull/1927

Gaussian Error Linear Units (GELUs) Alternate equations

https://arxiv.org/abs/1606.08415 GELU = 0.5*x*(1 + tanh[2/π(x + 0.044715 * x^3)])

https://github.com/huggingface/pytorch-openai-transformer-lm/blob/master/model_pytorch.py#L14-L15 def gelu(x):     return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))

https://github.com/microsoft/onnxruntime/pull/2293/files
    const T x = input[idx];
    const T in = (bias == nullptr) ? x : (x + bias[idx % bias_length]);
    const T cdf = a + a * Tanh(in * (c * in * in + b));
    output[idx] = in * cdf;

https://github.com/apache/incubator-mxnet/pull/14449/files

    const float GELU_CUBIC_CONSTANT = 0.044715;
    const float GELU_ROOT_2_OVER_PI = 0.7978845608028654;

    return 0.5 * x * f(x)
    f: return 1.0 + mx.nd.tanh(g(x))
    g: return ROOT_TWO_OVER_PI * (x + CUBE_CONSTANT * x * x * x)

## Mod

https://github.com/onnx/onnx/pull/1874
https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mod
https://docs.scipy.org/doc/numpy/reference/generated/numpy.mod.html
https://docs.scipy.org/doc/numpy/reference/generated/numpy.fmod.html

numpy.fmod / numpy.mod

The 'fmod' attribute selects between Python vs C signs, which when set really means (a) truncate division toward zero (b) result's sign follows dividend.
Note HLSL says "The % operator is defined only in cases where either both sides are positive or both sides are negative", and so it's likely unsuitable to implement this operator. https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-operators

``` c
    // The C++11 specification says a % b always resolves to the sign of a:
    //
    //  x = [8,  8, -8, -8]
    //  y = [3, -3,  3, -3]
    //  z = [2,  2, -2, -2] -- C fmod(), C %, or numpy.fmod())
    //
    // In Python, a % b (assuming non-zero) has the same sign as b:
    //
    //  x = [8,  8, -8, -8]
    //  y = [3, -3,  3, -3]
    //  z = [2, -1,  1, -2] -- Python % or numpy.mod
    //
    Mod(x, y, fmod) = if fmod == 1 then return x - (y * TruncateTowardZero(x / y)) // like C
                                   else return x - (y * Floor(x / y)) // like Python
```

Also add:

NCNN - https://github.com/Tencent/ncnn/blob/54a9a563e9913d3142782dac0e497f2be50075b5/docs/developer-guide/operators.md
StableHLO - https://github.com/openxla/stablehlo/blob/main/docs/spec.md
TOSA - https://mlir.llvm.org/docs/Dialects/TOSA/#tosaselect-mlirtosaselectop


CoreML https://apple.github.io/coremltools/mlmodel/Format/NeuralNetwork.html:

        ConvolutionLayerParams convolution = 100;

        PoolingLayerParams pooling = 120;

        ActivationParams activation = 130;

        InnerProductLayerParams innerProduct = 140;
        EmbeddingLayerParams embedding = 150;

        // Normalization-related Layers
        BatchnormLayerParams batchnorm = 160;
        MeanVarianceNormalizeLayerParams mvn = 165;
        L2NormalizeLayerParams l2normalize = 170;
        SoftmaxLayerParams softmax = 175;
        LRNLayerParams lrn = 180;

        CropLayerParams crop = 190;
        PaddingLayerParams padding = 200;
        UpsampleLayerParams upsample = 210;

        ResizeBilinearLayerParams resizeBilinear = 211;
        CropResizeLayerParams cropResize = 212;

        UnaryFunctionLayerParams unary = 220;

        // Element-wise Operations
        AddLayerParams add = 230;
        MultiplyLayerParams multiply = 231;

        AverageLayerParams average = 240;
        ScaleLayerParams scale = 245;

        BiasLayerParams bias = 250;
        MaxLayerParams max = 260;
        MinLayerParams min = 261;

        DotProductLayerParams dot = 270;
        ReduceLayerParams reduce = 280;
        LoadConstantLayerParams loadConstant = 290;

        // Data reorganization
        ReshapeLayerParams reshape = 300;
        FlattenLayerParams flatten = 301;
        PermuteLayerParams permute = 310;
        ConcatLayerParams concat = 320;
        SplitLayerParams split = 330;
        SequenceRepeatLayerParams sequenceRepeat = 340;

        ReorganizeDataLayerParams reorganizeData = 345;
        SliceLayerParams slice = 350;

        // Recurrent Layers
        SimpleRecurrentLayerParams simpleRecurrent = 400;
        GRULayerParams gru = 410;
        UniDirectionalLSTMLayerParams uniDirectionalLSTM = 420;
        BiDirectionalLSTMLayerParams biDirectionalLSTM = 430;

        // Custom (user-implemented) Layer
        CustomLayerParams custom = 500;

        // Following layers are available only after Core ML Specification
        // version >= 4 (iOS >= 13, macOS >= 10.15)

        // Control Flow related Layers
        CopyLayerParams copy = 600;
        BranchLayerParams branch = 605;

        LoopLayerParams loop = 615;
        LoopBreakLayerParams loopBreak = 620;
        LoopContinueLayerParams loopContinue = 625;

        RangeStaticLayerParams rangeStatic = 635;
        RangeDynamicLayerParams rangeDynamic = 640;

        // Element-wise Unary Layers
        ClipLayerParams clip = 660;
        CeilLayerParams ceil = 665;
        FloorLayerParams floor = 670;

        SignLayerParams sign = 680;
        RoundLayerParams round = 685;

        Exp2LayerParams exp2 = 700;

        SinLayerParams sin = 710;
        CosLayerParams cos = 715;
        TanLayerParams tan = 720;

        AsinLayerParams asin = 730;
        AcosLayerParams acos = 735;
        AtanLayerParams atan = 740;

        SinhLayerParams sinh = 750;
        CoshLayerParams cosh = 755;
        TanhLayerParams tanh = 760;

        AsinhLayerParams asinh = 770;
        AcoshLayerParams acosh = 775;
        AtanhLayerParams atanh = 780;

        ErfLayerParams erf = 790;
        GeluLayerParams gelu = 795;

        // Element-wise Binary with Broadcasting Support
        EqualLayerParams equal = 815;
        NotEqualLayerParams notEqual = 820;
        LessThanLayerParams lessThan = 825;
        LessEqualLayerParams lessEqual = 827;
        GreaterThanLayerParams greaterThan = 830;
        GreaterEqualLayerParams greaterEqual = 832;

        LogicalOrLayerParams logicalOr = 840;
        LogicalXorLayerParams logicalXor = 845;
        LogicalNotLayerParams logicalNot = 850;
        LogicalAndLayerParams logicalAnd = 855;

        ModBroadcastableLayerParams modBroadcastable = 865;
        MinBroadcastableLayerParams minBroadcastable = 870;
        MaxBroadcastableLayerParams maxBroadcastable = 875;
        AddBroadcastableLayerParams addBroadcastable = 880;
        PowBroadcastableLayerParams powBroadcastable = 885;
        DivideBroadcastableLayerParams divideBroadcastable = 890;
        FloorDivBroadcastableLayerParams floorDivBroadcastable = 895;
        MultiplyBroadcastableLayerParams multiplyBroadcastable = 900;
        SubtractBroadcastableLayerParams subtractBroadcastable = 905;

        // Tensor Manipulations
        TileLayerParams tile = 920;
        StackLayerParams stack = 925;
        GatherLayerParams gather = 930;
        ScatterLayerParams scatter = 935;
        GatherNDLayerParams gatherND = 940;
        ScatterNDLayerParams scatterND = 945;
        SoftmaxNDLayerParams softmaxND = 950;
        GatherAlongAxisLayerParams gatherAlongAxis = 952;
        ScatterAlongAxisLayerParams scatterAlongAxis = 954;

        ReverseLayerParams reverse = 960;
        ReverseSeqLayerParams reverseSeq = 965;

        SplitNDLayerParams splitND = 975;
        ConcatNDLayerParams concatND = 980;
        TransposeLayerParams transpose = 985;

        SliceStaticLayerParams sliceStatic = 995;
        SliceDynamicLayerParams sliceDynamic = 1000;
        SlidingWindowsLayerParams slidingWindows = 1005;

        TopKLayerParams topK = 1015;
        ArgMinLayerParams argMin = 1020;
        ArgMaxLayerParams argMax = 1025;

        EmbeddingNDLayerParams embeddingND = 1040;
        BatchedMatMulLayerParams batchedMatmul = 1045;

        // Tensor Allocation / Reshape-related Operations
        GetShapeLayerParams getShape = 1065;
        LoadConstantNDLayerParams loadConstantND = 1070;

        FillLikeLayerParams fillLike = 1080;
        FillStaticLayerParams fillStatic = 1085;
        FillDynamicLayerParams fillDynamic = 1090;

        BroadcastToLikeLayerParams broadcastToLike = 1100;
        BroadcastToStaticLayerParams broadcastToStatic = 1105;
        BroadcastToDynamicLayerParams broadcastToDynamic = 1110;

        SqueezeLayerParams squeeze = 1120;
        ExpandDimsLayerParams expandDims = 1125;
        FlattenTo2DLayerParams flattenTo2D = 1130;
        ReshapeLikeLayerParams reshapeLike = 1135;
        ReshapeStaticLayerParams reshapeStatic = 1140;
        ReshapeDynamicLayerParams reshapeDynamic = 1145;
        RankPreservingReshapeLayerParams rankPreservingReshape = 1150;

        ConstantPaddingLayerParams constantPad = 1155;

        // Random Distributions
        RandomNormalLikeLayerParams randomNormalLike = 1170;
        RandomNormalStaticLayerParams randomNormalStatic = 1175;
        RandomNormalDynamicLayerParams randomNormalDynamic = 1180;

        RandomUniformLikeLayerParams randomUniformLike = 1190;
        RandomUniformStaticLayerParams randomUniformStatic = 1195;
        RandomUniformDynamicLayerParams randomUniformDynamic = 1200;

        RandomBernoulliLikeLayerParams randomBernoulliLike = 1210;
        RandomBernoulliStaticLayerParams randomBernoulliStatic = 1215;
        RandomBernoulliDynamicLayerParams randomBernoulliDynamic = 1220;

        CategoricalDistributionLayerParams categoricalDistribution = 1230;

        // Reduction-related Layers:
        ReduceL1LayerParams reduceL1 = 1250;
        ReduceL2LayerParams reduceL2 = 1255;
        ReduceMaxLayerParams reduceMax = 1260;
        ReduceMinLayerParams reduceMin = 1265;
        ReduceSumLayerParams reduceSum = 1270;
        ReduceProdLayerParams reduceProd = 1275;
        ReduceMeanLayerParams reduceMean = 1280;
        ReduceLogSumLayerParams reduceLogSum = 1285;
        ReduceSumSquareLayerParams reduceSumSquare = 1290;
        ReduceLogSumExpLayerParams reduceLogSumExp = 1295;

        // Masking / Selection Layers
        WhereNonZeroLayerParams whereNonZero = 1313;
        MatrixBandPartLayerParams matrixBandPart = 1315;
        LowerTriangularLayerParams lowerTriangular = 1320;
        UpperTriangularLayerParams upperTriangular = 1325;
        WhereBroadcastableLayerParams whereBroadcastable = 1330;

        // Normalization Layers
        LayerNormalizationLayerParams layerNormalization = 1350;

        NonMaximumSuppressionLayerParams NonMaximumSuppression = 1400;

        // Following layers are available only after Core ML Specification
        // version >= 5 (iOS >= 14, macOS >= 10.16)
        OneHotLayerParams oneHot = 1450;
        CumSumLayerParams cumSum = 1455;
        ClampedReLULayerParams clampedReLU = 1460;
        ArgSortLayerParams argSort = 1461;
        Pooling3DLayerParams pooling3d = 1465;
        GlobalPooling3DLayerParams globalPooling3d = 1466;
        SliceBySizeLayerParams sliceBySize = 1470;
        Convolution3DLayerParams convolution3d = 1471;

https://github.com/Tencent/ncnn/blob/master/docs/developer-guide/operators.md
https://github.com/Tencent/ncnn/blob/54a9a563e9913d3142782dac0e497f2be50075b5/docs/developer-guide/operators.md

AbsVal
ArgMax
BatchNorm
Bias
BinaryOp
BNLL
Cast
CELU
Clip
Concat
Convolution
Convolution1D
Convolution3D
ConvolutionDepthWise
ConvolutionDepthWise1D
ConvolutionDepthWise3D
CopyTo
Crop
CumulativeSum
Deconvolution
Deconvolution1D
Deconvolution3D
DeconvolutionDepthWise
DeconvolutionDepthWise1D
DeconvolutionDepthWise3D
DeformableConv2D
Dequantize
Diag
Dropout
Eltwise
ELU
Exp
Flatten
GELU
GLU
Gemm
GridSample
GroupNorm
GRU
HardSigmoid
HardSwish
InnerProduct
Input
InstanceNorm
Interp
LayerNorm
Log
LRN
LSTM
MemoryData
Mish
MVN
Noop
Normalize
Packing
Padding
Permute
PixelShuffle
Pooling
Pooling1D
Pooling3D
Power
PReLU
Quantize
Reduction
ReLU
Reorg
Requantize
Reshape
RNN
Scale
SELU
Shrink
ShuffleChannel
Sigmoid
Slice
Softmax
Softplus
Split
Swish
TanH
Threshold
Tile
UnaryOp


https://www.cntk.ai/pythondocs/cntk.ops.html?highlight=cast#cntk.ops.cast
https://microsoft.github.io/CNTK-R/reference/index.html

All functions
activation_identity	Identity Function For CNTK Operations
Activation	Activation Layer
all_devices	All Devices
arraymixin_as_array	ArrayMixin As Array
ArrayMixin	Array Mixin
arrayview_from_data	ArrayView From Data
arrayview_from_dense	ArrayView From Dense Data
arrayview_slice_view	ArrayView Slice View
as_block	As Block
as_composite	As Composite
asvalue	Value Form Matrix
AttentionModel	Attention Model
AveragePooling	Average Pooling Layer
Base64ImageDeserializer	Base64ImageDeserializer
BatchNormalization	BatchNormalization
block_momentum_distributed_learner	Block Momentum Distributed Learner
CheckpointConfig	New Checkpoint Config
classification_error	Classification Error Between Target and Predicted
CloneMethod	CloneMethod
CNTKAxis	CNTKAxis
CNTKCrosstalk	CNTK Implementation for Crosstalk
comm_barrier	Communicator Barrier
comm_current_worker	Communicator Current Worker
comm_finalize	Communicator Finalize
comm_is_main	Communicator Is On Main Node
comm_num_workers	Number of Communicator Nodes
comm_rank	Communicator Rank
comm_workers	Communicator Workers
Communicator	New Communicator
Constant	Constant
Conv2DArgs	Convolution2D Arguments
Conv2DAttr	Conv2D Variable Attribute
Convolution	Convolution
Convolution1D	Convolution1D
Convolution2D	Two Dimensional Convolutional Layer
Convolution3D	Convolution3D
ConvolutionTranspose	ConvolutionTranspose
ConvolutionTranspose1D	ConvolutionTranspose1D
ConvolutionTranspose2D	ConvolutionTranspose2D
ConvolutionTranspose3D	ConvolutionTranspose3D
cpu_descriptor	CPU Descriptor
create_new_leading_axis	Create New Leading Axis
Crosstalk	Crosstalk Base Class
CrossValidationConfig	New Cross Validation Configuration
ct_assign	Assign Crosstalk Value
ct_compare	Compare Crosstalk Var
ct_fetch	Fetch Crosstalk Var
ct_is_param	CNTKCrosstalk Var is Parameter
ct_load_all_params	Load All CNTKCrosstalk Params From Files
ct_load_raw_value	Load Crosstalk Raw Value
ct_load	Load Crosstalk Vars
ct_next_pass	Next Crosstalk Pass
ct_register_funcs	Register Crosstalk Var Type Getter/Setters
ct_reset	Reset Crosstalk Vars
ct_save_all_params	Save All CNTKCrosstalk Params to Files
ct_save_all	Save All Crosstalk Vars
ct_save	Save Crosstalk Vars
ct_set_data	Set CNTKCrosstalk Mapped Data
ct_set_workdir	Set Crosstalk Working Directory
ct_watch	Watch Crosstalk Variable
CTFDeserializer	CTFDeserializer
data_parallel_distributed_learner	New Data Parallel Distributed Learner
debug_model	Debug Model
default_options_for	Default Options For
default_options	Default Options
default_override_or	Default Override Or
default_sample_dir	Default Sample Dir
default_sample_url	Default Sample URL
Delay	Delay
Dense	Dense
DeviceDescriptor	Create Device Descriptor
DeviceKind	Create Device Kind
disable_profiler	Disable Profiler
DistributedLearner	Distributed Learner
Dropout	Dropout
dump_function	Dump Function
dump_signature	Dump Signature
edit_distance_error	Edit Distance Error
EmbedAttr	EmbedAttr
Embedding	Embedding
enable_profiler	Enable Profiler
eval_test_minibatch	Test Evaluator Minibatch
Evaluator	Evaluator
find_func_param	Find Parameter in Function - CNTKCrosstalk
Fold	Fold
For	CNTK Function For Loop Construct
ForwardDeclaration	ForwardDeclaration
func_backward	Propogate Function Backward
func_clone	Clone Function
func_eval	Evaluate Function
func_find_all_with_name	Find All Functions With Name
func_find_by_name	Find Function By Name
func_forward	Compute Function Forward
func_grad	Compute Function Gradient
func_load	Load Function Model
func_replace_placeholder	Replace Function Placeholder
func_replace_placeholders	Replace Function Placeholders
func_restore	Restore Function
func_save	Save Function
func_set_attribute	Set Function Attribute
func_test	Test Function Model
func_train	Train Function Model
FuncInfo	Variable Setter/Getter Functions
Function	CNTK Function
get_all_axes	Get All Axes
get_all_static_axes	Get All Static Axes
get_communicator	Get Distributed Communicator
get_default_batch_axis	Get Default Batch Axis
get_default_dynamic_axis	Get Default Dynamic Axis
get_default_override	Get Default Override
get_global_option	Get Global Option
get_gpu_properties	Get GPU Properties
get_learning_rate	Get Learner Learning Rate
get_logging_trace_level	Get Logging Trace Level
get_minibatch_checkpoint_state	Get Minibatch Checkpoint State
get_static_axis_index	Get Static Axis Index
GlobalAveragePooling	GlobalAveragePooling
GlobalMaxPooling	GlobalMaxPooling
graph_depth_first_search	Graph - Depth First Search
graph_find_all_with_name	Graph - Find All With Name
graph_find_by_name	Graph - Find By Name
GRU	GRU
HTKFeatureDeserializer	HTKFeatureDeserializer
HTKMLFDeserializer	Base64ImageDeserializer
ImageDeserializer	ImageDeserializer
init_bilinear	Bilinear Initializer
init_glorot_normal	Glorot Normal Initializer
init_glorot_uniform	Glorot Uniform Initializer
init_he_normal	He Normal Initializer
init_he_uniform	He Uniform Initializer
init_normal	Normal Initializer
init_truncated_normal	Truncated Normal Initializer
init_uniform	Uniform Initializer
init_with_rank	Initializer With Rank
init_xavier	Xavier Initializer
install_samples	Install Samples
IO_INFINITELY_REPEAT	IO_INFINITELY_REPEAT
is_default_override	Is Default Override
Label	Label
LayerNormalization	LayerNormalization
learner_momentum_sgd	Creates a Momentum SGD learner instance to learn the parameters.
Learner	Learner
log_number_of_parameters	Log Number of Parameters
loss_binary_cross_entropy	Binary Cross Entropy Loss
loss_cosine_distance_negative_samples	Cosine Distance NEgative Samples Loss
loss_cosine_distance	Cosine Distance Loss
loss_cross_entropy_with_softmax	Cross Entropy Loss with Softmax for Multiclass Classification
loss_lambda_rank	Lambda Rank Loss
loss_squared_error	Squared Error Loss
loss_weighted_binary_cross_entropy	Weighted Binary Cross Entropy Loss
LSTM	LSTM
MaxPooling	Max-Pooling Layer Factory
mb_as_sequences	Minibatch Data As Sequences
mb_stream_info	Minibatch Stream Info
mb_stream_infos	Minibatch Stream Infos
MinibatchData	MinibatchData
MinibatchSource	Minibatch Source
MinibatchSourceFromData	MinibatchSourceFromData
module_is_unreleased	Module Is Unreleased
mpi_communicator	New MPI Communicator
native_user_function	Create Native UserFunction
NDArrayView	Create an NDArrayView Instance
ndcg_at_1	NDCG at 1
next_minibatch	Next Minibatch
on_train_cross_validation_end	On Training Cross Validation End
op_abs	Absolute Value
op_alias	Alias
op_argmax	Argmax Across Axis
op_argmin	Argmin Across Axis
op_assign	Assign
op_associative_multi_arg	Associative Multi-Arg
op_batch_normalization	Batch Normalization
op_ceil	Ceiling
op_clip	Clip
op_combine	Combine
op_constant	It creates a constant tensor initialized from a numpy array
op_convolution_transpose	Convolution Transpose
op_convolution	Convolution
op_cos	Element-wise Cosine
op_dim_mean_variance_normalize	Per-dimension Mean-variance Normalization
op_dropout	Dropout
op_element_divide	Element-wise Division
op_element_max	Element Max
op_element_min	Element Min
op_element_select	Element Select
op_element_times	Element Times
op_elu	Elu
op_equal	Equal Comparison
op_exp	Element-wise Exponential
op_floor	Floor
op_forward_backward	Forward-Backward
op_gather	Gather
op_greater_equal	Element-wise Greater Equal Comparison
op_greater	Element-wise Greater Comparison
op_hardmax	Hardmax
op_input_variable	Create input for network
op_labels_to_graph	Labels To Graph
op_leaky_relu	Leaky Relu
op_less_equal	Element-wise Less Equal Comparison
op_less	Element-wise Less Comparison
op_log_add_exp	Log Add Exp
op_log	Element-wise Natural Log
op_minus	Minus
op_negate	Element-wise Negation
op_not_equal	Element-wise Not Equal Comparison
op_one_hot	Create One-Hot Encoding
op_optimized_rnnstack	Optimized RNN Stack
op_output_variable	Output Variable
op_param_relu	Parametric ReLU
op_parameter	Parameter
op_placeholder	Placeholder
op_plus	Addition of Two Tensors
op_pooling	Pooling
op_pow	Power Computation
op_random_sample_inclusion_frequency	Random Sample Inclusion Frequency
op_random_sample	Random Sample
op_reciprocal	Element-wise Reciprocal
op_reconcile_dynamic_axes	Reconcile Dynamic Axes
op_reduce_log_sum_exp	Reduce Max Across Axis
op_reduce_max	Reduce Max Across Axis
op_reduce_mean	Reduce Mean Across Axis
op_reduce_min	Reduce Minimum Across Axis
op_reduce_prod	Reduce Prod Across Axis
op_reduce_sum	Reduce Sum Across Axis
op_relu	Rectified Linear Units Operation
op_reshape	Reshape
op_roipooling	Region of Interest Pooling
op_round	Element-wise Rounding
op_sigmoid	Element-wise Sigmoid
op_sin	Element-wise Sine
op_slice	Slice
op_softmax	Softmax
op_softplus	Softplus
op_splice	Concatenate Across Axis
op_sqrt	Element-wise Square-root
op_square	Element-wise Square
op_stop_gradient	Stop Gradient
op_swap_axes	Swap Axes
op_tanh	Hyperbolic tan
op_times_transpose	One Element Times Another Transposed Element
op_times	Matrix Product
op_to_sequence_like	To Sequence Like
op_to_sequence	To Sequence
op_transpose	Transpose
op_unpooling	Unpooling
Parameter	Parameter
PastValueWindow	Past Value Window
printer_end_progress_print	Printer - End Progress Pring
printer_log	Printer - Log
printer_on_training_update_end	Printer - On Training Update End
printer_on_write_distributed_sync_update	Printer - On Write Distributed Sync Update
printer_on_write_test_summary	Printer - On Write Test Summary
printer_on_write_test_update	any writer
printer_on_write_training_summary	Printer - On Write Training Summary
printer_on_write_training_update	Printer - Training Update on Write
printer_write	Printer - Write
ProgressPrinter	Create Progress Printer
rand_bernoulli_like	Random Bernoulli Like
rand_bernoulli	Random Bernoulli Distribution
rand_gumbel_like	Random Gumbel Like Distribution
rand_gumbel	Random Gumbel Distribution
rand_normal_like	Random Normal Like Distribution
rand_normal	Random Normal Distribution
rand_uniform_like	Random Uniform Like Distribution
rand_uniform	Random Uniform Distribution
Record	Record
Recurrence	Recurrence
RecurrenceFrom	Recurrence From
register_native_user_function	Register Native UserFunction
register_udf_deserialize_callback	Register UDF Deserialize Callback
reset_learning_rate	Reset Learner Learning Rate
ResNetBlock	ResNet Block
restore_mb_from_checkpoint	Restore Minibatch From Checkpoint
restore_trainer_from_checkpoint	Restore Trainer From Checkpoint
RnnArgs	RNN Variable Arguments
RnnAttr	RNN Variable Attributes
RRNStep	RNNStep
save_as_legacy_model	Save As Legacy Model
save_trainer_checkpoint	Save Trainer Checkpoint
seq_broadcast_as	Broadcast Sequence As
seq_delay	Delay Sequence
seq_first	First Element of Sequence
seq_future_value	Sequence Future Value
seq_gather	Sequence Gather
seq_input_variable	Sequence Network Input Variable
seq_is_first	Sequence Is First
seq_is_last	Sequence Is Last
seq_last	Get Last Sequence Element
seq_past_value	Get Past Sequence Value
seq_reduce_max	Reduce Sequence Max
seq_reduce_sum	Reduce Sequence Element Sum
seq_scatter	Sequence Scatter
seq_slice	Sequence Slice
seq_softmax	Sequence Softmax
seq_unpack	Sequence Unpack
seq_where	Sequence Where
sequence_to_cntk_text_format	Convert Sequence to CNTK Text Format
Sequential	Sequential Higher-Order Wrapper for Layer Definitions
SequentialClique	Sequential Clique
sess_minibatch_size_schedule	Create a Minibatch Size Schedule
sess_training_session	Create Training Session Object
set_checked_mode	Set Checked Mode
set_computation_network_trace_level	Set Computation Network Trace Level
set_excluded_devices	Set Excluded Devices
set_global_option	Set Global Option
set_logging_trace_level	Set Logging Trace Level
Stabilizer	Stabilizer
start_profiler	Start Profiler
stop_profiler	Stop Profiler
StreamConfiguration	Stream Configuration
StreamDef	StreamDef
StreamDefs	StreamDefs
StreamInformation	StreamInformation
summarize_test_progress	Summarize Evaluator Test Progress
summarize_training_progress	Summarize Training Progress
tensorboard_close	Close Tensorboard
tensorboard_flush	Flush Tensorboard
tensorboard_write_value	TensorBoard Write Value
TensorBoardProgressWriter	New TensorBoard Progress Writer
TensorOpsMixin	TensorOpsMixin
test_minibatch	Test Minibatch
TestConfig	New Test Configuration
TraceLevel	Trace Level
train_minibatch	Train Minibatch
train_on_session	Train On TrainingSession
Trainer	Trainer
TrainingSession	New Training Configuration
TrainingSummaryProgressCallback	Training Summary Progress Callback
transform_color	Color Transform
transform_crop	Crop Transform
transform_mean	Mean Transform
transform_scale	Scale Transform
try_set_default_device	Try Set Default Device
UnfoldFrom	Unfold From
unknown_dynamic_axes	Unknown Dynamic Axes
UntestedBranchError	Untested Branch Error
updated_record_with	Updated Record With
use_default_device	Use Default Device
user_function	User Defined Function
userfunc_clone	Clone UserFunction
userfunc_deserialize	Deserialize UserFunction
userfunc_infer_outputs	Infer Outputs of UserFunction
userfunc_serialize	Serialize UserFunction
UserFunction	User Function
UserLearner	UserLearner
usermb_next_minibatch	UserMinibatch Next Minibatch
UserMinibatchSource	UserMinibatchSource
value_as_matrix	Value As Matrix
value_as_sequences	Get Value As Sequence of Matrices
value_create	Create a Value Object
value_one_hot	Value as One Hot
Value	New Value Instance
Variable	Variable
VariableMixin	Variable Mixin
VarInfo	Variable Information
visualize_network	Visualize Network Architecture
WorkerDescriptor	New Distributed Worker Descriptor


https://developer.apple.com/documentation/metalperformanceshadersgraph/mpsgraph

func GRU(MPSGraphTensor, recurrentWeight: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, descriptor: MPSGraphGRUDescriptor, name: String?) -> [MPSGraphTensor]
func GRU(MPSGraphTensor, recurrentWeight: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, descriptor: MPSGraphGRUDescriptor, name: String?) -> [MPSGraphTensor]
func GRU(MPSGraphTensor, recurrentWeight: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, mask: MPSGraphTensor?, secondaryBias: MPSGraphTensor?, descriptor: MPSGraphGRUDescriptor, name: String?) -> [MPSGraphTensor]
func GRUGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, outputFwd: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, descriptor: MPSGraphGRUDescriptor, name: String?) -> [MPSGraphTensor]
func GRUGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, outputFwd: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, descriptor: MPSGraphGRUDescriptor, name: String?) -> [MPSGraphTensor]
func GRUGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, outputFwd: MPSGraphTensor, stateGradient: MPSGraphTensor?, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, mask: MPSGraphTensor?, secondaryBias: MPSGraphTensor?, descriptor: MPSGraphGRUDescriptor, name: String?) -> [MPSGraphTensor]
func HammingDistance(primary: MPSGraphTensor, secondary: MPSGraphTensor, resultDataType: MPSDataType, name: String?) -> MPSGraphTensor
func L2NormPooling4D(MPSGraphTensor, descriptor: MPSGraphPooling4DOpDescriptor, name: String?) -> MPSGraphTensor
func L2NormPooling4DGradient(MPSGraphTensor, source: MPSGraphTensor, descriptor: MPSGraphPooling4DOpDescriptor, name: String?) -> MPSGraphTensor
func LSTM(MPSGraphTensor, recurrentWeight: MPSGraphTensor, initState: MPSGraphTensor?, initCell: MPSGraphTensor?, descriptor: MPSGraphLSTMDescriptor, name: String?) -> [MPSGraphTensor]
func LSTM(MPSGraphTensor, recurrentWeight: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, initCell: MPSGraphTensor?, descriptor: MPSGraphLSTMDescriptor, name: String?) -> [MPSGraphTensor]
func LSTM(MPSGraphTensor, recurrentWeight: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, initCell: MPSGraphTensor?, mask: MPSGraphTensor?, peephole: MPSGraphTensor?, descriptor: MPSGraphLSTMDescriptor, name: String?) -> [MPSGraphTensor]
func LSTMGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, cellOutputFwd: MPSGraphTensor, descriptor: MPSGraphLSTMDescriptor, name: String?) -> [MPSGraphTensor]
func LSTMGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, cellOutputFwd: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, initCell: MPSGraphTensor?, descriptor: MPSGraphLSTMDescriptor, name: String?) -> [MPSGraphTensor]
func LSTMGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, cellOutputFwd: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, initCell: MPSGraphTensor?, mask: MPSGraphTensor?, descriptor: MPSGraphLSTMDescriptor, name: String?) -> [MPSGraphTensor]
func LSTMGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, cellOutputFwd: MPSGraphTensor, stateGradient: MPSGraphTensor?, cellGradient: MPSGraphTensor?, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, initCell: MPSGraphTensor?, mask: MPSGraphTensor?, peephole: MPSGraphTensor?, descriptor: MPSGraphLSTMDescriptor, name: String?) -> [MPSGraphTensor]
func absolute(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func acos(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func acosh(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func adam(currentLearningRate: MPSGraphTensor, beta1: MPSGraphTensor, beta2: MPSGraphTensor, epsilon: MPSGraphTensor, values: MPSGraphTensor, momentum: MPSGraphTensor, velocity: MPSGraphTensor, maximumVelocity: MPSGraphTensor?, gradient: MPSGraphTensor, name: String?) -> [MPSGraphTensor]
func adam(learningRate: MPSGraphTensor, beta1: MPSGraphTensor, beta2: MPSGraphTensor, epsilon: MPSGraphTensor, beta1Power: MPSGraphTensor, beta2Power: MPSGraphTensor, values: MPSGraphTensor, momentum: MPSGraphTensor, velocity: MPSGraphTensor, maximumVelocity: MPSGraphTensor?, gradient: MPSGraphTensor, name: String?) -> [MPSGraphTensor]
func addition(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func applyStochasticGradientDescent(learningRate: MPSGraphTensor, variable: MPSGraphVariableOp, gradient: MPSGraphTensor, name: String?) -> MPSGraphOperation
func argSort(MPSGraphTensor, axis: Int, descending: Bool, name: String?) -> MPSGraphTensor
func argSort(MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func argSort(MPSGraphTensor, axisTensor: MPSGraphTensor, descending: Bool, name: String?) -> MPSGraphTensor
func argSort(MPSGraphTensor, axisTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func asin(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func asinh(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func assign(MPSGraphTensor, tensor: MPSGraphTensor, name: String?) -> MPSGraphOperation
func atan(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func atan2(withPrimaryTensor: MPSGraphTensor, secondaryTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func atanh(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func avgPooling2D(withSourceTensor: MPSGraphTensor, descriptor: MPSGraphPooling2DOpDescriptor, name: String?) -> MPSGraphTensor
func avgPooling2DGradient(withGradientTensor: MPSGraphTensor, sourceTensor: MPSGraphTensor, descriptor: MPSGraphPooling2DOpDescriptor, name: String?) -> MPSGraphTensor
func avgPooling4D(MPSGraphTensor, descriptor: MPSGraphPooling4DOpDescriptor, name: String?) -> MPSGraphTensor
func avgPooling4DGradient(MPSGraphTensor, source: MPSGraphTensor, descriptor: MPSGraphPooling4DOpDescriptor, name: String?) -> MPSGraphTensor
func bandPart(MPSGraphTensor, numLower: Int, numUpper: Int, name: String?) -> MPSGraphTensor
func bandPart(MPSGraphTensor, numLowerTensor: MPSGraphTensor, numUpperTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func batchToSpace(MPSGraphTensor, spatialAxes: [NSNumber], batchAxis: Int, blockDimensions: [NSNumber], usePixelShuffleOrder: Bool, name: String?) -> MPSGraphTensor
func batchToSpace(MPSGraphTensor, spatialAxesTensor: MPSGraphTensor, batchAxisTensor: MPSGraphTensor, blockDimensionsTensor: MPSGraphTensor, usePixelShuffleOrder: Bool, name: String?) -> MPSGraphTensor
func bitwiseAND(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func bitwiseLeftShift(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func bitwiseNOT(MPSGraphTensor, name: String?) -> MPSGraphTensor
func bitwiseOR(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func bitwisePopulationCount(MPSGraphTensor, name: String?) -> MPSGraphTensor
func bitwiseRightShift(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func bitwiseXOR(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func broadcast(MPSGraphTensor, shape: [NSNumber], name: String?) -> MPSGraphTensor
func broadcast(MPSGraphTensor, shapeTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func cast(MPSGraphTensor, to: MPSDataType, name: String?) -> MPSGraphTensor
func ceil(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func clamp(MPSGraphTensor, min: MPSGraphTensor, max: MPSGraphTensor, name: String?) -> MPSGraphTensor
func compile(with: MPSGraphDevice?, feeds: [MPSGraphTensor : MPSGraphShapedType], targetTensors: [MPSGraphTensor], targetOperations: [MPSGraphOperation]?, compilationDescriptor: MPSGraphCompilationDescriptor?) -> MPSGraphExecutable
func concatTensor(MPSGraphTensor, with: MPSGraphTensor, dimension: Int, name: String?) -> MPSGraphTensor
func concatTensors([MPSGraphTensor], dimension: Int, interleave: Bool, name: String?) -> MPSGraphTensor
func concatTensors([MPSGraphTensor], dimension: Int, name: String?) -> MPSGraphTensor
func constant(Double, dataType: MPSDataType) -> MPSGraphTensor
func constant(Data, shape: [NSNumber], dataType: MPSDataType) -> MPSGraphTensor
func constant(Double, shape: [NSNumber], dataType: MPSDataType) -> MPSGraphTensor
func controlDependency(with: [MPSGraphOperation], dependentBlock: MPSGraphControlFlowDependencyBlock, name: String?) -> [MPSGraphTensor]
func convolution2D(MPSGraphTensor, weights: MPSGraphTensor, descriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func convolution2DDataGradient(MPSGraphTensor, weights: MPSGraphTensor, outputShape: [NSNumber], forwardConvolutionDescriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func convolution2DDataGradient(MPSGraphTensor, weights: MPSGraphTensor, outputShapeTensor: MPSGraphTensor, forwardConvolutionDescriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func convolution2DWeightsGradient(MPSGraphTensor, source: MPSGraphTensor, outputShape: [NSNumber], forwardConvolutionDescriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func convolution2DWeightsGradient(MPSGraphTensor, source: MPSGraphTensor, outputShapeTensor: MPSGraphTensor, forwardConvolutionDescriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func convolution3D(MPSGraphTensor, weights: MPSGraphTensor, descriptor: MPSGraphConvolution3DOpDescriptor, name: String?) -> MPSGraphTensor
func convolution3DDataGradient(MPSGraphTensor, weights: MPSGraphTensor, outputShape: [NSNumber], forwardConvolutionDescriptor: MPSGraphConvolution3DOpDescriptor, name: String?) -> MPSGraphTensor
func convolution3DDataGradient(MPSGraphTensor, weights: MPSGraphTensor, outputShapeTensor: MPSGraphTensor, forwardConvolutionDescriptor: MPSGraphConvolution3DOpDescriptor, name: String?) -> MPSGraphTensor
func convolution3DWeightsGradient(MPSGraphTensor, source: MPSGraphTensor, outputShape: [NSNumber], forwardConvolutionDescriptor: MPSGraphConvolution3DOpDescriptor, name: String?) -> MPSGraphTensor
func convolution3DWeightsGradient(MPSGraphTensor, source: MPSGraphTensor, outputShapeTensor: MPSGraphTensor, forwardConvolutionDescriptor: MPSGraphConvolution3DOpDescriptor, name: String?) -> MPSGraphTensor
func convolutionTranspose2D(MPSGraphTensor, weights: MPSGraphTensor, outputShape: [NSNumber], descriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func convolutionTranspose2D(MPSGraphTensor, weights: MPSGraphTensor, outputShapeTensor: MPSGraphTensor, descriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func convolutionTranspose2DDataGradient(MPSGraphTensor, weights: MPSGraphTensor, outputShape: [NSNumber], forwardConvolutionDescriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func convolutionTranspose2DDataGradient(MPSGraphTensor, weights: MPSGraphTensor, outputShapeTensor: MPSGraphTensor, forwardConvolutionDescriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func convolutionTranspose2DWeightsGradient(MPSGraphTensor, weights: MPSGraphTensor, outputShape: [NSNumber], forwardConvolutionDescriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func convolutionTranspose2DWeightsGradient(MPSGraphTensor, weights: MPSGraphTensor, outputShapeTensor: MPSGraphTensor, forwardConvolutionDescriptor: MPSGraphConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func coordinate(alongAxis: Int, withShape: [NSNumber], name: String?) -> MPSGraphTensor
func coordinate(alongAxis: Int, withShapeTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func coordinate(alongAxisTensor: MPSGraphTensor, withShape: [NSNumber], name: String?) -> MPSGraphTensor
func coordinate(alongAxisTensor: MPSGraphTensor, withShapeTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func cos(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func cosh(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func cumulativeMaximum(MPSGraphTensor, axis: Int, exclusive: Bool, reverse: Bool, name: String?) -> MPSGraphTensor
func cumulativeMaximum(MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func cumulativeMaximum(MPSGraphTensor, axisTensor: MPSGraphTensor, exclusive: Bool, reverse: Bool, name: String?) -> MPSGraphTensor
func cumulativeMaximum(MPSGraphTensor, axisTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func cumulativeMinimum(MPSGraphTensor, axis: Int, exclusive: Bool, reverse: Bool, name: String?) -> MPSGraphTensor
func cumulativeMinimum(MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func cumulativeMinimum(MPSGraphTensor, axisTensor: MPSGraphTensor, exclusive: Bool, reverse: Bool, name: String?) -> MPSGraphTensor
func cumulativeMinimum(MPSGraphTensor, axisTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func cumulativeProduct(MPSGraphTensor, axis: Int, exclusive: Bool, reverse: Bool, name: String?) -> MPSGraphTensor
func cumulativeProduct(MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func cumulativeProduct(MPSGraphTensor, axisTensor: MPSGraphTensor, exclusive: Bool, reverse: Bool, name: String?) -> MPSGraphTensor
func cumulativeProduct(MPSGraphTensor, axisTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func cumulativeSum(MPSGraphTensor, axis: Int, exclusive: Bool, reverse: Bool, name: String?) -> MPSGraphTensor
func cumulativeSum(MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func cumulativeSum(MPSGraphTensor, axisTensor: MPSGraphTensor, exclusive: Bool, reverse: Bool, name: String?) -> MPSGraphTensor
func cumulativeSum(MPSGraphTensor, axisTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func depth(toSpace2DTensor: MPSGraphTensor, widthAxis: Int, heightAxis: Int, depthAxis: Int, blockSize: Int, usePixelShuffleOrder: Bool, name: String?) -> MPSGraphTensor
func depth(toSpace2DTensor: MPSGraphTensor, widthAxisTensor: MPSGraphTensor, heightAxisTensor: MPSGraphTensor, depthAxisTensor: MPSGraphTensor, blockSize: Int, usePixelShuffleOrder: Bool, name: String?) -> MPSGraphTensor
func depthwiseConvolution2D(MPSGraphTensor, weights: MPSGraphTensor, descriptor: MPSGraphDepthwiseConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func depthwiseConvolution2DDataGradient(MPSGraphTensor, weights: MPSGraphTensor, outputShape: [NSNumber], descriptor: MPSGraphDepthwiseConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func depthwiseConvolution2DWeightsGradient(MPSGraphTensor, source: MPSGraphTensor, outputShape: [NSNumber], descriptor: MPSGraphDepthwiseConvolution2DOpDescriptor, name: String?) -> MPSGraphTensor
func depthwiseConvolution3D(MPSGraphTensor, weights: MPSGraphTensor, descriptor: MPSGraphDepthwiseConvolution3DOpDescriptor, name: String?) -> MPSGraphTensor
func depthwiseConvolution3DDataGradient(MPSGraphTensor, weights: MPSGraphTensor, outputShape: [NSNumber]?, descriptor: MPSGraphDepthwiseConvolution3DOpDescriptor, name: String?) -> MPSGraphTensor
func depthwiseConvolution3DWeightsGradient(MPSGraphTensor, source: MPSGraphTensor, outputShape: [NSNumber], descriptor: MPSGraphDepthwiseConvolution3DOpDescriptor, name: String?) -> MPSGraphTensor
func dequantize(MPSGraphTensor, scale: Double, zeroPoint: Double, dataType: MPSDataType, name: String?) -> MPSGraphTensor
func dequantize(MPSGraphTensor, scaleTensor: MPSGraphTensor, zeroPoint: Double, dataType: MPSDataType, axis: Int, name: String?) -> MPSGraphTensor
func dequantize(MPSGraphTensor, scaleTensor: MPSGraphTensor, zeroPointTensor: MPSGraphTensor, dataType: MPSDataType, axis: Int, name: String?) -> MPSGraphTensor
func division(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func divisionNoNaN(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func dropout(MPSGraphTensor, rate: Double, name: String?) -> MPSGraphTensor
func dropout(MPSGraphTensor, rate: MPSGraphTensor, name: String?) -> MPSGraphTensor
func encode(to: MPSCommandBuffer, feeds: [MPSGraphTensor : MPSGraphTensorData], targetOperations: [MPSGraphOperation]?, resultsDictionary: [MPSGraphTensor : MPSGraphTensorData], executionDescriptor: MPSGraphExecutionDescriptor?)
func encode(to: MPSCommandBuffer, feeds: [MPSGraphTensor : MPSGraphTensorData], targetTensors: [MPSGraphTensor], targetOperations: [MPSGraphOperation]?, executionDescriptor: MPSGraphExecutionDescriptor?) -> [MPSGraphTensor : MPSGraphTensorData]
func equal(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func erf(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func expandDims(MPSGraphTensor, axes: [NSNumber], name: String?) -> MPSGraphTensor
func expandDims(MPSGraphTensor, axesTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func expandDims(MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func exponent(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func exponentBase10(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func exponentBase2(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func flatten2D(MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func flatten2D(MPSGraphTensor, axisTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func floor(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func floorModulo(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func `for`(lowerBound: MPSGraphTensor, upperBound: MPSGraphTensor, step: MPSGraphTensor, initialBodyArguments: [MPSGraphTensor], body: MPSGraphForLoopBodyBlock, name: String?) -> [MPSGraphTensor]
func `for`(numberOfIterations: MPSGraphTensor, initialBodyArguments: [MPSGraphTensor], body: MPSGraphForLoopBodyBlock, name: String?) -> [MPSGraphTensor]
func gather(withUpdatesTensor: MPSGraphTensor, indicesTensor: MPSGraphTensor, axis: Int, batchDimensions: Int, name: String?) -> MPSGraphTensor
func gatherAlongAxis(Int, updates: MPSGraphTensor, indices: MPSGraphTensor, name: String?) -> MPSGraphTensor
func gatherAlongAxisTensor(MPSGraphTensor, updates: MPSGraphTensor, indices: MPSGraphTensor, name: String?) -> MPSGraphTensor
func gatherND(withUpdatesTensor: MPSGraphTensor, indicesTensor: MPSGraphTensor, batchDimensions: Int, name: String?) -> MPSGraphTensor
func gradients(of: MPSGraphTensor, with: [MPSGraphTensor], name: String?) -> [MPSGraphTensor : MPSGraphTensor]
func greaterThan(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func greaterThanOrEqualTo(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func identity(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func `if`(MPSGraphTensor, then: MPSGraphIfThenElseBlock, else: MPSGraphIfThenElseBlock?, name: String?) -> [MPSGraphTensor]
func inverse(input: MPSGraphTensor, name: String?) -> MPSGraphTensor
func isFinite(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func isInfinite(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func isNaN(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func leakyReLU(with: MPSGraphTensor, alpha: Double, name: String?) -> MPSGraphTensor
func leakyReLU(with: MPSGraphTensor, alphaTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func leakyReLUGradient(withIncomingGradient: MPSGraphTensor, sourceTensor: MPSGraphTensor, alphaTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func lessThan(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func lessThanOrEqualTo(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func logarithm(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func logarithmBase10(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func logarithmBase2(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func logicalAND(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func logicalNAND(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func logicalNOR(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func logicalOR(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func logicalXNOR(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func logicalXOR(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func matrixMultiplication(primary: MPSGraphTensor, secondary: MPSGraphTensor, name: String?) -> MPSGraphTensor
func maxPooling2D(withSourceTensor: MPSGraphTensor, descriptor: MPSGraphPooling2DOpDescriptor, name: String?) -> MPSGraphTensor
func maxPooling2DGradient(withGradientTensor: MPSGraphTensor, indicesTensor: MPSGraphTensor, outputShape: [NSNumber], descriptor: MPSGraphPooling2DOpDescriptor, name: String?) -> MPSGraphTensor
func maxPooling2DGradient(withGradientTensor: MPSGraphTensor, indicesTensor: MPSGraphTensor, outputShapeTensor: MPSGraphTensor, descriptor: MPSGraphPooling2DOpDescriptor, name: String?) -> MPSGraphTensor
func maxPooling2DGradient(withGradientTensor: MPSGraphTensor, sourceTensor: MPSGraphTensor, descriptor: MPSGraphPooling2DOpDescriptor, name: String?) -> MPSGraphTensor
func maxPooling2DReturnIndices(MPSGraphTensor, descriptor: MPSGraphPooling2DOpDescriptor, name: String?) -> [MPSGraphTensor]
func maxPooling4D(MPSGraphTensor, descriptor: MPSGraphPooling4DOpDescriptor, name: String?) -> MPSGraphTensor
func maxPooling4DGradient(MPSGraphTensor, source: MPSGraphTensor, descriptor: MPSGraphPooling4DOpDescriptor, name: String?) -> MPSGraphTensor
func maxPooling4DGradient(withGradientTensor: MPSGraphTensor, indicesTensor: MPSGraphTensor, outputShape: [NSNumber], descriptor: MPSGraphPooling4DOpDescriptor, name: String?) -> MPSGraphTensor
func maxPooling4DGradient(withGradientTensor: MPSGraphTensor, indicesTensor: MPSGraphTensor, outputShapeTensor: MPSGraphTensor, descriptor: MPSGraphPooling4DOpDescriptor, name: String?) -> MPSGraphTensor
func maxPooling4DReturnIndices(MPSGraphTensor, descriptor: MPSGraphPooling4DOpDescriptor, name: String?) -> [MPSGraphTensor]
func maximum(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func maximumWithNaNPropagation(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func mean(of: MPSGraphTensor, axes: [NSNumber], name: String?) -> MPSGraphTensor
func minimum(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func minimumWithNaNPropagation(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func modulo(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func multiplication(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func negative(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func normalizationBetaGradient(withIncomingGradientTensor: MPSGraphTensor, sourceTensor: MPSGraphTensor, reductionAxes: [NSNumber], name: String?) -> MPSGraphTensor
func normalizationGammaGradient(withIncomingGradientTensor: MPSGraphTensor, sourceTensor: MPSGraphTensor, mean: MPSGraphTensor, varianceTensor: MPSGraphTensor, reductionAxes: [NSNumber], epsilon: Float, name: String?) -> MPSGraphTensor
func normalizationGradient(withIncomingGradientTensor: MPSGraphTensor, sourceTensor: MPSGraphTensor, mean: MPSGraphTensor, varianceTensor: MPSGraphTensor, gammaTensor: MPSGraphTensor?, gammaGradientTensor: MPSGraphTensor?, betaGradientTensor: MPSGraphTensor?, reductionAxes: [NSNumber], epsilon: Float, name: String?) -> MPSGraphTensor
func normalize(MPSGraphTensor, mean: MPSGraphTensor, variance: MPSGraphTensor, gamma: MPSGraphTensor?, beta: MPSGraphTensor?, epsilon: Float, name: String?) -> MPSGraphTensor
func not(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func notEqual(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func oneHot(withIndicesTensor: MPSGraphTensor, depth: Int, axis: Int, dataType: MPSDataType, name: String?) -> MPSGraphTensor
func oneHot(withIndicesTensor: MPSGraphTensor, depth: Int, axis: Int, dataType: MPSDataType, onValue: Double, offValue: Double, name: String?) -> MPSGraphTensor
func oneHot(withIndicesTensor: MPSGraphTensor, depth: Int, axis: Int, name: String?) -> MPSGraphTensor
func oneHot(withIndicesTensor: MPSGraphTensor, depth: Int, dataType: MPSDataType, name: String?) -> MPSGraphTensor
func oneHot(withIndicesTensor: MPSGraphTensor, depth: Int, dataType: MPSDataType, onValue: Double, offValue: Double, name: String?) -> MPSGraphTensor
func oneHot(withIndicesTensor: MPSGraphTensor, depth: Int, name: String?) -> MPSGraphTensor
func padGradient(withIncomingGradientTensor: MPSGraphTensor, sourceTensor: MPSGraphTensor, paddingMode: MPSGraphPaddingMode, leftPadding: [NSNumber], rightPadding: [NSNumber], name: String?) -> MPSGraphTensor
func padTensor(MPSGraphTensor, with: MPSGraphPaddingMode, leftPadding: [NSNumber], rightPadding: [NSNumber], constantValue: Double, name: String?) -> MPSGraphTensor
func placeholder(shape: [NSNumber]?, dataType: MPSDataType, name: String?) -> MPSGraphTensor
func placeholder(shape: [NSNumber]?, name: String?) -> MPSGraphTensor
func power(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func quantize(MPSGraphTensor, scale: Double, zeroPoint: Double, dataType: MPSDataType, name: String?) -> MPSGraphTensor
func quantize(MPSGraphTensor, scaleTensor: MPSGraphTensor, zeroPoint: Double, dataType: MPSDataType, axis: Int, name: String?) -> MPSGraphTensor
func quantize(MPSGraphTensor, scaleTensor: MPSGraphTensor, zeroPointTensor: MPSGraphTensor, dataType: MPSDataType, axis: Int, name: String?) -> MPSGraphTensor
func randomPhiloxStateTensor(withCounterLow: Int, counterHigh: Int, key: Int, name: String?) -> MPSGraphTensor
func randomPhiloxStateTensor(withSeed: Int, name: String?) -> MPSGraphTensor
func randomTensor(withShape: [NSNumber], descriptor: MPSGraphRandomOpDescriptor, name: String?) -> MPSGraphTensor
func randomTensor(withShape: [NSNumber], descriptor: MPSGraphRandomOpDescriptor, seed: Int, name: String?) -> MPSGraphTensor
func randomTensor(withShape: [NSNumber], descriptor: MPSGraphRandomOpDescriptor, stateTensor: MPSGraphTensor, name: String?) -> [MPSGraphTensor]
func randomTensor(withShapeTensor: MPSGraphTensor, descriptor: MPSGraphRandomOpDescriptor, name: String?) -> MPSGraphTensor
func randomTensor(withShapeTensor: MPSGraphTensor, descriptor: MPSGraphRandomOpDescriptor, seed: Int, name: String?) -> MPSGraphTensor
func randomTensor(withShapeTensor: MPSGraphTensor, descriptor: MPSGraphRandomOpDescriptor, stateTensor: MPSGraphTensor, name: String?) -> [MPSGraphTensor]
func randomUniformTensor(withShape: [NSNumber], name: String?) -> MPSGraphTensor
func randomUniformTensor(withShape: [NSNumber], seed: Int, name: String?) -> MPSGraphTensor
func randomUniformTensor(withShape: [NSNumber], stateTensor: MPSGraphTensor, name: String?) -> [MPSGraphTensor]
func randomUniformTensor(withShapeTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func randomUniformTensor(withShapeTensor: MPSGraphTensor, seed: Int, name: String?) -> MPSGraphTensor
func randomUniformTensor(withShapeTensor: MPSGraphTensor, stateTensor: MPSGraphTensor, name: String?) -> [MPSGraphTensor]
func reLU(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func reLUGradient(withIncomingGradient: MPSGraphTensor, sourceTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func read(MPSGraphTensor, name: String?) -> MPSGraphTensor
func reciprocal(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func reductionAnd(with: MPSGraphTensor, axes: [NSNumber]?, name: String?) -> MPSGraphTensor
func reductionAnd(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func reductionArgMaximum(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func reductionArgMinimum(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func reductionMaximum(with: MPSGraphTensor, axes: [NSNumber]?, name: String?) -> MPSGraphTensor
func reductionMaximum(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func reductionMaximumPropagateNaN(with: MPSGraphTensor, axes: [NSNumber]?, name: String?) -> MPSGraphTensor
func reductionMaximumPropagateNaN(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func reductionMinimum(with: MPSGraphTensor, axes: [NSNumber]?, name: String?) -> MPSGraphTensor
func reductionMinimum(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func reductionMinimumPropagateNaN(with: MPSGraphTensor, axes: [NSNumber]?, name: String?) -> MPSGraphTensor
func reductionMinimumPropagateNaN(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func reductionOr(with: MPSGraphTensor, axes: [NSNumber]?, name: String?) -> MPSGraphTensor
func reductionOr(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func reductionProduct(with: MPSGraphTensor, axes: [NSNumber]?, name: String?) -> MPSGraphTensor
func reductionProduct(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func reductionSum(with: MPSGraphTensor, axes: [NSNumber]?, name: String?) -> MPSGraphTensor
func reductionSum(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func reinterpretCast(MPSGraphTensor, to: MPSDataType, name: String?) -> MPSGraphTensor
func reshape(MPSGraphTensor, shape: [NSNumber], name: String?) -> MPSGraphTensor
func reshape(MPSGraphTensor, shapeTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func resize(MPSGraphTensor, size: [NSNumber], mode: MPSGraphResizeMode, centerResult: Bool, alignCorners: Bool, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resize(MPSGraphTensor, sizeTensor: MPSGraphTensor, mode: MPSGraphResizeMode, centerResult: Bool, alignCorners: Bool, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resize(MPSGraphTensor, sizeTensor: MPSGraphTensor, scaleOffsetTensor: MPSGraphTensor, mode: MPSGraphResizeMode, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resize(withGradientTensor: MPSGraphTensor, input: MPSGraphTensor, mode: MPSGraphResizeMode, centerResult: Bool, alignCorners: Bool, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resize(withGradientTensor: MPSGraphTensor, input: MPSGraphTensor, scaleOffsetTensor: MPSGraphTensor, mode: MPSGraphResizeMode, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resizeBilinear(MPSGraphTensor, sizeTensor: MPSGraphTensor, centerResult: Bool, alignCorners: Bool, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resizeBilinear(MPSGraphTensor, sizeTensor: MPSGraphTensor, scaleOffsetTensor: MPSGraphTensor, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resizeBilinear(withGradientTensor: MPSGraphTensor, input: MPSGraphTensor, centerResult: Bool, alignCorners: Bool, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resizeBilinear(withGradientTensor: MPSGraphTensor, input: MPSGraphTensor, scaleOffsetTensor: MPSGraphTensor, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resizeNearest(MPSGraphTensor, sizeTensor: MPSGraphTensor, nearestRoundingMode: MPSGraphResizeNearestRoundingMode, centerResult: Bool, alignCorners: Bool, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resizeNearest(MPSGraphTensor, sizeTensor: MPSGraphTensor, scaleOffsetTensor: MPSGraphTensor, nearestRoundingMode: MPSGraphResizeNearestRoundingMode, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resizeNearest(withGradientTensor: MPSGraphTensor, input: MPSGraphTensor, nearestRoundingMode: MPSGraphResizeNearestRoundingMode, centerResult: Bool, alignCorners: Bool, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func resizeNearest(withGradientTensor: MPSGraphTensor, input: MPSGraphTensor, scaleOffsetTensor: MPSGraphTensor, nearestRoundingMode: MPSGraphResizeNearestRoundingMode, layout: MPSGraphTensorNamedDataLayout, name: String?) -> MPSGraphTensor
func reverse(MPSGraphTensor, axes: [NSNumber], name: String?) -> MPSGraphTensor
func reverse(MPSGraphTensor, axesTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func reverse(MPSGraphTensor, name: String?) -> MPSGraphTensor
func reverseSquareRoot(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func rint(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func round(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func run(feeds: [MPSGraphTensor : MPSGraphTensorData], targetTensors: [MPSGraphTensor], targetOperations: [MPSGraphOperation]?) -> [MPSGraphTensor : MPSGraphTensorData]
func run(with: MTLCommandQueue, feeds: [MPSGraphTensor : MPSGraphTensorData], targetOperations: [MPSGraphOperation]?, resultsDictionary: [MPSGraphTensor : MPSGraphTensorData])
func run(with: MTLCommandQueue, feeds: [MPSGraphTensor : MPSGraphTensorData], targetTensors: [MPSGraphTensor], targetOperations: [MPSGraphOperation]?) -> [MPSGraphTensor : MPSGraphTensorData]
func runAsync(feeds: [MPSGraphTensor : MPSGraphTensorData], targetTensors: [MPSGraphTensor], targetOperations: [MPSGraphOperation]?, executionDescriptor: MPSGraphExecutionDescriptor?) -> [MPSGraphTensor : MPSGraphTensorData]
func runAsync(with: MTLCommandQueue, feeds: [MPSGraphTensor : MPSGraphTensorData], targetOperations: [MPSGraphOperation]?, resultsDictionary: [MPSGraphTensor : MPSGraphTensorData], executionDescriptor: MPSGraphExecutionDescriptor?)
func runAsync(with: MTLCommandQueue, feeds: [MPSGraphTensor : MPSGraphTensorData], targetTensors: [MPSGraphTensor], targetOperations: [MPSGraphOperation]?, executionDescriptor: MPSGraphExecutionDescriptor?) -> [MPSGraphTensor : MPSGraphTensorData]
func sampleGrid(withSourceTensor: MPSGraphTensor, coordinateTensor: MPSGraphTensor, layout: MPSGraphTensorNamedDataLayout, normalizeCoordinates: Bool, relativeCoordinates: Bool, alignCorners: Bool, paddingMode: MPSGraphPaddingMode, nearestRoundingMode: MPSGraphResizeNearestRoundingMode, constantValue: Double, name: String?) -> MPSGraphTensor
func sampleGrid(withSourceTensor: MPSGraphTensor, coordinateTensor: MPSGraphTensor, layout: MPSGraphTensorNamedDataLayout, normalizeCoordinates: Bool, relativeCoordinates: Bool, alignCorners: Bool, paddingMode: MPSGraphPaddingMode, samplingMode: MPSGraphResizeMode, constantValue: Double, name: String?) -> MPSGraphTensor
func scatter(MPSGraphTensor, indices: MPSGraphTensor, shape: [NSNumber], axis: Int, mode: MPSGraphScatterMode, name: String?) -> MPSGraphTensor
func scatterAlongAxis(Int, data: MPSGraphTensor, updates: MPSGraphTensor, indices: MPSGraphTensor, mode: MPSGraphScatterMode, name: String?) -> MPSGraphTensor
func scatterAlongAxis(Int, updates: MPSGraphTensor, indices: MPSGraphTensor, shape: [NSNumber], mode: MPSGraphScatterMode, name: String?) -> MPSGraphTensor
func scatterAlongAxisTensor(MPSGraphTensor, data: MPSGraphTensor, updates: MPSGraphTensor, indices: MPSGraphTensor, mode: MPSGraphScatterMode, name: String?) -> MPSGraphTensor
func scatterAlongAxisTensor(MPSGraphTensor, updates: MPSGraphTensor, indices: MPSGraphTensor, shape: [NSNumber], mode: MPSGraphScatterMode, name: String?) -> MPSGraphTensor
func scatterND(withUpdatesTensor: MPSGraphTensor, indicesTensor: MPSGraphTensor, shape: [NSNumber], batchDimensions: Int, mode: MPSGraphScatterMode, name: String?) -> MPSGraphTensor
func scatterND(withUpdatesTensor: MPSGraphTensor, indicesTensor: MPSGraphTensor, shape: [NSNumber], batchDimensions: Int, name: String?) -> MPSGraphTensor
func scatterNDWithData(MPSGraphTensor, updates: MPSGraphTensor, indices: MPSGraphTensor, batchDimensions: Int, mode: MPSGraphScatterMode, name: String?) -> MPSGraphTensor
func scatterWithData(MPSGraphTensor, updates: MPSGraphTensor, indices: MPSGraphTensor, axis: Int, mode: MPSGraphScatterMode, name: String?) -> MPSGraphTensor
func select(predicate: MPSGraphTensor, trueTensor: MPSGraphTensor, falseTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func shapeOf(MPSGraphTensor, name: String?) -> MPSGraphTensor
func sigmoid(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func sigmoidGradient(withIncomingGradient: MPSGraphTensor, sourceTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func sign(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func signbit(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func sin(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func singleGateRNN(MPSGraphTensor, recurrentWeight: MPSGraphTensor, initState: MPSGraphTensor?, descriptor: MPSGraphSingleGateRNNDescriptor, name: String?) -> [MPSGraphTensor]
func singleGateRNN(MPSGraphTensor, recurrentWeight: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, descriptor: MPSGraphSingleGateRNNDescriptor, name: String?) -> [MPSGraphTensor]
func singleGateRNN(MPSGraphTensor, recurrentWeight: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, mask: MPSGraphTensor?, descriptor: MPSGraphSingleGateRNNDescriptor, name: String?) -> [MPSGraphTensor]
func singleGateRNNGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, initState: MPSGraphTensor?, descriptor: MPSGraphSingleGateRNNDescriptor, name: String?) -> [MPSGraphTensor]
func singleGateRNNGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, descriptor: MPSGraphSingleGateRNNDescriptor, name: String?) -> [MPSGraphTensor]
func singleGateRNNGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, mask: MPSGraphTensor?, descriptor: MPSGraphSingleGateRNNDescriptor, name: String?) -> [MPSGraphTensor]
func singleGateRNNGradients(MPSGraphTensor, recurrentWeight: MPSGraphTensor, sourceGradient: MPSGraphTensor, zState: MPSGraphTensor, stateGradient: MPSGraphTensor?, inputWeight: MPSGraphTensor?, bias: MPSGraphTensor?, initState: MPSGraphTensor?, mask: MPSGraphTensor?, descriptor: MPSGraphSingleGateRNNDescriptor, name: String?) -> [MPSGraphTensor]
func sinh(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func sliceGradientTensor(MPSGraphTensor, fwdInShapeTensor: MPSGraphTensor, starts: [NSNumber], ends: [NSNumber], strides: [NSNumber], name: String?) -> MPSGraphTensor
func sliceGradientTensor(MPSGraphTensor, fwdInShapeTensor: MPSGraphTensor, starts: [NSNumber], ends: [NSNumber], strides: [NSNumber], startMask: UInt32, endMask: UInt32, squeezeMask: UInt32, name: String?) -> MPSGraphTensor
func sliceTensor(MPSGraphTensor, dimension: Int, start: Int, length: Int, name: String?) -> MPSGraphTensor
func sliceTensor(MPSGraphTensor, starts: [NSNumber], ends: [NSNumber], strides: [NSNumber], name: String?) -> MPSGraphTensor
func sliceTensor(MPSGraphTensor, starts: [NSNumber], ends: [NSNumber], strides: [NSNumber], startMask: UInt32, endMask: UInt32, squeezeMask: UInt32, name: String?) -> MPSGraphTensor
func softMax(with: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func softMaxCrossEntropy(MPSGraphTensor, labels: MPSGraphTensor, axis: Int, reuctionType: MPSGraphLossReductionType, name: String?) -> MPSGraphTensor
func softMaxCrossEntropyGradient(MPSGraphTensor, source: MPSGraphTensor, labels: MPSGraphTensor, axis: Int, reuctionType: MPSGraphLossReductionType, name: String?) -> MPSGraphTensor
func softMaxGradient(withIncomingGradient: MPSGraphTensor, sourceTensor: MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func sort(MPSGraphTensor, axis: Int, descending: Bool, name: String?) -> MPSGraphTensor
func sort(MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func sort(MPSGraphTensor, axisTensor: MPSGraphTensor, descending: Bool, name: String?) -> MPSGraphTensor
func sort(MPSGraphTensor, axisTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func space(toDepth2DTensor: MPSGraphTensor, widthAxis: Int, heightAxis: Int, depthAxis: Int, blockSize: Int, usePixelShuffleOrder: Bool, name: String?) -> MPSGraphTensor
func space(toDepth2DTensor: MPSGraphTensor, widthAxisTensor: MPSGraphTensor, heightAxisTensor: MPSGraphTensor, depthAxisTensor: MPSGraphTensor, blockSize: Int, usePixelShuffleOrder: Bool, name: String?) -> MPSGraphTensor
func spaceToBatch(MPSGraphTensor, spatialAxes: [NSNumber], batchAxis: Int, blockDimensions: [NSNumber], usePixelShuffleOrder: Bool, name: String?) -> MPSGraphTensor
func spaceToBatch(MPSGraphTensor, spatialAxesTensor: MPSGraphTensor, batchAxisTensor: MPSGraphTensor, blockDimensionsTensor: MPSGraphTensor, usePixelShuffleOrder: Bool, name: String?) -> MPSGraphTensor
func sparseTensor(sparseTensorWithDescriptor: MPSGraphCreateSparseOpDescriptor, tensors: [MPSGraphTensor], shape: [NSNumber], name: String?) -> MPSGraphTensor
func sparseTensor(sparseTensorWithType: MPSGraphSparseStorageType, tensors: [MPSGraphTensor], shape: [NSNumber], dataType: MPSDataType, name: String?) -> MPSGraphTensor
func split(MPSGraphTensor, numSplits: Int, axis: Int, name: String?) -> [MPSGraphTensor]
func split(MPSGraphTensor, splitSizes: [NSNumber], axis: Int, name: String?) -> [MPSGraphTensor]
func split(MPSGraphTensor, splitSizesTensor: MPSGraphTensor, axis: Int, name: String?) -> [MPSGraphTensor]
func square(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func squareRoot(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func squeeze(MPSGraphTensor, axes: [NSNumber], name: String?) -> MPSGraphTensor
func squeeze(MPSGraphTensor, axesTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func squeeze(MPSGraphTensor, axis: Int, name: String?) -> MPSGraphTensor
func squeeze(MPSGraphTensor, name: String?) -> MPSGraphTensor
func stack([MPSGraphTensor], axis: Int, name: String?) -> MPSGraphTensor
func stencil(withSourceTensor: MPSGraphTensor, weightsTensor: MPSGraphTensor, descriptor: MPSGraphStencilOpDescriptor, name: String?) -> MPSGraphTensor
func stochasticGradientDescent(learningRate: MPSGraphTensor, values: MPSGraphTensor, gradient: MPSGraphTensor, name: String?) -> MPSGraphTensor
func subtraction(MPSGraphTensor, MPSGraphTensor, name: String?) -> MPSGraphTensor
func tan(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func tanh(with: MPSGraphTensor, name: String?) -> MPSGraphTensor
func tileGradient(withIncomingGradientTensor: MPSGraphTensor, sourceTensor: MPSGraphTensor, withMultiplier: [NSNumber], name: String?) -> MPSGraphTensor
func tileTensor(MPSGraphTensor, withMultiplier: [NSNumber], name: String?) -> MPSGraphTensor
func topK(MPSGraphTensor, k: Int, name: String?) -> [MPSGraphTensor]
func topK(MPSGraphTensor, kTensor: MPSGraphTensor, name: String?) -> [MPSGraphTensor]
func topKGradient(MPSGraphTensor, input: MPSGraphTensor, k: Int, name: String?) -> MPSGraphTensor
func topKGradient(MPSGraphTensor, input: MPSGraphTensor, kTensor: MPSGraphTensor, name: String?) -> MPSGraphTensor
func transpose(MPSGraphTensor, permutation: [NSNumber], name: String?) -> MPSGraphTensor
func transposeTensor(MPSGraphTensor, dimension: Int, withDimension: Int, name: String?) -> MPSGraphTensor
func truncate(MPSGraphTensor, name: String?) -> MPSGraphTensor
func variable(with: Data, shape: [NSNumber], dataType: MPSDataType, name: String?) -> MPSGraphTensor
func variance(of: MPSGraphTensor, axes: [NSNumber], name: String?) -> MPSGraphTensor
func variance(of: MPSGraphTensor, mean: MPSGraphTensor, axes: [NSNumber], name: String?) -> MPSGraphTensor
func `while`(initialInputs: [MPSGraphTensor], before: MPSGraphWhileBeforeBlock, after: MPSGraphWhileAfterBlock, name: String?) -> [MPSGraphTensor]


Add NNAPI:

https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaabbe492c60331b13038e39d4207940e0a2fb636e30d8853f9fa1a395e30660e92

OperationCode{
  ANEURALNETWORKS_ADD = 0,
  ANEURALNETWORKS_AVERAGE_POOL_2D = 1,
  ANEURALNETWORKS_CONCATENATION = 2,
  ANEURALNETWORKS_CONV_2D = 3,
  ANEURALNETWORKS_DEPTHWISE_CONV_2D = 4,
  ANEURALNETWORKS_DEPTH_TO_SPACE = 5,
  ANEURALNETWORKS_DEQUANTIZE = 6,
  ANEURALNETWORKS_EMBEDDING_LOOKUP = 7,
  ANEURALNETWORKS_FLOOR = 8,
  ANEURALNETWORKS_FULLY_CONNECTED = 9,
  ANEURALNETWORKS_HASHTABLE_LOOKUP = 10,
  ANEURALNETWORKS_L2_NORMALIZATION = 11,
  ANEURALNETWORKS_L2_POOL_2D = 12,
  ANEURALNETWORKS_LOCAL_RESPONSE_NORMALIZATION = 13,
  ANEURALNETWORKS_LOGISTIC = 14,
  ANEURALNETWORKS_LSH_PROJECTION = 15,
  ANEURALNETWORKS_LSTM = 16,
  ANEURALNETWORKS_MAX_POOL_2D = 17,
  ANEURALNETWORKS_MUL = 18,
  ANEURALNETWORKS_RELU = 19,
  ANEURALNETWORKS_RELU1 = 20,
  ANEURALNETWORKS_RELU6 = 21,
  ANEURALNETWORKS_RESHAPE = 22,
  ANEURALNETWORKS_RESIZE_BILINEAR = 23,
  ANEURALNETWORKS_RNN = 24,
  ANEURALNETWORKS_SOFTMAX = 25,
  ANEURALNETWORKS_SPACE_TO_DEPTH = 26,
  ANEURALNETWORKS_SVDF = 27,
  ANEURALNETWORKS_TANH = 28,
  ANEURALNETWORKS_BATCH_TO_SPACE_ND = 29,
  ANEURALNETWORKS_DIV = 30,
  ANEURALNETWORKS_MEAN = 31,
  ANEURALNETWORKS_PAD = 32,
  ANEURALNETWORKS_SPACE_TO_BATCH_ND = 33,
  ANEURALNETWORKS_SQUEEZE = 34,
  ANEURALNETWORKS_STRIDED_SLICE = 35,
  ANEURALNETWORKS_SUB = 36,
  ANEURALNETWORKS_TRANSPOSE = 37,
  ANEURALNETWORKS_ABS = 38,
  ANEURALNETWORKS_ARGMAX = 39,
  ANEURALNETWORKS_ARGMIN = 40,
  ANEURALNETWORKS_AXIS_ALIGNED_BBOX_TRANSFORM = 41,
  ANEURALNETWORKS_BIDIRECTIONAL_SEQUENCE_LSTM = 42,
  ANEURALNETWORKS_BIDIRECTIONAL_SEQUENCE_RNN = 43,
  ANEURALNETWORKS_BOX_WITH_NMS_LIMIT = 44,
  ANEURALNETWORKS_CAST = 45,
  ANEURALNETWORKS_CHANNEL_SHUFFLE = 46,
  ANEURALNETWORKS_DETECTION_POSTPROCESSING = 47,
  ANEURALNETWORKS_EQUAL = 48,
  ANEURALNETWORKS_EXP = 49,
  ANEURALNETWORKS_EXPAND_DIMS = 50,
  ANEURALNETWORKS_GATHER = 51,
  ANEURALNETWORKS_GENERATE_PROPOSALS = 52,
  ANEURALNETWORKS_GREATER = 53,
  ANEURALNETWORKS_GREATER_EQUAL = 54,
  ANEURALNETWORKS_GROUPED_CONV_2D = 55,
  ANEURALNETWORKS_HEATMAP_MAX_KEYPOINT = 56,
  ANEURALNETWORKS_INSTANCE_NORMALIZATION = 57,
  ANEURALNETWORKS_LESS = 58,
  ANEURALNETWORKS_LESS_EQUAL = 59,
  ANEURALNETWORKS_LOG = 60,
  ANEURALNETWORKS_LOGICAL_AND = 61,
  ANEURALNETWORKS_LOGICAL_NOT = 62,
  ANEURALNETWORKS_LOGICAL_OR = 63,
  ANEURALNETWORKS_LOG_SOFTMAX = 64,
  ANEURALNETWORKS_MAXIMUM = 65,
  ANEURALNETWORKS_MINIMUM = 66,
  ANEURALNETWORKS_NEG = 67,
  ANEURALNETWORKS_NOT_EQUAL = 68,
  ANEURALNETWORKS_PAD_V2 = 69,
  ANEURALNETWORKS_POW = 70,
  ANEURALNETWORKS_PRELU = 71,
  ANEURALNETWORKS_QUANTIZE = 72,
  ANEURALNETWORKS_QUANTIZED_16BIT_LSTM = 73,
  ANEURALNETWORKS_RANDOM_MULTINOMIAL = 74,
  ANEURALNETWORKS_REDUCE_ALL = 75,
  ANEURALNETWORKS_REDUCE_ANY = 76,
  ANEURALNETWORKS_REDUCE_MAX = 77,
  ANEURALNETWORKS_REDUCE_MIN = 78,
  ANEURALNETWORKS_REDUCE_PROD = 79,
  ANEURALNETWORKS_REDUCE_SUM = 80,
  ANEURALNETWORKS_ROI_ALIGN = 81,
  ANEURALNETWORKS_ROI_POOLING = 82,
  ANEURALNETWORKS_RSQRT = 83,
  ANEURALNETWORKS_SELECT = 84,
  ANEURALNETWORKS_SIN = 85,
  ANEURALNETWORKS_SLICE = 86,
  ANEURALNETWORKS_SPLIT = 87,
  ANEURALNETWORKS_SQRT = 88,
  ANEURALNETWORKS_TILE = 89,
  ANEURALNETWORKS_TOPK_V2 = 90,
  ANEURALNETWORKS_TRANSPOSE_CONV_2D = 91,
  ANEURALNETWORKS_UNIDIRECTIONAL_SEQUENCE_LSTM = 92,
  ANEURALNETWORKS_UNIDIRECTIONAL_SEQUENCE_RNN = 93,
  ANEURALNETWORKS_RESIZE_NEAREST_NEIGHBOR = 94,
  ANEURALNETWORKS_QUANTIZED_LSTM = 95,
  ANEURALNETWORKS_IF = 96,
  ANEURALNETWORKS_WHILE = 97,
  ANEURALNETWORKS_ELU = 98,
  ANEURALNETWORKS_HARD_SWISH = 99,
  ANEURALNETWORKS_FILL = 100,
  ANEURALNETWORKS_RANK = 101,
  ANEURALNETWORKS_BATCH_MATMUL = 102,
  ANEURALNETWORKS_PACK = 103,
  ANEURALNETWORKS_MIRROR_PAD = 104,
  ANEURALNETWORKS_REVERSE = 105
}

MIL (model intermediate language) https://apple.github.io/coremltools/source/coremltools.converters.mil.mil.ops.defs.html#coremltools.converters.mil.mil.ops.defs.iOS15.activation.gelu

Add pooling link:
Fine-Grained Vehicle Classification With Channel Max Pooling Modified CNNs
    https://ieeexplore.ieee.org/document/8648206
    DML/TF/PT limited to dimensions 2 to N-1.

jax.lax.broadcast
  https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.broadcast.html
  Adds leading shape. So input size [2,3,4] with shape [5,6] yields [5,6,2,3,4]
broadcast_shapes(*shapes)
  https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.broadcast_shapes.html
  Returns the shape that results from NumPy broadcasting of shapes
BroadcastInDim
  operand	XlaOp	The array to duplicate
  out_dim_size	ArraySlice<int64>	The sizes of the dimensions of the target shape
  broadcast_dimensions	ArraySlice<int64>	Which dimension in the target shape each dimension of the operand shape corresponds to
  https://openxla.org/xla/operation_semantics#broadcastindim
    Given input shape [1,5] and wanting to broadcast to [2,3,4,5,6]
      out_dim_size = [2,3,4,5,6]
      broadcast_dimensions = [1,3]
      So:
        output.shape[0..<5] = 1  // initialize to 1's
        output.shape[1] = input.shape[0] (1)
        output.shape[3] = input.shape[1] (5)
    Equivalent to reshape([1,(1),1,(5),1]).expand([2,3,4,5,6])
    "The order of broadcast dimensions must be strictly increasing." https://openxla.org/xla/broadcasting#formal_definition
    No duplicate axes
    So, it cannot be a transpose() operation

QNN https://docs.qualcomm.com/bundle/publicresource/topics/80-63442-50/MasterOpDef.html

TFLite dialect https://www.tensorflow.org/mlir/tfl_ops

Add all PyTorch Prims: https://pytorch.org/docs/main/torch.compiler_ir.html#prims-ir

-->


<!--
TODO:Add these

Apple MPS (Metal Performance Shaders) - https://developer.apple.com/documentation/metalperformanceshadersgraph/mpsgraphtensor/3564663-datatype
MPSDataType.unorm1
MPSDataType.unorm8

Apple BNNS (Basic Neural Network Subroutines) - bnns_constants.h - https://github.com/alexey-lysiuk/macos-sdk/blob/6c1513f5b0667b76e24aaadcad130e90c545f046/MacOSX14.0.sdk/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/Headers/BNNS/bnns_constants.h#L33-L91
BNNSDataTypeIndexed2 - 2-bit unsigned indices into a floating point conversion table (4 values)
BNNSDataTypeIndexed4 - 4-bit unsigned indices into a floating point conversion table (16 values)
BNNSDataTypeIndexed8 - 8-bit unsigned indices into a floating point conversion table (256 values)

NumPy - https://numpy.org/devdocs/user/basics.types.html (https://numpy.org/doc/stable/user/basics.types.html)
numpy.longlong - long long
numpy.ulonglong - unsigned long long
numpy.float96 actually float80 with padding on x86
numpy.float128 actually float80 with padding on x86, true on SPARC
numpy.complex192 2x96 (or really 80 with padding)
numpy.complex256 2x128 (or really 80 with padding)
numpy.longdouble - long double, Platform-defined extended-precision float
numpy.clongdouble - long double complex, Complex number, represented by two extended-precision floats (real and imaginary components).

TensorFlow - https://www.tensorflow.org/api_docs/python/tf/dtypes
tensorflow.qint8 - Signed quantized 8-bit integer
tensorflow.qint16 - Signed quantized 16-bit integer
tensorflow.qint32 - signed quantized 32-bit integer
tensorflow.quint8 - Unsigned quantized 8-bit integer
tensorflow.quint16 - Unsigned quantized 16-bit integer

XNNPack - https://github.com/google/XNNPACK/blob/03d2a24b53f18103a2bb0f62e2c7123c5cea8890/include/xnnpack.h#L211-L232
xnn_datatype_qint8 - Quantized 8-bit signed integer with shared per-Value quantization parameters.
xnn_datatype_quint8 - Quantized 8-bit unsigned integer with shared per-Value quantization parameters.
xnn_datatype_qint32 - Quantized 32-bit signed integer with shared per-Value quantization parameters.
xnn_datatype_qcint8 - Quantized 8-bit signed integer with shared per-channel quantization parameters.
xnn_datatype_qcint32 - Quantized 32-bit signed integer with shared per-channel quantization parameters.
xnn_datatype_qcint4 - Quantized 4-bit signed integer with shared per-channel quantization parameters.
xnn_datatype_qdint8 - Dynamically quantized 8-bit signed integer with per-batch quantization parameters.
-xnn_datatype_fp32 - IEEE754 single-precision floating-point.
-xnn_datatype_fp16 - IEEE754 half-precision floating-point.

ANN - https://developer.android.com/ndk/reference/group/neural-networks#group___neural_networks_1ggaf06d1affd33f3bc698d0c04eceb23298ab275c740307fbffcfec94adcc7b374b9
ANEURALNETWORKS_TENSOR_QUANT16_ASYMM (uint16 elements, realValue = integerValue * scale
ANEURALNETWORKS_TENSOR_QUANT16_SYMM (int16) realValue = (integerValue - zeroPoint) * scale
ANEURALNETWORKS_TENSOR_QUANT8_ASYMM (uint8)
ANEURALNETWORKS_TENSOR_QUANT8_ASYMM_SIGNED (int8, scale and zp)
ANEURALNETWORKS_TENSOR_QUANT8_SYMM (int8, scale, no zp)
ANEURALNETWORKS_TENSOR_QUANT8_SYMM_PER_CHANNEL (int8) a channel axis and float scaleArray[channelDimensionLength]. realValue[..., C, ...] = integerValue[..., C, ...] * scales[C].
-->

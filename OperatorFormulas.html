<html>
<head>
<style>
body
{
  font-family: Calibri, Segoe UI, sans-serif;
  background-color: #FFFFFF;
}
table tr:nth-child(odd) td{
  background-color: #FFFFFF;
}
table tr:nth-child(even) td{
  background-color: #F8F8FF;
}
td
{
  white-space: pre; /*not pre-wrap;*/
  vertical-align: top;
}
 
 /* Hide expandable content by default */
.elementwiseOperator { visibility: collapse; }
.activationOperator { visibility: collapse; }
.reorganizationOperator { visibility: collapse; }
.poolingOperator { visibility: collapse; }
.controlFlowOperator { visibility: collapse; }
.reductionOperator { visibility: collapse; }
.normalizationOperator { visibility: collapse; }

/* visibility: collapse doesn't appear to work as expected for columns using Chrome. So use display: none instead. */
.webnnColumn { display: none; }
.onnxColumn { display: none; }
.dmlColumn { display: none; }
.xnnPackColumn { display: none; }
.stableHloColumn { display: none; }
.tosaColumn { display: none; }
.numpyColumn { display: none; }
.tensorFlowColumn { display: none; }
.pytorchColumn { display: none; }
.coreMlColumn { display: none; }
.bnnsColumn { display: none; }
.mpsColumn { display: none; }
.mlxColumn { display: none; }
.ncnnColumn { display: none; }
.cntkColumn { display: none; }
.futureColumn { display: none; }

/* Show hidden content when the checkbox is checked */
#toggleElementwiseOperators:checked ~ * .elementwiseOperator { visibility: visible; }
#toggleActivationOperators:checked ~ * .activationOperator { visibility: visible; } 
#toggleReorganizationOperators:checked ~ * .reorganizationOperator { visibility: visible; } 
#togglePoolingOperators:checked ~ * .poolingOperator { visibility: visible; } 
#toggleControlFlowOperators:checked ~ * .controlFlowOperator { visibility: visible; } 
#toggleReductionOperators:checked ~ * .reductionOperator { visibility: visible; }
#toggleNormalizationOperators:checked ~ * .normalizationOperator { visibility: visible; }

#toggleWebnnColumn:checked ~ * .webnnColumn { display: table-cell; }
#toggleOnnxColumn:checked ~ * .onnxColumn { display: table-cell; }
#toggleDmlColumn:checked ~ * .dmlColumn { display: table-cell; }
#toggleXnnPackColumn:checked ~ * .xnnPackColumn { display: table-cell; }
#toggleStableHloColumn:checked ~ * .stableHloColumn { display: table-cell; }
#toggleTosaColumn:checked ~ * .tosaColumn { display: table-cell; }
#toggleNumpyColumn:checked ~ * .numpyColumn { display: table-cell; }
#toggleTensorFlowColumn:checked ~ * .tensorFlowColumn { display: table-cell; }
#togglePytorchColumn:checked ~ * .pytorchColumn { display: table-cell; }
#toggleCoreMlColumn:checked ~ * .coreMlColumn { display: table-cell; }
#toggleBnnsColumn:checked ~ * .bnnsColumn { display: table-cell; }
#toggleMpsColumn:checked ~ * .mpsColumn { display: table-cell; }
#toggleMlxColumn:checked ~ * .mlxColumn { display: table-cell; }
#toggleNcnnColumn:checked ~ * .ncnnColumn { display: table-cell; }
#toggleCntkColumn:checked ~ * .cntkColumn { display: table-cell; }

</style>
</head>
<body>

<h1>Links</h1>
<a href="https://fdwr.github.io/LostOnnxDocs/MlFormulas.html">This document on GitHub</a><br/>
<a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md">ONNX Operators</a><br/>
<a href="https://docs.microsoft.com/en-us/windows/desktop/direct3d12/dml">DirectML</a><br/>
<a href="https://pytorch.org/docs/stable/torch.html">PyTorch Torch interface</a><br/>
<a href="https://pytorch.org/docs/stable/nn.html">PyTorch NN interface</a><br/>

<h1>Operator Equations</h1>

<p>Notation:
<li>Lowercase values are scalar. Uppercase are full tensors. So, x is scalar while X is a tensor, and abs(x) means it returns a scalar while Abs(X) returns a tensor.</li>
<li>Any multiplication signs '*' mean elementwise multiplication (per NumPy, PyTorch, TensorFlow).</li>
<li>Any matrix style compound dot product will explicitly use MatMul() rather than '*' to avoid unacceptable notation ambiguity.</li>
<li>Any addition signs '+' mean elementwise addition, never the horrible notation abuse of concatenation.</li>
<li>All exp() and log() use the natural logarithm 2.718281828 (not base 10 or 2).</li>
<li>The pseudocode below uses a few undefined functions, but their trivial behavior should be obvious to implement. e.g. min, max, ones, zeroes, iif, assert</li>
</p>

<input type="checkbox" id="toggleElementwiseOperators" checked="on"/><label for="toggleElementwiseOperators">Elementwise operators</label><br/>
<input type="checkbox" id="toggleActivationOperators" checked="on"/><label for="toggleActivationOperators">Activation operators</label><br/>
<input type="checkbox" id="toggleReorganizationOperators" checked="on"/><label for="toggleReorganizationOperators">Reorganization operators</label><br/>
<input type="checkbox" id="togglePoolingOperators" checked="on"/><label for="togglePoolingOperators">Pooling operators</label><br/>
<input type="checkbox" id="toggleReductionOperators" checked="on"/><label for="toggleReductionOperators">Reduction operators</label><br/>
<input type="checkbox" id="toggleNormalizationOperators" checked="on"/><label for="toggleNormalizationOperators">Normalization operators</label><br/>
<input type="checkbox" id="toggleControlFlowOperators" checked="on"/><label for="toggleControlFlowOperators">Control flow operators</label><br/>
<br/>
<input type="checkbox" id="toggleWebnnColumn" checked="on"/><label for="toggleWebnnColumn">WebNN (W3C <b>Web</b> <b>N</b>eural <b>N</b>etwork) <a href="https://www.w3.org/TR/webnn/">(info)</a></label><br/>
<input type="checkbox" id="toggleOnnxColumn" checked="on"/><label for="toggleOnnxColumn">ONNX (<b>O</b>pen <b>N</b>eural <b>N</b>etwork E<b>x</b>change) <a href="https://onnx.ai/">(info)</a> <a href="https://onnx.ai/onnx/operators/index.html">(ops)</a></label><br/>
<input type="checkbox" id="toggleDmlColumn" checked="on"/><label for="toggleDmlColumn">DirectML (Microsoft <b>Direct</b> <b>M</b>achine <b>L</b>earning) <a href="https://learn.microsoft.com/en-us/windows/ai/directml/dml-intro">(info)</a> <a href="https://learn.microsoft.com/en-us/windows/win32/api/directml/ne-directml-dml_operator_type">(ops)</a></label><br/>
<input type="checkbox" id="toggleXnnPackColumn" checked="on"/><label for="toggleXnnPackColumn">XNNPACK (Google <b>X</b> <b>N</b>eural <b>N</b>etwork <b>Pack</b>age) <a href="https://github.com/google/XNNPACK">(info)</a></label><br/>
<input type="checkbox" id="toggleStableHloColumn" checked="on"/><label for="toggleStableHloColumn">StableHLO (OpenXLA <b>Stable</b> <b>H</b>igh <b>L</b>evel <b>O</b>ptimizer) <a href="https://github.com/openxla/stablehlo/blob/main/docs/spec.md">(info)</a></label><br/>
<input type="checkbox" id="toggleTosaColumn" checked="on"/><label for="toggleTosaColumn">TOSA (ARM <b>T</b>ensor <b>O</b>perator <b>S</b>et <b>A</b>rchitecture) <a href="https://mlir.llvm.org/docs/Dialects/TOSA/">(info)</a></label><br/>
<input type="checkbox" id="toggleNumpyColumn" checked="on"/><label for="toggleNumpyColumn">NumPy (<b>Num</b>erical <b>Py</b>thon) <a href="https://numpy.org/">(info)</a> <a href="https://numpy.org/doc/stable/reference/routines.html">(ops)</a></label><br/>
<input type="checkbox" id="toggleTensorFlowColumn" checked="on"/><label for="toggleTensorFlowColumn">TensorFlow (Google's TensorFlow) <a href="https://www.tensorflow.org/">(info)</a></label><br/>
<input type="checkbox" id="togglePytorchColumn" checked="on"/><label for="togglePytorchColumn">PyTorch (<b>Py</b>thon <b>Torch</b>, originally by Meta) <a href="https://pytorch.org/">(info)</a> <a href="https://pytorch.org/docs/stable/torch.html">(ops)</a></label><br/>
<input type="checkbox" id="toggleCoreMlColumn" checked="on"/><label for="toggleCoreMlColumn">CoreML (Apple <b>Core</b> <b>M</b>achine <b>L</b>earning) <a href="https://developer.apple.com/machine-learning/core-ml/">(info)</a> <a href="https://apple.github.io/coremltools/mlmodel/Format/NeuralNetwork.html">(ops)</a></label><br/>
<input type="checkbox" id="toggleBnnsColumn" checked="on"/><label for="toggleBnnsColumn">BNNS (Apple <b>B</b>asic <b>N</b>eural <b>N</b>etwork <b>S</b>ubroutines) <a href="https://developer.apple.com/documentation/accelerate/bnns">(info)</a></label><br/>
<input type="checkbox" id="toggleMpsColumn" checked="on"/><label for="toggleMpsColumn">MPS (Apple <b>M</b>etal <b>P</b>erformance <b>S</b>haders) <a href="https://developer.apple.com/documentation/metalperformanceshaders">(info)</a></label><br/>
<input type="checkbox" id="toggleMlxColumn" checked="on"/><label for="toggleMlxColumn">MLX (Apple <b>M</b>achine <b>L</b>earning E<b>x</b>plore) <a href="https://ml-explore.github.io/mlx/build/html/python/ops.html">(info)</a></label><br/>
<input type="checkbox" id="toggleNcnnColumn" checked="on"/><label for="toggleNcnnColumn">NCNN (<b>T</b>en<b>c</b>ent <b>N</b>eural <b>N</b>etwork) <a href="https://github.com/Tencent/ncnn/">(info)</a> <a href="https://github.com/Tencent/ncnn/blob/54a9a563e9913d3142782dac0e497f2be50075b5/docs/developer-guide/operators.md">(ops)</a></label><br/>
<input type="checkbox" id="toggleCntkColumn" checked="on"/><label for="toggleCntkColumn">NCNN (Microsoft <b>C</b>og<b>n</b>itive <b>T</b>ool<b>k</b>it) <a href="https://github.com/microsoft/CNTK">(info)</a> <a href="https://microsoft.github.io/CNTK-R/reference/index.html">(ops)</a></label><br/>


<table border=1 cellspacing=0 cellpadding=1 style='border-collapse:collapse; border:none'>
  <tr>
    <th style="width:15em">Categories</th>
    <th>Name</th>
    <th class="webnnColumn">WebNN</th>
    <th class="onnxColumn">ONNX</th>
    <th class="dmlColumn">DML</th>
    <th class="xnnPackColumn">XNNPACK</th>
    <th class="stableHloColumn">StableHLO</th>
    <th class="tosaColumn">TOSA</th>
    <th class="numpyColumn">NumPy</th>
    <th class="tensorFlowColumn">TensorFlow</th>
    <th class="pytorchColumn">PyTorch</th>
    <th class="coreMlColumn">CoreML</th>
    <th class="bnnsColumn">BNNS</th>
    <th class="mpsColumn">MPS</th>
    <th class="mlxColumn">MLX</th>
    <th class="ncnnColumn">NCNN</th>
    <th class="cntkColumn">CNTK</th>
    <th class="futureColumn">(for future additions)</th>
    <th valign="top">Formula</th>
    <th>Precision</th>
  </tr>
  <tr>
    <td>Generic</td>
    <td>Identity</td>
    <td class="webnnColumn">identity</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Identity">Identity</a></th>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY or
DML_ACTIVATION_IDENTITY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">stablehlo.optimization_barrier</td>
    <td class="tosaColumn">tosa.identity</td>
    <td class="numpyColumn">numpy.identity</td>
    <td class="tensorFlowColumn">tf.identity</td>
    <td class="pytorchColumn">torch.nn.Identity</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>Identity(X) = X</code></td>
    <td>Exact</td>
  </tr>
  <tr>
    <td>Input</td>
    <td>Constant</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Constant">Constant</a></td>
    <td class="dmlColumn">NA just provide the tensor data</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>Constant() = Value</code></td>
    <td>Exact</td>
  </tr>
  <tr>
    <td>Input</td>
    <td>Constant Of Shape</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#ConstantOfShape">ConstantOfShape</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY with zero strides to broadcast</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>ConstantOfShape(scalarTensorValue, inputOfDesiredShape) = Expand(scalarTensorValue, Shape(inputOfDesiredShape))</code></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Add</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Add">Add</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ADD</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x, y) = x + y</code></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Subtract</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sub">Sub</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SUBTRACT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x, y) = x - y</code></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Multiply</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mul">Mul</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MULTIPLY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x, y) = x * y</code></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Divide</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Div">Div</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_DIVIDE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x, y) = x / y</code></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Reciprocal</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Reciprocal">Reciprocal</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_RECIP</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x) = 1 / x</code></td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Modulus Truncate</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mod">Mod fmod=0</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MODULUS_TRUNCATE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x, y) = x - (y * floor(x / y)) // Result sign follows the divisor sign.</code></td>
    <td>2 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Modulus Floor</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mod">Mod fmod=1</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MODULUS_FLOOR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x, y) = x - (y * trunc(x / y)) // Result sign follows the dividend sign.</code></td>
    <td>2 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Power</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pow">Pow</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_POW</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x, exponent) = pow(x, exponent)</code></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Root</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX NA</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_RECIP & POW</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x, y) = root(x, exponent) // pow(x, 1/2)</code></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Square root</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sqrt">Sqrt</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SQRT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x) = sqrt(x) // pow(x, 1/2)</code></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Expnonent</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Exp">Exp</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_EXP</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x) = expₑ(x) // pow(2.71828, x)</code></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Logarithm</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Log">Log</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOG</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x) = logₑ(x) // log(x, 2.71828), log(exp(x)) == x</code></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Absolute</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Abs">Abs</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ABS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x) = abs(x)</code></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Negative</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Neg">Neg</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY with scale = -1</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x) = -x</code></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Ceiling</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Ceil">Ceil</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_CEIL</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x) = ceil(x)</code></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Floor</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Floor">Floor</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_FLOOR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x) = floor(x)</code></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Clamp</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Clip">Clip</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_CLIP</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x) = clamp(x, min, max)</code></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Error Function</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Erf">Erf</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ERF</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>erf(x) = 1/sqrt(pi) * integrate(i = -x to x, e ^ -(i^2))</code>
or: <code>erf(x) = 2/sqrt(pi) * integrate(i = 0 to x, e ^ -(i^2))</code>
<code>
double f(double x)
{
    // Polynomial approximation constants.
    double a1 =  0.254829592;
    double a2 = -0.284496736;
    double a3 =  1.421413741;
    double a4 = -1.453152027;
    double a5 =  1.061405429;
    double p  =  0.3275911;

    // Save the sign of x.
    int sign = 1;
    if (x &lt; 0) sign = -1;
    x = fabs(x);

    // Approximate the formula A&S 7.1.26:
    // 2/sqrt(pi) * integrate(i = 0 to x, e ^ -(i^2))
    double t = 1.0/(1.0 + p*x);
    double y = 1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1) * t*expₑ(-x*x);
    return sign * y;
}</code></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Is Not a Number</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#IsNaN">IsNan</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IS_NAN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = isnan(x)
      where isnan(float32 x): return (reinterpret_cast(x, uint32_t) & 0x7FFFFFFF) &gt; 0x7F800000.
      Any float32 value with all 1's for exponent and a nonzero mantissa is <a href="https://en.wikipedia.org/wiki/NaN">NaN</a>. The sign is ignored.
      e.g. s1111111 10000000 0000000 00000001 - float32
      e.g. s1111100 00000001 - float16</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Is Infinity</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.5.0/docs/Operators.md#IsInf">IsInf</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IS_INFINITY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>output.shape = input.shape
for every coordinate in input tensor
    hasExpectedSign = iif(input[coordinate] &gt; 0, detect_positive, detect_negative)
    output[coordinate] = isinf(input[coordinate]) && hasExpectedSign
    // or test that all exponent bits are one and all mantissa bits are 0:
    // (input value & 0x7FFFFFFF) == 0x7F800000
endfor
</code></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Sign</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Sign">Sign</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SIGN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>function Sign(x)
    if x == 0 then 0
    elif x &gt; 0 then 1
    elif x &lt; 0 then -1
endfunction</code></td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math (Deleted)</td>
    <td>Scale Signal</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.0/docs/Operators.md#Scale">Scale</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MULTIPLY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Mul(X, scale)
      or: f(x) = x * scale</td>
    <td>1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math (Deleted)</td>
    <td>Image Scaler</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#ImageScaler">ImageScaler</a></td>
    <td class="dmlColumn">DML_OPERATOR_VALUE_SCALE_2D</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Add(Mul(X, scale), Unsqueeze(biasTensor, [0, 2, 3])) // reshape bias to [1,C,1,1]
      or: f(x, scale, bias) = x * scale + bias</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Equals</td>
    <td class="webnnColumn">equals</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Equal">Equal</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_EQUALS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = (x == y)</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Greater</td>
    <td class="webnnColumn">greater</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Greater">Greater</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_GREATER_THAN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = (x &gt; y)</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Lesser</td>
    <td class="webnnColumn">lesser</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Less">Less</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_LESS_THAN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = (x &lt; y)</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Greater or Equal</td>
    <td class="webnnColumn">greaterOrEqual</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GreaterOrEqual">GreaterOrEqual</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_GREATER_THAN_OR_EQUAL</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = (x &gt; y)</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Comparison</td>
    <td>Lesser or Equal</td>
    <td class="webnnColumn">lesserOrEqual</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LessOrEqual">LessOrEqual</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_LESS_THAN_OR_EQUAL</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = (x &lt; y)</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Bitwise</td>
    <td>Bitwise Not</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseNot">BitwiseNot</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_NOT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">LogicalNotLayerParams</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = ~x</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Bitwise</td>
    <td>Bitwise And</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseAnd">BitwiseAnd</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_AND</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = x &amp; y</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Bitwise</td>
    <td>Bitwise Or</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseOr">BitwiseOr</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_OR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = x | y</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Bitwise</td>
    <td>Bitwise Xor</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseXor">BitwiseXor</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_XOR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = x ^ y</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Bitwise</td>
    <td>Bitwise Left Shift</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseXor">BitShift</a> direction = LEFT</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_SHIFT_LEFT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = x &lt;&lt; y</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Bitwise</td>
    <td>Bitwise Right Shift</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitwiseXor">BitShift</a> direction = RIGHT</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_SHIFT_Right</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = x &gt;&gt; y</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Bitwise</td>
    <td>Bitwise Count</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">NA</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_BIT_COUNT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = add one to count for each set bit in x</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Logical</td>
    <td>Logical Not</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Not">Not</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_NOT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">LogicalNotLayerParams</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = !x</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Logical</td>
    <td>Logical And</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#And">And</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_AND</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = x &amp;&amp; y</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Logical</td>
    <td>Logical Or</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Or">Or</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_OR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = x || y</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Logical</td>
    <td>Logical Xor</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Xor">Xor</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_LOGICAL_XOR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y) = !!x xor !!y</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Sine</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sin">Sin</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SIN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = sin(x)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Cosine</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Cos">Cos</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_COS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = cos(x)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Tangent</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Tan">Tan</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_TAN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = tan(x)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Arcsine</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Asin">Asin</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ASIN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = asin(x)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Arccosine</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Acos">Acos</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ACOS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = acos(x)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Arctangent</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Atan">Atan</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ATAN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = atan(x)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Sine</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Sinh">Sinh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SINH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = sinh(x)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Cosine</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Cosh">Cosh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_COSH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = cosh(x)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Tangent</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Tanh">Tanh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_TANH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = tanh(x)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Arccosine</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Acosh">Acosh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ACOSH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = arccosh(x)
      or: logₑ(x + sqrt(x * x - 1))</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Arccosine</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Asinh">Asinh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ASINH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = arcsinh(x)
      or: logₑ(x + sqrt(x * x + 1))</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>Hyperbolic Arccosine</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Atanh">Atanh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ATANH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = arctanh(x)
      or: logₑ((1 + x) / (1 - x)) / 2</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Trigonometric</td>
    <td>CosineGrad</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">Composed</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_SIN &
DML_OPERATOR_ELEMENT_WISE_MULTIPLY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(Dx, X) = Mul(Sin(X), Dx)
      f(dx, x) = sin(x) * dx</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Reduction</td>
    <td>Sum</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sum">Sum</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ADD via repeated inputs</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y, z…) = x + y + z…</td>
    <td>&lt; N-1 ULP</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Reduction</td>
    <td>Mean</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mean">Mean</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MEAN via repeated inputs</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y, z…) = (x + y + z…) / n</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Reduction</td>
    <td>Maximum</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Max">Max</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MAX via repeated inputs</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y, z…) = max(x, y, z…)</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math</td>
    <td>Threshold</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Max">Max</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_THRESHOLD</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X, minValue) = Max(X, minValue)
      or: f(x) = max(x, minValue)
      notes: Not equivalent to ThresholdedRelu.</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Reduction</td>
    <td>Minimum</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Min">Min</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_MIN via repeated inputs</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, y, z…) = min(x, y, z…)</td>
    <td>Exact</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Quantization</td>
    <td>Quantize Linear</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#QuantizeLinear">QuantizeLinear</a><br/>com.microsoft QuantizeLinear</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_QUANTIZE_LINEAR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(input:float32, scale:float32, zero_point:int32)
      return output:uint8 = clamp(round(input / scale) + zero_point, 0, 255)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Elementwise Math Quantization</td>
    <td>Dequantize Linear</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#DequantizeLinear">DequantizeLinear</a><br/>com.microsoft DequantizeLinear</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_DEQUANTIZE_LINEAR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(input:uint8, scale:float32, zero_point:float32)
      return output:float32 = (input - zero_point) * scale</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Sigmoid</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Sigmoid">Sigmoid</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SIGMOID</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Reciprocal(Add(1, Exp(Neg(X))))
      or: f(x) = 1 / (1 + expₑ(-x))
      or: f(x) = expₑ(x) / (1 + expₑ(x))</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Hard Sigmoid</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#HardSigmoid">HardSigmoid</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_HARD_SIGMOID</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Clip(Add(Mul(alpha, X), beta), 0, 1)
      or: f(x) = max(0, min(alpha * x + beta, 1))
      defaults: alpha = 0.2, beta = 0.5</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Hyperbolic Tangent</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Tanh">Tanh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_TANH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Div(Sub(1, Exp(Mul(X, -2)), Add(1, Exp(X, -2)))
      or: f(x) = (1 - expₑ(-2 * x))/(1 + expₑ(-2 * x))
      or: f(x) = 2 /(1 + expₑ(-2 * x)) - 1
      or: f(x) = (expₑ(x) - expₑ(-x)) / (expₑ(x) + expₑ(-x))</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Scaled Hyperbolic Tangent</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#ScaledTanh">ScaledTanh</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SCALED_TANH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X, alpha, beta) = Mul(Tanh(Mul(X, beta)), alpha)
      or: f(x, alpha, beta) = alpha * tanh(beta * x)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Clamp Positive (Rectified Linear Unit)</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Relu">Relu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_RELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Max(X, 0)
      or: f(x) = max(x, 0)
      or: if x &gt;= 0 then x else 0</td>
    <td>Exact</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Leaky Rectified Linear Unit</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LeakyRelu">LeakyRelu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_LEAKY_RELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Where(Less(X, 0), Mul(X, alpha), X)
      or: f(x, alpha) = if x &gt;= 0 then x else alpha * x</td>
    <td>&lt;= Mul precision</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Parameterized Rectified Linear Unit</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#PRelu">PRelu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_PARAMETERIZED_RELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Where(Less(X, 0), Mul(X, Slope), X)
      or: f(x, slope) = if x &gt;= 0 then x else slope * x
      PRelu and LeakyRelu are identical, except one slope is an input tensor and one slope is a constant.</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Thresholded Rectified Linear Unit</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ThresholdedRelu">ThresholdedRelu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_THRESHOLDED_RELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X, alpha = 1) = Where(Greater(X, alpha), X, 0)
      f(x) = if x &gt; alpha then x else 0</td>
    <td>Exact</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Exponential Linear Unit</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Elu">Elu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_ELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X, alpha = 1) = Where(Less(X, 0), Mul(Sub(Exp(X), 1), alpha))
      or: F(X, alpha = 1) = Add(Clip(X, 0, inf), Clip(Mul(Sub(Exp(X), 1), alpha), -inf, 0))
      or: f(x, alpha = 1) = if x &gt;= 0 then x else alpha * (expₑ(x) - 1)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Scaled Exponential Linear Unit</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Selu">Selu</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SCALED_ELU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X, alpha = 1.6732, gamma = 1.0507) = Mul(Elu(X, alpha), gamma)
      or: f(x, alpha = 1.6732, gamma = 1.0507):
      if x &gt; 0 then gamma * x
      else gamma * alpha * (expₑ(x) - 1)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator normalizationOperator">
    <td>Activation / Normalization</td>
    <td>Soft Maximum</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softmax">Softmax</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SOFTMAX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Raise all elements to e, and divide all the elements in each batch by that batch's sum.
<code>function SoftMax2D(Input; Output; axis):
  MaxInput = ReduceMax(Input, axes=[1], keepdims=1)
  ExpInput = Exp(Input - MaxInput)
  ReducedExpInput = ReduceSum(ExpInput, axis=[1], keepdims=1)
  Output = ExpInput / ReducedExpInput
endfunction

function F(Input; Output; axis):
  FlattenedInput = Flatten(Input, axis) // Flatten to 2D
  NormalizedInput = SoftMax2D(FlattenedInput)
  Output = Reshape(NormalizedInput, Shape(X))
endfunction
</code>

    or per batch: f(x) = expₑ(x) / sum(expₑ(X))
    or per batch for more numerical stability: expₑ(x - max(X)) / sum(expₑ(x - max(X)))</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Log Soft Maximum</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LogSoftmax">LogSoftmax</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_LOG_SOFTMAX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(Input, axis) = Log(Softmax(Input, axis))
  or: f(x) = logₑ(expₑ(x - max(X)) / sum(expₑ(X - max(X))))
  or: (x - max(X)) - logₑ(x - max(X))))</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Hard Maximum</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Hardmax">Hardmax</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_HARDMAX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = if x_i == max(X) then 1 else 0
      *but only for first element along that axis</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Soft Sign</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softsign">Softsign</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SOFTSIGN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Div(X, Add(Abs(X), 1))
      or: f(x) = x / (1 + abs(x))</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Softplus</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Softplus">Softplus</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SOFTPLUS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Log(Add(Exp(x), 1))
      or: f(x) = logₑ(1 + expₑ(x))</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Affine</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#Affine">Affine</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY
    with scale and bias
DML_OPERATOR_ACTIVATION_LINEAR</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X, alpha, beta) = Add(Mul(X, alpha), beta)
  or: f(x, alpha, beta) = alpha * x + beta</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation</td>
    <td>Symmetric signal shift</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#shrink">Shrink</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_SHRINK</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x, lambda, bias):
      if x &lt; -lambda then y = x + bias
      elif x &gt; lambda then y = x - bias
      else y = 0</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="activationOperator">
    <td>Activation (Deleted)</td>
    <td>Parametric Softplus</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#ParametricSoftplus">ParametricSoftplus</a></td>
    <td class="dmlColumn">DML_OPERATOR_ACTIVATION_PARAMETRIC_SOFTPLUS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X, alpha, beta) = Mul(alpha, Softplus(Mul(beta, X))).
      or: f(x, alpha, beta) = alpha * logₑ(1 + expₑ(beta * x))
  </td>
    <td>Precision TBD</td>
  </tr>
 <tr>
    <td>Generation Random</td>
    <td>Random Normal</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomNormal">RandomNormal</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(scale, mean) = <a href="https://en.wikipedia.org/wiki/Marsaglia_polar_method">MarsagliaPolarTransform</a>(random(), random()) * scale + mean</td>
    <td>Unpredictable</td>
  </tr>
 <tr>
    <td>Generation Random</td>
    <td>Random Normal Like</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomNormalLike">RandomNormalLike</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(scale, mean) = <a href="https://en.wikipedia.org/wiki/Marsaglia_polar_method">MarsagliaPolarTransform</a>(random(), random()) * scale + mean</td>
    <td>Unpredictable</td>
  </tr>
 <tr>
    <td>Generation Random</td>
    <td>Random Uniform</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomUniform">RandomUniform</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(low, high): // see MT19937
      range = high - low // note inclusive end
      if integer: return (rand() % (range+1) + low 
      if float: (rand() / randmax) * range + low</td>
    <td>Unpredictable</td>
  </tr>
 <tr>
    <td>Generation Random</td>
    <td>Random Uniform Normal</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#RandomUniformLike">RandomUniformLike</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(low, high): // see MT19937
      range = high - low // note inclusive end
      if integer: return (rand() % (range+1) + low 
      if float: (rand() / randmax) * range + low</td>
    <td>Unpredictable</td>
  </tr>
 <tr>
    <td>Generation Random</td>
    <td>Random Multinomial</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Multinomial">Multinomial</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>TODO:</td>
    <td>Unpredictable</td>
  </tr>
 <tr>
    <td>Generation Matrix Multiplication</td>
    <td>Diagonal Matrix</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#EyeLike">EyeLike</a></td>
    <td class="dmlColumn">DML_OPERATOR_DIAGONAL_MATRIX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Notes: set 1's all along diagonal. In other words, all output[i, i+k] = 1, and every other element = 0.<code>
output.shape = input.shape
output.type = if exists(dtype) then dtype else input.type
function EyeLike(input, k=0):
    for each coordinate in output tensor
        output[coordinate] = if coordinate.h + k == coordinate.w then 1 else 0
    endfor
endfunction</code></td>
    <td>Exact</td>
  </tr>
 <tr>
    <td>Matrix Multiplication</td>
    <td>Generic Matrix Multiplication</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Gemm">Gemm</a></td>
    <td class="dmlColumn">DML_OPERATOR_MATRIX_GEMM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(A, B, C; alpha, beta, transA, transB; Y):
      A2 = If(transA, Transpose(A), A)
      B2 = If(transB, Transpose(B), B)
      Y = Add(Mul(alpha, MatMul(A2, B2)), Mul(beta, C))</td>
    <td>Precision TBD</td>
  </tr>
 <tr>
    <td>Matrix Multiplication</td>
    <td>Matrix Multiplication</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MatMul">MatMul</a></td>
    <td class="dmlColumn">DML_OPERATOR_MATRIX_GEMM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>for i=0..&lt;h do for j=0..&lt;w do y[i,j] = dot(A[i,0..w], B[0..h,j])
      It's essentially a ReduceSum(Mul(A.row, B.column)) per output element.
      notes: A and B can be 1D vectors, which are treated as [1,W] and [H,1] matrices. A and B can have batch count dimensions, where each 2D matrix is multiplied separately. The batch count can be broadcast too.</td>
    <td>Precision TBD</td>
  </tr>
 <tr>
    <td>Matrix Multiplication</td>
    <td>Convolve</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv">Conv</a></td>
    <td class="dmlColumn">DML_OPERATOR_CONVOLUTION 
    with DML_CONVOLUTION_MODE_CROSS_CORRELATION
    and DML_CONVOLUTION_DIRECTION_FORWARD</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Every output element is the convolution of the filter with the corresponding input elements.
  <code>out[j] = (x[i]*w[0]) + (x[i+1]*w[1]) + (x[i+2]*w[2]) + ... + (x[i+k]*w[k]) + b</code>
      notes: 'steps' affects the size of steps over the input.
      'dilations' affects the step of the filter, as if the filter had been resized with interceding zeroes between elements.
      A dilation of 1 means no change (1:1 with filter), whereas dilation of 2 inserts lines of zeros between every filter line.
      'pads' are not actually added to the input, just virtually treated as if zeros. <a href="https://github.com/vdumoulin/conv_arithmetic">vdumoulin convolution diagrams</a>
<code>
function Convolve(input, filterWeights, dilations, strides, kernel_shape, pads; output)
    startPads = pads[0..pads.size/2]
    endPads = pads[pads.size/2..pads.size]
    // todo: compute output size
    // output.shape = (input.shape + startPads + endPads) // todo: consider strides and kernel size
    for each outputCoordinate in output
        output[outputCoordinate] = ConvolveKernel(input, filterWeights, outputCoordinate * strides - startPads, dilations)
    endfor
endfunction

function ConvolveKernel(input, filterWeights, firstInputCoordinate, dilations)
    // 2D example only todo:Figure out what 'group' does and what 'M' is?
    result = 0
    // todo: How do 'M' and 'C' factor into this?
    for y=0..&lt;filterWeights.shape[2]
        for x=0..&lt;filterWeights.shape[3]
            inputCoordinate = firstInputCoordinate + ([y,x] * dilations)
            if (input.contains(inputCoordinate)) // check coordinates within tensor
                result += filterWeights[y,x] * input[inputCoordinate]
            endif
        endfor // x
    endfor // y
    return result
endfunction
</code></td>
    <td>Precision TBD</td>
  </tr>
 <tr>
    <td>Matrix Multiplication</td>
    <td>Convolve Tranposed</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose">ConvTranspose</a></td>
    <td class="dmlColumn">DML_OPERATOR_CONVOLUTION
    with DML_CONVOLUTION_MODE_CROSS_CORRELATION
    and DML_CONVOLUTION_DIRECTION_BACKWARD</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>todo: Here be dragons.
      questions: What is the difference between CONVOLUTION vs CORRELATION enum, and FORWARD vs BACKWARD?</td>
    <td>Precision TBD</td>
  </tr>
 <tr>
    <td>Data Conversion</td>
    <td>Cast</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Cast">Cast</a></td>
    <td class="dmlColumn">DML_OPERATOR_CAST</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(x) = cast(x)</td>
    <td>&lt; 1 ULP</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Transpose</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Transpose">Transpose</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY with
    TENSOR_DESC that flips via permuted strides</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Reorder axes, such as X Y -&gt; Y X, or X Y Z -&gt; Z X Y.
<code>
function Transpose(input, perm):
    N = input.rank
    assert(perm.size == input.rank)
    for i=0..&lt;N do output.shape[i] = input.shape[perm[i]]
    for each inputCoordinate in input
        for i=0..&lt;N do outputCoordinate[i] = inputCoordinate[perm[i]]
        output[outputCoordinate] = input[inputCoordinate]
    endfor
endfunction</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Broadcast</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#Expand">Expand</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY with
    TENSOR_DESC using zero strides along broadcast dimension</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Broadcast any single size dimensions up to the output dimension counts.
Similar to <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.broadcast_to.html">NumPy broadcast_to</a>.
<code>
function Broadcast(input, shape)
    output.shape = BroadcastShape(input.shape, shape)
    N = output.rank
    inputShape = PadLeadingValues(input.shape, N, 1)
    for each outputCoordinate in output
        for i=0..&lt;N do inputCoordinate[i] = iif(inputShape[i] &gt; 1), outputCoordinate[i], 0)
        output[outputCoordinate] = inputData[inputCoordinate]
    endfor
endfunction</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>BroadcastShape</td>
    <td class="webnnColumn">NA</td>
    <td class="onnxColumn">NA</td>
    <td class="dmlColumn">NA</td>
    <td class="xnnPackColumn">NA</td>
    <td class="stableHloColumn">NA</td>
    <td class="tosaColumn">NA</td>
    <td class="numpyColumn">NA</td>
    <td class="tensorFlowColumn">NA</td>
    <td class="pytorchColumn">NA</td>
    <td class="coreMlColumn">NA</td>
    <td class="bnnsColumn">NA</td>
    <td class="mpsColumn">NA</td>
    <td class="mlxColumn">NA</td>
    <td class="ncnnColumn">NA</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Helper to compute the broadcasted output shape (1D tensor) from multiple input shapes.
Any single size dimensions are stretched to the output dimension size.
<code>
function BroadcastShape(shapes...)
    N = 0
    for each shape in shapes do N = max(N, shape.size) // Determine the largest rank in shapes
    broadcastedShape = ones(N) // [1,1,...]
    for each shape in shapes // Take the max of all shape dimensions.
        paddedShape = PadLeadingValues(shape, N, 1) // Right align. e.g. N=4 with [H,W] -&gt; [1,1,H,W]
        for i=0..&lt;N do
            assert(paddedShape[i] == broadcastedShape[i] || paddedShape[i] == 1 || broadcastedShape[i] == 1))
            broadcastedShape[i] = max(broadcastedShape[i], paddedShape[i])
        endfor
    endfor
    return broadcastedShape
endfunction

function PadLeadingValues(shape, paddedSize, padValue)
    // Right align. e.g. shape=[H,W], paddedSize=4, padValue=1 -&gt; [1,1,H,W]
    paddedSize = max(padddedSize, shape.size)
    padCount = paddedSize - shape.size
    for i=0..&lt;paddedSize
        paddedShape[i] = i &lt; padCount ? padValue : shape[i - padCount]
    endfor
    return paddedShape
endfunction</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Tile</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Tile">Tile</a></td>
    <td class="dmlColumn">DML_OPERATOR_TILE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Repeat entire tensor along each axis by repeat counts.
<code>
function Tile(input, repeats)
    N = input.rank
    assert(repeats.size == input.rank)
    for i=0..&lt;N do assert(repeats[i] &gt; 0)
    output.shape = input.shape * repeats // elementwise multiply per axis
    for each outputCoordinate in output
        for i=0..&lt;N do inputCoordinate[i] = outputCoordinate[i] % input.shape[i]
        output[outputCoordinate] = inputData[inputCoordinate]
    endfor
endfunction</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Split</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Split">Split</a></td>
    <td class="dmlColumn">DML_OPERATOR_SPLIT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Split input into multiple output tensors.</td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Slice</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Slice">Slice</a></td>
    <td class="dmlColumn">DML_OPERATOR_SLICE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Crop the tensor to the given ranges for each axis.
<code>function Slice(input, starts, ends, axes, steps)
    N = input.rank
    if axes.empty then axes = arange(0, N-1) // [0,1,2,...]
    if starts.empty then starts = zeroes(N) // [0,0,0,...]
    if ends.empty then ends = input.shape
    if steps.empty then steps = ones(N) // [1,1,1,...]
    assert(axes.size == input.rank || axes.size == 0)
    assert(starts.size == axes.size)
    assert(ends.size == axes.size)
    assert(steps.size == axes.size)
    starts = max(starts, zeroes(N))
    ends = min(ends, input.shape)
    ends = max(ends, starts)

    for i=0..&lt;N do output.shape[i] = ceil((ends[i] - starts[i]) / steps[i]) // negative steps unhandled!
    for each outputCoordinate in output
        for i=0..&lt;N do inputCoordinate[i] = outputCoordinate[i] * steps[i] + starts[i]
        output[outputCoordinate] = inputData[inputCoordinate]
    endfor
endfunction</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization (Deleted)</td>
    <td>Crop</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#experimental-crop">Crop</a> (ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Slice">Slice</a> subset)?</td>
    <td class="dmlColumn">DML_OPERATOR_SLICE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Crop the tensor to the given ranges for each axis. Crop is confusing and redundant. Just use Slice.</td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Contenate</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Concat">Concat</a></td>
    <td class="dmlColumn">DML_OPERATOR_JOIN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Combine multiple tensors into large output tensor. e.g. {1,2,3} with {4,5} -&gt; {1,2,3,4,5}
<code>function Concat(inputs, axis)
    sizesAlongAxis = []
    for each input in inputs
        sizesAlongAxis.append(input.shape[axis])
    endfor
    outputOffsets = CumSum(axisSizes)
    for each inputIndex from 0 up to inputs.count
        input = inputs[inputIndex]
        outputOffset = outputOffset[inputIndex]
        for each index from 0 up to axis
            output[..., outputOffset + index, ...] = input[..., index, ...]
        endfor
    endfor
</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Gather</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Gather">Gather</a></td>
    <td class="dmlColumn">DML_OPERATOR_GATHER</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>TODO:</td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Gather Elements</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherElements">GatherElements</a></td>
    <td class="dmlColumn">DML_OPERATOR_GATHER_ELEMENTS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn"><a href="https://pytorch.org/docs/stable/torch.html#torch.gather">torch.gather</a></td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Return output tensor the same size as indices, filling with values from input indexed along the axis by indices.
<code>
output = input
for each coordinate in indices tensor
    inputCoordinate = coordinate
    inputCoordinate[axis] = indices[coordinate]
    output[coordinate] = input[inputCoordinate]
endfor

output[i][j][k] = input[ index[i][j][k] ][j][k]  # if dim == 0
output[i][j][k] = input[i][ index[i][j][k] ][k]  # if dim == 1
output[i][j][k] = input[i][j][ index[i][j][k] ]  # if dim == 2
</code>

e.g.
<code>
input = [1,2,3,4,5,6]
indices = [0,0,1,5]
axis = 0
output = [1,1,2,6]

e.g.
input = [[1,2],[3,4],[5,6]]
indices = [[0,0],[1,0],[1,1]]
axis = 1
output = [[1,1], [4,3], [6,6]]
</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Gather Multidimensional</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherND">GatherND</a></td>
    <td class="dmlColumn">DML_OPERATOR_GATHER_ND</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>TODO</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Scatter Elements</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.6.0/docs/Operators.md#ScatterElements">ScatterElements</a><br/><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.scatter_">torch.tensor.scatter_</a></td>
    <td class="dmlColumn">DML_OPERATOR_SCATTER_ELEMENTS</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Opposite of gather. Write values from updates into data at the given indices. If two output element indices overlap, there is no documented winner, but last write wins in practice.
<code>
output = input
for each coordinate in indices tensor
    outputCoordinate = coordinate
    outputCoordinate[axis] = indices[coordinate]
    output[outputCoordinate] = updates[coordinate]
endfor

output[ index[i][j][k] ][j][k] = input[i][j][k]  # if dim == 0
output[i][ index[i][j][k] ][k] = input[i][j][k]  # if dim == 1
output[i][j][ index[i][j][k] ] = input[i][j][k]  # if dim == 2
</code>

<code>
      e.g.
      data = [[1, 2, 3, 4, 5]] // data == input
      indices = [[1, 3]]
      updates = [[11, 21]]
      axis = 0
      output = [[1, 11, 3, 21, 5]]
</code>
  </td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization</td>
    <td>Scatter ND</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.6.0/docs/Operators.md#ScatterND">ScatterND</a></td>
    <td class="dmlColumn">DML_OPERATOR_SCATTER_ND</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>TODO</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Pad</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Pad">Pad</a></td>
    <td class="dmlColumn">DML_OPERATOR_PADDING</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Inflate the input with zeroes on the edges</td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Space To Depth</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#SpaceToDepth">SpaceToDepth</a></td>
    <td class="dmlColumn">DML_OPERATOR_SPACE_TO_DEPTH</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Rearrange blocks of elements.
<code>
channelCountDivBlockCount = channelCount / (blockSize * blockSize);
inputIndices = [
    outputIndices.batch,
    outputIndices.channel % channelCountDivBlockCount,
    (outputIndices.channel / channelCountDivBlockCount) / blockSize + (outputIndices.height * blockSize),
    (outputIndices.channel / channelCountDivBlockCount) % blockSize + (outputIndices.width  * blockSize)
]

output[outputIndices] = input[inputIndices];</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Depth To Space</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#DepthToSpace">DepthToSpace</a></td>
    <td class="dmlColumn">DML_OPERATOR_DEPTH_TO_SPACE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Rearrange blocks of elements.
<code>
channelCountDivBlockCount = channelCount / (blockSize * blockSize);
outputIndices = [
    inputIndices.batch,
    inputIndices.channel % channelCountDivBlockCount,
    (inputIndices.channel / channelCountDivBlockCount) / blockSize + (inputIndices.height * blockSize),
    (inputIndices.channel / channelCountDivBlockCount) % blockSize + (inputIndices.width  * blockSize)
]

output[outputIndices] = input[inputIndices];</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Shape</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Shape">Shape</a></td>
    <td class="dmlColumn">NA, just read the TENSOR_DESC dimensions</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Return the dimensions of the tensor as a 1D tensor.
      F(input): return input.shape
  </td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Element Count</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Size">Size</a></td>
    <td class="dmlColumn">NA, just compute the number of TENSOR_DESC elements</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Return the element count. ReduceProd(Shape(X), keepdims=0).
note: <code>Size</code> is unfortunately named, inconsistently so with <code>Resize-10</code> which accepts separate dimensions. 🙃
If you want the sizes of the tensor (N C H W) rather than just the total element count, called <code>Shape</code> instead.</td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Reshape</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Reshape">Reshape</a></td>
    <td class="dmlColumn">NA, no actual data change, just update the TENSOR_DESC</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Return tensor with a different view of the data, like a reinterpret cast using new dimensions that are element-count compatible.</td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Reshape To 2D</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Flatten">Flatten</a></td>
    <td class="dmlColumn">NA, no actual data change, just update the TENSOR_DESC</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Reinterpret the view of the tensor, reducing the dimensions from N to 2 (e.g. [1,2,3,4,5] with a split at axis 3 -&gt; [1*2*3,4*5] -&gt; [6,20]).

<code>
aggregate Flatten(input, axis)
    InputShape = Shape(input)
    ShapeFrontHalf = Slice(InputShape; ends=axis)
    ShapeBackHalf = Slice(InputShape; starts=axis)
    NewShape = Concat(axis=0, ReduceProd(ShapeFrontHalf), ReduceProd(ShapeBackHalf))
    Output = Reshape(input, NewShape)
endaggregate
</code>

<code>
function Flatten(input, axis)
    output = input
    inputShape = input.shape
    output.shape = join(reduceprod(inputShape[0..axis]), reduceprod(inputShape[axis..oldShape.size]))
    return output
endfunction</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Reshape Removing Ones</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Squeeze">Squeeze</a></td>
    <td class="dmlColumn">NA, just rearrange the TENSOR_DESC</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Reinterpret the view of the tensor, removing 1's for deletable axes.

<code>
function ReshapeDeletingOnes(input, axes)
    outputShape = input.shape
    if axes.empty
        axes = arange(0, outputShape.size)
    else // !axes.empty
        for i in axes do assert(outputShape[i] == 1)
        axes = removeDupes(sort(axes))
    endif
    axes = reverse(axes)
    for i in axes // work from back to front
        if outputShape[i] == 1
            outputShape.deleteAt(i)
        endif
    endfor
    output = input
    output.shape = outputShape
    return output
endfunction</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Reshape Inserting Ones</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Unsqueeze">Unsqueeze</a></td>
    <td class="dmlColumn">NA, just rearrange the TENSOR_DESC</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Reinterpret the view of the tensor, filling in 1's for newly inserted axes.

<code>
function ReshapeInsertingOnes(input, axes)
    output = input
    outputShape = input.shape
    axes = removeDupes(sort(axes))
    for i in axes
        outputShape.insertAt(i, 1)
    endfor
    output.shape = outputShape
    return output
endfunction</code></td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization mapping</td>
    <td>One Hot Along Axis</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#OneHot">OneHot</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_ONE_HOT</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Set all elements to 'off' values, then set one element to 'on' value along specified axis using index offset.</td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data Reorganization</td>
    <td>Top K Sorted Selection</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#TopK">TopK</a></td>
    <td class="dmlColumn">DML_OPERATOR_TOP_K</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>TopK(X, K, axis) = Slice(SortDecreasing(X, axis), starts=0, ends=K, axes=axis)</td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization selection</td>
    <td>Select elementwise ("where" is a bad name)</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Where">Where</a></td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IF</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">stablehlo.select</td>
    <td class="tosaColumn">tola.select</td>
    <td class="numpyColumn">numpy.where</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(b, x, y) = if b then x else y
      notes: A conditional per-element if statement. Can be used to implement composites that use logical operators (e.g. PRelu).
  </td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization selection</td>
    <td>Join Selected Slices</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#Compress">Compress</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>A conditional slice/join along a specific axis. Has utterly nothing to do with data compression, despite the confusing name.</td>
    <td>Exact</td>
  </tr>
  <tr class="reorganizationOperator">
    <td>Data reorganization <a href="https://github.com/onnx/onnx/pull/1882">(Reverted)</a></td>
    <td>Reverse axes</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/pull/1804">Reverse</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Reverse all the elements along the given axes.
<code>
output.shape = input.shape
for every inputCoordinate in input tensor
    // Flip the coordinate along all applicable axes
    outputCoordinate = inputCoordinate
    for each axis in axes
        outputCoordinate[axis] = input.shape[axis] - outputCoordinate[axis]
    endfor

    output[outputCoordinate] = input[inputCoordinate]
endfor
</code></td>
    <td>Exact</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Global Average Pooling</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalAveragePool">GlobalAveragePool</a></td>
    <td class="dmlColumn">DML_OPERATOR_AVERAGE_POOLING</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Average all elements in each pool. y = (x1 + x2 + … + xn) / pool_size;
So X[N C H W] reduces to Y[N C 1 1]

GlobalAveragePool(X):
InputShape = Shape(X)
SpatialDimensions = Slice(InputShape; starts=2) // skip leading N and C dimensions.
NewShape = Unsqueeze(SpatialDimensions, Const([0,1]) // Prepend with [1,1]
Output = AveragePool(X, kernel_shape=NewShape))</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Average Pooling</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#AveragePool">AveragePool</a></td>
    <td class="dmlColumn">DML_OPERATOR_AVERAGE_POOLING</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>y = (x1 + x2 + … + xn) / pool_size</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Global Maximum Pooling</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalMaxPool">GlobalMaxPool</a></td>
    <td class="dmlColumn">DML_OPERATOR_MAX_POOLING with output being 1 element</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>y = max(x1, x2, … x_pool_size)</td>
    <td>Exact</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Maximum Pooling</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxPool">MaxPool</a></td>
    <td class="dmlColumn">DML_OPERATOR_MAX_POOLING</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>y = max(x1, x2, … x_pool_size)</td>
    <td>Exact</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Maximum Unpooling</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#MaxUnpool">MaxUnpool</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Opposite of MaxPool.
Fill the output tensor of the given shape (either explicit or the input shape plus padding) with zeros.
Then write each value from the input tensor into the output tensor at the element offset from the corresponding indices array.</td>
    <td>Exact</td>
</tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Lebesgue Pooling</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LpPool">LpPool</a></td>
    <td class="dmlColumn">DML_OPERATOR_LP_POOLING</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>y = (x1^p + x2^p + ... + xn^p) ^ (1/p); y is reduced for each kernel</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Global Lebesgue Pooling</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalLpPool">GlobalLpPool</a></td>
    <td class="dmlColumn">DML_OPERATOR_LP_POOLING with output being 1 element</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>y = (x1^p + x2^p + ... + xn^p) ^ (1/p);
      So X[N C H W] reduces to Y[N C 1 1]
      e.g. (3^2 + 4^2) ^ (1/2) = 5</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="poolingOperator">
    <td>Pooling</td>
    <td>Maximum Region of Interest Pooling</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MaxRoiPool">MaxRoiPool</a></td>
    <td class="dmlColumn">DML_OPERATOR_ROI_POOLING (only POOLING_MAX is supported)</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Apply MaxPool to given input within each numbered region (batch_index, w_offset_start, h_offset_start, w_offset_last_inclusive, h_offset_last_inclusive), and write the maximal value back to the output.
questions: Are x2 and y2 really supposed to be end-inclusive? If so, how can that possibly work correctly with the spatial_scale attribute?
's broken and inconsistent with a lot of graphics API's and Python array slice start:end notation. What's the point of the pooled_shape when each region has a specific size anyway?
  </td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Sum</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceSum">ReduceSum</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_SUM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Y.shape = If(keepdims==1, Shape(X), Squeeze(X, axes))
      y = (x1 + x2 + ... + xn)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Mean</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMean">ReduceMean</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_AVERAGE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>y = (x1 + x2 + ... + xn) / n</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Product</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceProd">ReduceProd</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_MULTIPLY</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>y = (x1 * x2 * ... * xn)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Logarithm of Sum</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceLogSum">ReduceLogSum</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_LOG_SUM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Log(ReduceSum(X, axes, keepdims))
      or: y = logₑ(x1 + x2 + ... + xn)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Logarithm of Sum of Exponents</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceLogSumExp">ReduceLogSumExp</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_LOG_SUM_EXP</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Log(ReduceSum(Exp(X), axes, keepdims))
      or: y = logₑ(expₑ(x1) + expₑ(x2) + ... + expₑ(xn))
  </td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Sum of Squares</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceSumSquare">ReduceSumSquare</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_SUM_SQUARE</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = ReduceSum(Pow(X, 2), axes, keepdims)
      or: y = x1^2 + x2^2 + ... + xn^2</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Sum of Absolute Values</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceL1">ReduceL1</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_L1</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = ReduceSum(Abs(X), axes, keepdims)
      or: y = abs(x1) + abs(x2) + ... + abs(xn)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to L2 Distance</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceL2">ReduceL2</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_L2</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>F(X) = Sqrt(ReduceSum(Pow(X, 2), axes, keepdims))
  or: y = sqrt(x1^2 + x2^2 + ... + xn^2)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Maximum</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMax">ReduceMax</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_MAX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>x = max(max(max(x1, x2), x3), ..., xn)</td>
    <td>Exact</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Minimum</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ReduceMin">ReduceMin</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_MIN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>x = min(min(min(x1, x2), x3), ..., xn)</td>
    <td>Exact</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Maximum Argument</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ArgMax">ArgMax</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_ARGMAX</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>int32 {i j k ..} = maxindex(X Y Z …)</td>
    <td>Exact</td>
  </tr>
  <tr class="reductionOperator">
    <td>Reduction</td>
    <td>Reduce to Minimum Argument</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#ArgMin">ArgMin</a></td>
    <td class="dmlColumn">DML_OPERATOR_REDUCE with DML_REDUCE_FUNCTION_ARGMIN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>int32 {i j k ..} = minindex(X Y Z …)</td>
    <td>Exact</td>
  </tr>
 <tr>
    <td>Imaging Operators</td>
    <td>Resample Up</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Upsample">Upsample</a></td>
    <td class="dmlColumn">DML_OPERATOR_UPSAMPLE_2D</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Y.Shape = Floor(Shape(X) * Scales)
      Y[output_i] = X[output_i / Scales]</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="controlFlowOperator">
    <td>Control Flow</td>
    <td>If</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#If">If</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>f(cond, then_graph, else_graph, outputs...):
      subgraph = cond ? then_graph : else_graph
      outputs = subgraph(implictly_named_inputs_from_outer_graph)
  </td>
    <td>Exact</td>
  </tr>
  <tr class="controlFlowOperator">
    <td>Control Flow</td>
    <td>Loop</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Loop">Loop</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>TODO:CODE</td>
    <td>Exact</td>
  </tr>
  <tr class="controlFlowOperator">
    <td>Control Flow</td>
    <td>Scan</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Scan">Scan</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>TODO:CODE</td>
    <td>Exact</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Spatial Normalization (independent batch&channel)</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#InstanceNormalization">InstanceNormalization</a></td>
    <td class="dmlColumn">DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION1 with
    axes = [2,3,4,...] excluding (N,C).
DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION with
    acrossChannels=false
    normalizeVariance=true
    scale and bias provided</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>InstanceNormalization(X, scale, bias) = scale * (X - mean) / sqrt(Variance + epsilon) + reshape(Bias, [batch size, C axis size, spatial dims...])

Mean and variance are computed across spatial dimensions DHW, independently per batch per channel NC:

axes = [2,3, ..., inputRank-1] // Exclude axes {0,1}
mean = (x0 + x1 + …) / xn;
variance = ((x0 - xmean)^2 + (x1 - xmean)^2 + …) / xn

ONNX:
mean = ReduceAverage(axes, keepdims=true)
variance = ReduceAverage(Pow(Sub(x, mean), 2), axes, keepdims=true)

NumPy:
mean = np.mean(x, axis=axes, keepdims=True)
variance = np.var(x, axis=axes, keepdims=True)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Layer Normalization (independent leading batches)</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/main/docs/Operators.md#LayerNormalization">LayerNormalization</a></td>
    <td class="dmlColumn">DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION1 with
    axes = [firstAxis, firstAxis+1, ...].
DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION with
    acrossChannels=false
    normalizeVariance=true
    scale and bias provided</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>LayerNormalization(X, scale, bias) = scale * (X - mean) / sqrt(Variance + epsilon) + reshape(Bias, [batch size, C axis size, spatial dims...])

Mean and variance are computed across all dimensions from and after axis, independently per leading batches:

axes = [axis, axis+1, ..., inputRank-1] // Exclude axes {0, ..., axis-1}
mean = (x0 + x1 + …) / xn;
variance = ((x0 - xmean)^2 + (x1 - xmean)^2 + …) / xn

ONNX:
mean = ReduceAverage(axes, keepdims=true)
variance = ReduceAverage(Pow(Sub(x, mean), 2), axes, keepdims=true)

NumPy:
mean = np.mean(x, axis=axes, keepdims=True)
variance = np.var(x, axis=axes, keepdims=True)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Spatial&Channel Normalization</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">NA (<a href="https://arxiv.org/abs/1803.08494">alternate layer normalization</a>)</td>
    <td class="dmlColumn">DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION1 with
    axes = [1,2,3,...].</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>LayerNormalization(X, scale, bias) = scale * (X - mean) / sqrt(Variance + epsilon) + Bias

Mean and variance are computed across spatial&channel dimensions CDHW, independently per batch N:

axes = [1,2,3, ..., inputRank-1] // Exclude axes {0}
mean = (x0 + x1 + …) / xn;
variance = ((x0 - xmean)^2 + (x1 - xmean)^2 + …) / xn

ONNX:
mean = ReduceAverage(axes, keepdims=true)
variance = ReduceAverage(Pow(Sub(x, mean), 2), axes, keepdims=true)

NumPy:
mean = np.mean(x, axis=axes, keepdims=True)
variance = np.var(x, axis=axes, keepdims=True)</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Batch&Spatial Normalization (independent channel)</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#BatchNormalization">BatchNormalization</a></td>
    <td class="dmlColumn">DML_OPERATOR_BATCH_NORMALIZATION</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>BatchNormalization(X, scale, bias, mean, var, epsilon, momentum) = Scale * (X - mean) / sqrt(Variance + epsilon) + reshape(Bias, C axis)

Statistics are precomputed across batch <i>and</i> spatial dimensions NDHW (and not just the batch dimension, as the name would misleadingly lead you believe).
So each channel C is independent.
Then it's reshaped to be broadcast-compatible with the input.

axes = [0,2, ..., inputRank-1] // Exclude axes {1}, and everything except channel
mean = (x0 + x1 + …) / xn;
variance = ((x0 - xmean)^2 + (x1 - xmean)^2 + …) / xn

ONNX:
mean = ReduceAverage(axes, keepdims=true)
variance = ReduceAverage(Pow(Sub(x, mean), 2), axes, keepdims=true)

NumPy:
mean = np.var(x, axis=axes, keepdims=True)
variance = np.mean(x, axis=axes, keepdims=True)
</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Mean Variance Normalization</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#MeanVarianceNormalization">MeanVarianceNormalization</a></td>
    <td class="dmlColumn">DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION1</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>For each output element, subtract the mean, and divide by standard deviation.

MeanVarianceNormalization(X) = (X - mean) / standardDeviation
MeanVarianceNormalization(X) = (X - mean) / sqrt(variance + epsilon)
MeanVarianceNormalization(X) = (X - mean(X)) / sqrt(mean((X - mean(X))^2))
MeanVarianceNormalization(X) = (X - mean(X)) / sqrt(mean(X^2) - mean(X)^2))

ONNX:
Exponent = Const(2.0)
Epsilon = Const(1e-9)
X_RM = ReduceMean(X)
EX_squared = Pow(X_RM, Exponent)
X_squared = Pow(X, Exponent)
E_Xsquared = ReduceMean(X_squared)
Variance = Sub(E_Xsquared, EX_squared)
STD = Sqrt(Variance)
X_variance = Sub(X, X_RM)
Processed_STD = Add(STD, Epsilon)
X_MVN = Div(X_variance, Processed_STD)

NumPy:
dataMean = np.mean(inputData, axes, keepdims=1)
dataMeanSquared = np.power(dataMean, 2)
dataSquared = np.power(inputData, 2)
dataSquareMeaned = np.mean(dataSquared, axes, keepdims=1)
std = np.sqrt(dataSquareMeaned - dataMeanSquared)
output = (inputData - dataMean) / (std + 1e-9)
</td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Local Response Normalization</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LRN">LRN</a></td>
    <td class="dmlColumn">DML_OPERATOR_LOCAL_RESPONSE_NORMALIZATION</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>For each output element, sum all the corresponding inputs in a local window, considering scale, power, and bias.

LRN(x, localSize, scaleAlpha, powerBeta, bias) = x / (bias + (scaleAlpha / localSize) * sum(xi^2 for every xi in the local region)) ^ powerBeta
defaults: bias = 1

Decomposition:
Radius = LocalSize / 2
axes = if CrossChannel then {C} else {H,W}
PoolingWindowSizes = ConstructWindowSizes(axes, Rank, 1 + Radius) // dimension = 1 + Radius along axes, 1's elsewhere
Summed = PoolSum(Pow(Input, 2), axes, PoolingWindowSizes) * Alpha / LocalSize
Biased = Summed + Bias
Output = Input / Pow(Biased, Beta)
  </td>
    <td>Precision TBD</td>
  </tr>
  <tr class="normalizationOperator">
    <td>Normalization</td>
    <td>Lebesgue Length Normalization</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LpNormalization">LpNormalization</a></td>
    <td class="dmlColumn">DML_OPERATOR_LP_NORMALIZATION</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>f(x) = x / sqrt(variance(X) + epsilon)</code> TODO: verify formula
<code>aggregate F(X, p)
    // TODO: verify this. mean? variance not / n?
    X_reduced = ReduceLp(X, p, axis, keepdims=1)
    // where ReduceLP is ReduceL1 or ReduceL2 based on p
    X_reduced_broadcast = Expand(X_reduced, Shape(X))
    X_variance = Pow(X_reduced_broadcast, 2)
    Epsilon = Const(1e-9)
    Output = Div(X, Sqrt(Add(X_variance, Epsilon)))
endaggregate</code></td>
    <td>Precision TBD</td>
  </tr>
 <tr>
    <td>Sparse tensor collation</td>
    <td>Nonzero Indices List</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#NonZero">Nonzero</a></td>
    <td class="dmlColumn">DML_OPERATOR_NONZERO_COORDINATES</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Append the coordinates of every nonzero input value to a list, with coordinates stored interleaved (so not [[X1,Y1,Z1], [X2,Y2,Z2], …] but rather [[X1,X2,…], [Y1,Y1,…], [Z1,Z2,…]]).</td>
    <td>Exact</td>
  </tr>
 <tr>
    <td>NGram</td>
    <td>Term Frequency Inverse Document Frequency Vectorizer</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.4.0/docs/Operators.md#tfidfvectorizer">TfldfVectorizer</a></td>
    <td class="dmlColumn">---</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Read input front to back, incrementing output histogram for each occurrence found of desired patterns.
It's basically a word count algorithm with the output histogram size equalling the number of words in the dictionary to find.</td>
    <td>Exact</td>
  </tr>
 <tr>
    <td>Aggregate</td>
    <td>Recurrent Neural Network</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#RNN">RNN</a></td>
    <td class="dmlColumn">DML_OPERATOR_RNN</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Y = Activation(Clip(MatMul(X, Transpose(W)) + MatMul(Initial_h, Transpose(R)) + B), -clip, +clip)</td>
    <td>Precision TBD</td>
  </tr>
 <tr>
    <td>Aggregate</td>
    <td>Gated Recurrent Unit</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#GRU">GRU</a></td>
    <td class="dmlColumn">DML_OPERATOR_GRU</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Iteratively apply matrix multiplication. TODO: Need better summary.
<code>
Z = Activation1(Clip(MatMul(X, Transpose(W1)) + MatMul(Initial_h1, Transpose(R1)) + b1, -clip, +clip))
R = Activation1(Clip(MatMul(X, Transpose(W2)) + MatMul(Initial_h1, Transpose(R2)) + b2, -clip, +clip))
C = Mul(Initial_h1, R)
O = Activation2(Clip(MatMul(X, Transpose(W3)) + MatMul(Initial_h1, Transpose(R3)) + b3, -clip, +clip))
Y = Mul((1-Z), O) + Mul(Z, Initial_h1)

W = [W1, W2, W3];
b1 = B[0, :] + B[3*hidden_size, :];
b2 = B[1, :] + B[4*hidden_size, :];
b3 = B[2, :] + B[5*hidden_size, :];</code></td>
    <td>Precision TBD</td>
  </tr>
  <tr class="elementwiseOperator">
    <td>Input (Deleted)</td>
    <td>Constant Fill</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.2.1/docs/Operators.md#ConstantFill">ConstantFill</a> (see ConstantOfShape)</td>
    <td class="dmlColumn">DML_OPERATOR_ELEMENT_WISE_IDENTITY with zero strides for broadcasting</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td><code>function ConstantFill(dtype, extra_shape, input_as_shape, shape, value; inputOfDesiredShape)
    assert(!exists(shape) || !input_as_shape)
    output.dataType = dtype
    output.shape = if exists(shape) then shape else Shape(inputOfDesiredShape) + extra_shape
    for each element in output tensor
        element = value
    endfor
endfunction</code></td>
    <td>Exact</td>
  </tr>
  <tr>
    <td>Input (Deleted)</td>
    <td>Constant Fill</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.3.0/docs/Operators.md#GivenTensorFill">GivenTensorFill</a></td>
    <td class="dmlColumn">NA experimental</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>unknown</td>
    <td>Exact</td>
  </tr>
  <tr>
    <td>Aggregate (Deleted)</td>
    <td>Gated Recurrent Unit Unit</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.0/docs/Operators.md#GRUUnit">GRUUnit</a></td>
    <td class="dmlColumn">NA</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>???</td>
    <td>Precision TBD</td>
  </tr>
  <tr>
    <td>Aggregate</td>
    <td>Long Short Term Memory</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#LSTM">LSTM</a></td>
    <td class="dmlColumn">DML_OPERATOR_LSTM</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>Iteratively apply matrix multiplication. TODO: Need better summary.
<code>
I = Activation1f(Clip(MatMul(X, Transpose(W1)) + MatMul(Initial_h1, Transpose(R1)) + Mul(p, initial_c) + b1), -clip, +clip)
F = Activation1f(Clip(MatMul(X, Transpose(W2)) + MatMul(Initial_h1, Transpose(R2)) + Mul(p, initial_c) + b2), -clip, +clip)
Z = Activation2g(Clip(MatMul(X, Transpose(W3)) + MatMul(Initial_h1, Transpose(R3)) + b3), -clip, +clip)
C = Mul(Initial_h1, F) + Mul(I, Z)
O = Activation2g(clip(MatMul(X, Transpose(W4)) + MatMul(Initial_h1, Transpose(R4)) + Mul(p, initial_c) + b4))
Y = Mul(Activation3h(C), O)
&nbsp;
W = [W1, W2, W3, W4];
b1 = B[0, :] + B[4*hidden_size, :];
b2 = B[1, :] + B[5*hidden_size, :];
b3 = B[2, :] + B[6*hidden_size, :];
b4 = B[3, :] + B[7*hidden_size, :];</code></td>
    <td>Precision TBD</td>
  </tr>
  <tr>
    <td>Training</td>
    <td>Dropout</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/master/docs/Operators.md#Dropout">Dropout</a></td>
    <td class="dmlColumn">NA (can use identity, since not used during inference)</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>For each element, randomly zero it or multiply it by 1 / (1 - ratio).
<code>F(X, ratio) = Where(Less(Random(0, 0.9999), ratio), 0, Mul(X, Recip(Sub(1, ratio)))),
or f(x) = iif(random(0, 0.9999) &lt ratio, 0, 1 / (1 - ratio) * x);</code>
For forward execution, ratio is 0, and so it's equivalent to: <code>F(X) = Identity(X)</code>
notes: If probability = 1, then all zeroes. If 0, then identity. Selected randomly per element.</td>
    <td>Unpredictable</td>
  </tr>
  <tr>
    <td>Deleted / Code Execution</td>
    <td>A TENsor Kernel</td>
    <td class="webnnColumn">?</td>
    <td class="onnxColumn">ONNX <a href="https://github.com/onnx/onnx/blob/rel-1.0/docs/Operators.md#ATen">ATen</a> <i>experimental and deprecated</i></td>
    <td class="dmlColumn">NA</td>
    <td class="xnnPackColumn">?</td>
    <td class="stableHloColumn">?</td>
    <td class="tosaColumn">?</td>
    <td class="numpyColumn">?</td>
    <td class="tensorFlowColumn">?</td>
    <td class="pytorchColumn">?</td>
    <td class="coreMlColumn">?</td>
    <td class="bnnsColumn">?</td>
    <td class="mpsColumn">?</td>
    <td class="mlxColumn">?</td>
    <td class="ncnnColumn">?</td>
    <td class="cntkColumn">?</td>
    <td class="futureColumn"></td>
    <td>???</td>
    <td>Unpredictable</td>
  </tr>
</table>

</body>
</html>

<!--

TODO: Add these

## ConvInteger

https://github.com/onnx/onnx/pull/1908

## MatMulInteger

https://github.com/onnx/onnx/pull/1908

## QLinearConv

https://github.com/onnx/onnx/pull/1908
## QLinearMatMul

https://github.com/onnx/onnx/pull/1908

## NonMaxSuppression

https://github.com/onnx/onnx/pull/1703
https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression  
tf.image.non_max_suppression
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/non_max_suppression_op.cc

## StringNormalizer

https://github.com/onnx/onnx/pull/1745  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#StringNormalizer

## Resize (Resample=Upsample+Downsample)

https://github.com/onnx/onnx/pull/1773

Resample elements from the source to destination tensor, using the scale factors to compute the destination tensor size. Can use linear or nearest neighbor. Supports interpolation across multiple dimensions, not just 2D. So one can keep the same spatial size but interpolate across channels or across batches.

    samplesToInterpolate = 1 << rank
    samples.resize(samplesToInterpolate)

    for every outputCoordinate in output tensor
        // Offset the fractional component by the pixel center offsets.
        inputCoordinateFloat = (outputCoordinate + outputPixelOrigin) / scales
        inputCoordinateFractions = frac(inputCoordinateFloat) - inputPixelOrigin
        inputCoordinate = floor(inputCoordinateFloat)

        // If the lerp value is negative, adjust to lower pixel.
        inputCoordinate += where(inputCoordinateFractions < 0, -ones(rank), zeroes(rank))
        inputCoordinateFractions += where(inputCoordinateFractions < 0, ones(rank), zeroes(rank))

        // Read the surrounding samples from around the interpolated point.
        for sampleIndex = 0..<samplesToInterpolate
            inputCoordinate = clamp(SampleIndexToCoordinate(sampleIndex), zeroes(rank), input.shape - ones(rank))
            samples[sampleIndex] = input[inputCoordinate];
        endfor

        // Intepolate all pixels
        samplesLeftToInterpolate = samplesToInterpolate
        for axis = 0..<rank
            samplesLeftToInterpolate >>= 1
            for sampleIndex = 0..<samplesLeftToInterpolate
                samples[sampleIndex] = lerp(samples[sampleIndex], samples[sampleIndex + samplesLeftToInterpolate], inputCoordinateFractions[sampleIndex])
            endfor
        endfor

        output[outputCoordinate] = samples[0]
    endfor

## ThresholdedRelu (already supported)

https://github.com/onnx/onnx/pull/1856

    f(x) = if x > alpha then x else 0

## BitShift left/right elemntwise shift

https://github.com/onnx/onnx/pull/1931  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#BitShift

    2 << 3 = 8
    8 >> 3 = 2

    // transparently apply broadcasting...
    for each coordinate in output tensor
        if direction == "LEFT"
            output[coordinate] = X[coordinate] << Y[coordinate]
        else if direction == "RIGHT"
            output[coordinate] = X[coordinate] >> Y[coordinate]
        endif
        // else error
    endif

## CumSum cumulative summation

https://github.com/onnx/onnx/pull/2030  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#CumSum
tf.math.cumsum
https://www.tensorflow.org/api_docs/python/tf/math/cumsum

Tally the cumulative summation along a given axis.
output size = input size  
can proceed along any axis.  

    cumsum([a, b, c])  -> [a, a + b, a + b + c]
    cumsum([a, b, c], reverse=true)  -> [a + b + c, b + c, c]
    cumsum([a, b, c], exclusive=true)  -> [0, a, a + b]

    x = [[0,1,3],
         [2,3,5]]
    axis = 0
    exclusive = false
    reverse = false // so go down along y axis
    output = [[0, 1, 3],
              [2, 4, 8]]

Pseudocode:

    int numberOfElementsAlongAxis = input.dimensions[axis]
    int numberOfSlivers = ElementCount(input) / numberOfElementsAlongAxis

    for i = 0..<numberOfSlivers
        int tally = 0
        auto coordinates = ComputeCoordinates(input.dimensions, i, axis)

        for j = 0..<numberOfElementsAlongAxis
            coordinates[axis] = if reverse then numberOfElementsAlongAxis - j else j

            inputValue = input[coordinates]
            if !exclusive
                tally += input[coordinates]
            endif
            output[coordinates] = tally
            if exclusive
                tally += input[coordinates]
            endif
        endfor
    endfor

## Det determinant

https://github.com/onnx/onnx/pull/2233  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#Det

Once factored into upper and lower diagonal matrices, or into "row echelon form" with all the lower diagonal being zeroes, the determinant is the product of all values along the diagonal.

## DynamicQuantizeLinear

https://github.com/onnx/onnx/pull/2187  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#DynamicQuantizeLinear

Compute the minimum and maximum element in the input. Then apply QuantizeLinear, rounding halves to nearest evens.

    xmax = max(ReduceMax(X), 0)
    xmin = min(ReduceMin(X), 0)
    y_scale = (xmax - xmin) / (qmax - qmin) // qmax - qmin is just 255 for uint8
    intermediate_zero_point = (qmin - min(x)) / (qmax - qmin)
    y_zero_point = cast(round(saturate(itermediate_zero_point)))

    for i = 0..<numberOfElements
        output[i] = saturate(roundNearestEvens(input[i] / y_scale) + y_zero_point)
    endfor

## GatherElements

https://github.com/onnx/onnx/pull/2143  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherElements

## GatherND

https://github.com/onnx/onnx/pull/2106  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#GatherND

## Range

https://github.com/onnx/onnx/pull/2242  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#Range

Generate a 1D increasing/decreasing sequence of numbers.

``` c
    numberOfElements = max(ceil((limit - start) / delta ), 0)
    output.shape = [numberOfElements]

    for i = 0..<numberOfElements
        output[i] = start + (i * delta);
    endfor
```

Example 1 Inputs: `start = 3, limit = 9, delta = 3 Output: [3, 6]`  
Example 2 Inputs: `start = 10, limit = 4, delta = -2 Output: [10, 8, 6]`

## Round

https://github.com/onnx/onnx/pull/2053  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#Round

For every element, round halves to nearest even.

``` c
    for i = 0..<numberOfElements
        output[i] = roundNearestEven(input[i]);
    endfor
```

## ScatterElements

https://github.com/onnx/onnx/pull/2143  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#ScatterElements

## ScatterND

https://github.com/onnx/onnx/pull/2220  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#ScatterND

## Unique

https://github.com/onnx/onnx/pull/2141  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#Unique

## ConcatFromSequence

https://github.com/onnx/onnx/pull/2249  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConcatFromSequence

## SequenceAt

https://github.com/onnx/onnx/pull/2249  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceAt

## SequenceConstruct

https://github.com/onnx/onnx/pull/2249  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceConstruct

## SequenceEmpty

https://github.com/onnx/onnx/pull/2249  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceEmpty

## SequenceErase

https://github.com/onnx/onnx/pull/2249  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceErase

## SequenceInsert

https://github.com/onnx/onnx/pull/2249  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceInsert

## SequenceLength

https://github.com/onnx/onnx/pull/2249  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SequenceLength

## SplitToSequence

https://github.com/onnx/onnx/pull/2249  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#SplitToSequence

## Resize (with interpolation model)

https://github.com/onnx/onnx/pull/2057

## ReverseSequence

https://github.com/onnx/onnx/pull/1927


Gaussian Error Linear Units (GELUs)

https://arxiv.org/abs/1606.08415 GELU = 0.5*x*(1 + tanh[2/π(x + 0.044715 * x^3)])

https://github.com/huggingface/pytorch-openai-transformer-lm/blob/master/model_pytorch.py#L14-L15 def gelu(x):     return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))

https://github.com/microsoft/onnxruntime/pull/2293/files
    const T x = input[idx];
    const T in = (bias == nullptr) ? x : (x + bias[idx % bias_length]);
    const T cdf = a + a * Tanh(in * (c * in * in + b));
    output[idx] = in * cdf;

https://github.com/apache/incubator-mxnet/pull/14449/files

    const float GELU_CUBIC_CONSTANT = 0.044715;
    const float GELU_ROOT_2_OVER_PI = 0.7978845608028654;

    return 0.5 * x * f(x)
    f: return 1.0 + mx.nd.tanh(g(x))
    g: return ROOT_TWO_OVER_PI * (x + CUBE_CONSTANT * x * x * x)

## Mod

https://github.com/onnx/onnx/pull/1874  
https://github.com/onnx/onnx/blob/master/docs/Operators.md#Mod  
https://docs.scipy.org/doc/numpy/reference/generated/numpy.mod.html  
https://docs.scipy.org/doc/numpy/reference/generated/numpy.fmod.html  

numpy.fmod / numpy.mod

The 'fmod' attribute selects between Python vs C signs, which when set really means (a) truncate division toward zero (b) result's sign follows dividend.
Note HLSL says "The % operator is defined only in cases where either both sides are positive or both sides are negative", and so it's likely unsuitable to implement this operator. https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-operators

``` c
    // The C++11 specification says a % b always resolves to the sign of a:
    //
    //  x = [8,  8, -8, -8]
    //  y = [3, -3,  3, -3]
    //  z = [2,  2, -2, -2] -- C fmod(), C %, or numpy.fmod())
    //
    // In Python, a % b (assuming non-zero) has the same sign as b:
    //
    //  x = [8,  8, -8, -8]
    //  y = [3, -3,  3, -3]
    //  z = [2, -1,  1, -2] -- Python % or numpy.mod
    //
    Mod(x, y, fmod) = if fmod == 1 then return x - (y * TruncateTowardZero(x / y)) // like C
                                   else return x - (y * Floor(x / y)) // like Python
```

Also add:

NCNN - https://github.com/Tencent/ncnn/blob/54a9a563e9913d3142782dac0e497f2be50075b5/docs/developer-guide/operators.md
StableHLO - https://github.com/openxla/stablehlo/blob/main/docs/spec.md
TOSA - https://mlir.llvm.org/docs/Dialects/TOSA/#tosaselect-mlirtosaselectop
CoreML - https://apple.github.io/coremltools/mlmodel/Format/NeuralNetwork.html


From https://apple.github.io/coremltools/mlmodel/Format/NeuralNetwork.html:

        ConvolutionLayerParams convolution = 100;

        PoolingLayerParams pooling = 120;

        ActivationParams activation = 130;

        InnerProductLayerParams innerProduct = 140;
        EmbeddingLayerParams embedding = 150;

        // Normalization-related Layers
        BatchnormLayerParams batchnorm = 160;
        MeanVarianceNormalizeLayerParams mvn = 165;
        L2NormalizeLayerParams l2normalize = 170;
        SoftmaxLayerParams softmax = 175;
        LRNLayerParams lrn = 180;

        CropLayerParams crop = 190;
        PaddingLayerParams padding = 200;
        UpsampleLayerParams upsample = 210;

        ResizeBilinearLayerParams resizeBilinear = 211;
        CropResizeLayerParams cropResize = 212;

        UnaryFunctionLayerParams unary = 220;

        // Element-wise Operations
        AddLayerParams add = 230;
        MultiplyLayerParams multiply = 231;

        AverageLayerParams average = 240;
        ScaleLayerParams scale = 245;

        BiasLayerParams bias = 250;
        MaxLayerParams max = 260;
        MinLayerParams min = 261;

        DotProductLayerParams dot = 270;
        ReduceLayerParams reduce = 280;
        LoadConstantLayerParams loadConstant = 290;

        // Data Reorganization
        ReshapeLayerParams reshape = 300;
        FlattenLayerParams flatten = 301;
        PermuteLayerParams permute = 310;
        ConcatLayerParams concat = 320;
        SplitLayerParams split = 330;
        SequenceRepeatLayerParams sequenceRepeat = 340;

        ReorganizeDataLayerParams reorganizeData = 345;
        SliceLayerParams slice = 350;

        // Recurrent Layers
        SimpleRecurrentLayerParams simpleRecurrent = 400;
        GRULayerParams gru = 410;
        UniDirectionalLSTMLayerParams uniDirectionalLSTM = 420;
        BiDirectionalLSTMLayerParams biDirectionalLSTM = 430;

        // Custom (user-implemented) Layer
        CustomLayerParams custom = 500;

        // Following layers are available only after Core ML Specification
        // version >= 4 (iOS >= 13, macOS >= 10.15)

        // Control Flow related Layers
        CopyLayerParams copy = 600;
        BranchLayerParams branch = 605;

        LoopLayerParams loop = 615;
        LoopBreakLayerParams loopBreak = 620;
        LoopContinueLayerParams loopContinue = 625;

        RangeStaticLayerParams rangeStatic = 635;
        RangeDynamicLayerParams rangeDynamic = 640;

        // Element-wise Unary Layers
        ClipLayerParams clip = 660;
        CeilLayerParams ceil = 665;
        FloorLayerParams floor = 670;

        SignLayerParams sign = 680;
        RoundLayerParams round = 685;

        Exp2LayerParams exp2 = 700;

        SinLayerParams sin = 710;
        CosLayerParams cos = 715;
        TanLayerParams tan = 720;

        AsinLayerParams asin = 730;
        AcosLayerParams acos = 735;
        AtanLayerParams atan = 740;

        SinhLayerParams sinh = 750;
        CoshLayerParams cosh = 755;
        TanhLayerParams tanh = 760;

        AsinhLayerParams asinh = 770;
        AcoshLayerParams acosh = 775;
        AtanhLayerParams atanh = 780;

        ErfLayerParams erf = 790;
        GeluLayerParams gelu = 795;

        // Element-wise Binary with Broadcasting Support
        EqualLayerParams equal = 815;
        NotEqualLayerParams notEqual = 820;
        LessThanLayerParams lessThan = 825;
        LessEqualLayerParams lessEqual = 827;
        GreaterThanLayerParams greaterThan = 830;
        GreaterEqualLayerParams greaterEqual = 832;

        LogicalOrLayerParams logicalOr = 840;
        LogicalXorLayerParams logicalXor = 845;
        LogicalNotLayerParams logicalNot = 850;
        LogicalAndLayerParams logicalAnd = 855;

        ModBroadcastableLayerParams modBroadcastable = 865;
        MinBroadcastableLayerParams minBroadcastable = 870;
        MaxBroadcastableLayerParams maxBroadcastable = 875;
        AddBroadcastableLayerParams addBroadcastable = 880;
        PowBroadcastableLayerParams powBroadcastable = 885;
        DivideBroadcastableLayerParams divideBroadcastable = 890;
        FloorDivBroadcastableLayerParams floorDivBroadcastable = 895;
        MultiplyBroadcastableLayerParams multiplyBroadcastable = 900;
        SubtractBroadcastableLayerParams subtractBroadcastable = 905;

        // Tensor Manipulations
        TileLayerParams tile = 920;
        StackLayerParams stack = 925;
        GatherLayerParams gather = 930;
        ScatterLayerParams scatter = 935;
        GatherNDLayerParams gatherND = 940;
        ScatterNDLayerParams scatterND = 945;
        SoftmaxNDLayerParams softmaxND = 950;
        GatherAlongAxisLayerParams gatherAlongAxis = 952;
        ScatterAlongAxisLayerParams scatterAlongAxis = 954;

        ReverseLayerParams reverse = 960;
        ReverseSeqLayerParams reverseSeq = 965;

        SplitNDLayerParams splitND = 975;
        ConcatNDLayerParams concatND = 980;
        TransposeLayerParams transpose = 985;

        SliceStaticLayerParams sliceStatic = 995;
        SliceDynamicLayerParams sliceDynamic = 1000;
        SlidingWindowsLayerParams slidingWindows = 1005;

        TopKLayerParams topK = 1015;
        ArgMinLayerParams argMin = 1020;
        ArgMaxLayerParams argMax = 1025;

        EmbeddingNDLayerParams embeddingND = 1040;
        BatchedMatMulLayerParams batchedMatmul = 1045;

        // Tensor Allocation / Reshape-related Operations
        GetShapeLayerParams getShape = 1065;
        LoadConstantNDLayerParams loadConstantND = 1070;

        FillLikeLayerParams fillLike = 1080;
        FillStaticLayerParams fillStatic = 1085;
        FillDynamicLayerParams fillDynamic = 1090;

        BroadcastToLikeLayerParams broadcastToLike = 1100;
        BroadcastToStaticLayerParams broadcastToStatic = 1105;
        BroadcastToDynamicLayerParams broadcastToDynamic = 1110;

        SqueezeLayerParams squeeze = 1120;
        ExpandDimsLayerParams expandDims = 1125;
        FlattenTo2DLayerParams flattenTo2D = 1130;
        ReshapeLikeLayerParams reshapeLike = 1135;
        ReshapeStaticLayerParams reshapeStatic = 1140;
        ReshapeDynamicLayerParams reshapeDynamic = 1145;
        RankPreservingReshapeLayerParams rankPreservingReshape = 1150;

        ConstantPaddingLayerParams constantPad = 1155;

        // Random Distributions
        RandomNormalLikeLayerParams randomNormalLike = 1170;
        RandomNormalStaticLayerParams randomNormalStatic = 1175;
        RandomNormalDynamicLayerParams randomNormalDynamic = 1180;

        RandomUniformLikeLayerParams randomUniformLike = 1190;
        RandomUniformStaticLayerParams randomUniformStatic = 1195;
        RandomUniformDynamicLayerParams randomUniformDynamic = 1200;

        RandomBernoulliLikeLayerParams randomBernoulliLike = 1210;
        RandomBernoulliStaticLayerParams randomBernoulliStatic = 1215;
        RandomBernoulliDynamicLayerParams randomBernoulliDynamic = 1220;

        CategoricalDistributionLayerParams categoricalDistribution = 1230;

        // Reduction-related Layers:
        ReduceL1LayerParams reduceL1 = 1250;
        ReduceL2LayerParams reduceL2 = 1255;
        ReduceMaxLayerParams reduceMax = 1260;
        ReduceMinLayerParams reduceMin = 1265;
        ReduceSumLayerParams reduceSum = 1270;
        ReduceProdLayerParams reduceProd = 1275;
        ReduceMeanLayerParams reduceMean = 1280;
        ReduceLogSumLayerParams reduceLogSum = 1285;
        ReduceSumSquareLayerParams reduceSumSquare = 1290;
        ReduceLogSumExpLayerParams reduceLogSumExp = 1295;

        // Masking / Selection Layers
        WhereNonZeroLayerParams whereNonZero = 1313;
        MatrixBandPartLayerParams matrixBandPart = 1315;
        LowerTriangularLayerParams lowerTriangular = 1320;
        UpperTriangularLayerParams upperTriangular = 1325;
        WhereBroadcastableLayerParams whereBroadcastable = 1330;

        // Normalization Layers
        LayerNormalizationLayerParams layerNormalization = 1350;

        NonMaximumSuppressionLayerParams NonMaximumSuppression = 1400;

        // Following layers are available only after Core ML Specification
        // version >= 5 (iOS >= 14, macOS >= 10.16)
        OneHotLayerParams oneHot = 1450;
        CumSumLayerParams cumSum = 1455;
        ClampedReLULayerParams clampedReLU = 1460;
        ArgSortLayerParams argSort = 1461;
        Pooling3DLayerParams pooling3d = 1465;
        GlobalPooling3DLayerParams globalPooling3d = 1466;
        SliceBySizeLayerParams sliceBySize = 1470;
        Convolution3DLayerParams convolution3d = 1471;


https://github.com/Tencent/ncnn/blob/54a9a563e9913d3142782dac0e497f2be50075b5/docs/developer-guide/operators.md

AbsVal
ArgMax
BatchNorm
Bias
BinaryOp
BNLL
Cast
CELU
Clip
Concat
Convolution
Convolution1D
Convolution3D
ConvolutionDepthWise
ConvolutionDepthWise1D
ConvolutionDepthWise3D
CopyTo
Crop
CumulativeSum
Deconvolution
Deconvolution1D
Deconvolution3D
DeconvolutionDepthWise
DeconvolutionDepthWise1D
DeconvolutionDepthWise3D
DeformableConv2D
Dequantize
Diag
Dropout
Eltwise
ELU
Exp
Flatten
GELU
GLU
Gemm
GridSample
GroupNorm
GRU
HardSigmoid
HardSwish
InnerProduct
Input
InstanceNorm
Interp
LayerNorm
Log
LRN
LSTM
MemoryData
Mish
MultiHeadAttention
MVN
Noop
Normalize
Packing
Padding
Permute
PixelShuffle
Pooling
Pooling1D
Pooling3D
Power
PReLU
Quantize
Reduction
ReLU
Reorg
Requantize
Reshape
RNN
Scale
SELU
Shrink
ShuffleChannel
Sigmoid
Slice
Softmax
Softplus
Split
Swish
TanH
Threshold
Tile
UnaryOp


https://microsoft.github.io/CNTK-R/reference/index.html

All functions	
activation_identity	Identity Function For CNTK Operations
Activation	Activation Layer
all_devices	All Devices
arraymixin_as_array	ArrayMixin As Array
ArrayMixin	Array Mixin
arrayview_from_data	ArrayView From Data
arrayview_from_dense	ArrayView From Dense Data
arrayview_slice_view	ArrayView Slice View
as_block	As Block
as_composite	As Composite
asvalue	Value Form Matrix
AttentionModel	Attention Model
AveragePooling	Average Pooling Layer
Base64ImageDeserializer	Base64ImageDeserializer
BatchNormalization	BatchNormalization
block_momentum_distributed_learner	Block Momentum Distributed Learner
CheckpointConfig	New Checkpoint Config
classification_error	Classification Error Between Target and Predicted
CloneMethod	CloneMethod
CNTKAxis	CNTKAxis
CNTKCrosstalk	CNTK Implementation for Crosstalk
comm_barrier	Communicator Barrier
comm_current_worker	Communicator Current Worker
comm_finalize	Communicator Finalize
comm_is_main	Communicator Is On Main Node
comm_num_workers	Number of Communicator Nodes
comm_rank	Communicator Rank
comm_workers	Communicator Workers
Communicator	New Communicator
Constant	Constant
Conv2DArgs	Convolution2D Arguments
Conv2DAttr	Conv2D Variable Attribute
Convolution	Convolution
Convolution1D	Convolution1D
Convolution2D	Two Dimensional Convolutional Layer
Convolution3D	Convolution3D
ConvolutionTranspose	ConvolutionTranspose
ConvolutionTranspose1D	ConvolutionTranspose1D
ConvolutionTranspose2D	ConvolutionTranspose2D
ConvolutionTranspose3D	ConvolutionTranspose3D
cpu_descriptor	CPU Descriptor
create_new_leading_axis	Create New Leading Axis
Crosstalk	Crosstalk Base Class
CrossValidationConfig	New Cross Validation Configuration
ct_assign	Assign Crosstalk Value
ct_compare	Compare Crosstalk Var
ct_fetch	Fetch Crosstalk Var
ct_is_param	CNTKCrosstalk Var is Parameter
ct_load_all_params	Load All CNTKCrosstalk Params From Files
ct_load_raw_value	Load Crosstalk Raw Value
ct_load	Load Crosstalk Vars
ct_next_pass	Next Crosstalk Pass
ct_register_funcs	Register Crosstalk Var Type Getter/Setters
ct_reset	Reset Crosstalk Vars
ct_save_all_params	Save All CNTKCrosstalk Params to Files
ct_save_all	Save All Crosstalk Vars
ct_save	Save Crosstalk Vars
ct_set_data	Set CNTKCrosstalk Mapped Data
ct_set_workdir	Set Crosstalk Working Directory
ct_watch	Watch Crosstalk Variable
CTFDeserializer	CTFDeserializer
data_parallel_distributed_learner	New Data Parallel Distributed Learner
debug_model	Debug Model
default_options_for	Default Options For
default_options	Default Options
default_override_or	Default Override Or
default_sample_dir	Default Sample Dir
default_sample_url	Default Sample URL
Delay	Delay
Dense	Dense
DeviceDescriptor	Create Device Descriptor
DeviceKind	Create Device Kind
disable_profiler	Disable Profiler
DistributedLearner	Distributed Learner
Dropout	Dropout
dump_function	Dump Function
dump_signature	Dump Signature
edit_distance_error	Edit Distance Error
EmbedAttr	EmbedAttr
Embedding	Embedding
enable_profiler	Enable Profiler
eval_test_minibatch	Test Evaluator Minibatch
Evaluator	Evaluator
find_func_param	Find Parameter in Function - CNTKCrosstalk
Fold	Fold
For	CNTK Function For Loop Construct
ForwardDeclaration	ForwardDeclaration
func_backward	Propogate Function Backward
func_clone	Clone Function
func_eval	Evaluate Function
func_find_all_with_name	Find All Functions With Name
func_find_by_name	Find Function By Name
func_forward	Compute Function Forward
func_grad	Compute Function Gradient
func_load	Load Function Model
func_replace_placeholder	Replace Function Placeholder
func_replace_placeholders	Replace Function Placeholders
func_restore	Restore Function
func_save	Save Function
func_set_attribute	Set Function Attribute
func_test	Test Function Model
func_train	Train Function Model
FuncInfo	Variable Setter/Getter Functions
Function	CNTK Function
get_all_axes	Get All Axes
get_all_static_axes	Get All Static Axes
get_communicator	Get Distributed Communicator
get_default_batch_axis	Get Default Batch Axis
get_default_dynamic_axis	Get Default Dynamic Axis
get_default_override	Get Default Override
get_global_option	Get Global Option
get_gpu_properties	Get GPU Properties
get_learning_rate	Get Learner Learning Rate
get_logging_trace_level	Get Logging Trace Level
get_minibatch_checkpoint_state	Get Minibatch Checkpoint State
get_static_axis_index	Get Static Axis Index
GlobalAveragePooling	GlobalAveragePooling
GlobalMaxPooling	GlobalMaxPooling
graph_depth_first_search	Graph - Depth First Search
graph_find_all_with_name	Graph - Find All With Name
graph_find_by_name	Graph - Find By Name
GRU	GRU
HTKFeatureDeserializer	HTKFeatureDeserializer
HTKMLFDeserializer	Base64ImageDeserializer
ImageDeserializer	ImageDeserializer
init_bilinear	Bilinear Initializer
init_glorot_normal	Glorot Normal Initializer
init_glorot_uniform	Glorot Uniform Initializer
init_he_normal	He Normal Initializer
init_he_uniform	He Uniform Initializer
init_normal	Normal Initializer
init_truncated_normal	Truncated Normal Initializer
init_uniform	Uniform Initializer
init_with_rank	Initializer With Rank
init_xavier	Xavier Initializer
install_samples	Install Samples
IO_INFINITELY_REPEAT	IO_INFINITELY_REPEAT
is_default_override	Is Default Override
Label	Label
LayerNormalization	LayerNormalization
learner_momentum_sgd	Creates a Momentum SGD learner instance to learn the parameters.
Learner	Learner
log_number_of_parameters	Log Number of Parameters
loss_binary_cross_entropy	Binary Cross Entropy Loss
loss_cosine_distance_negative_samples	Cosine Distance NEgative Samples Loss
loss_cosine_distance	Cosine Distance Loss
loss_cross_entropy_with_softmax	Cross Entropy Loss with Softmax for Multiclass Classification
loss_lambda_rank	Lambda Rank Loss
loss_squared_error	Squared Error Loss
loss_weighted_binary_cross_entropy	Weighted Binary Cross Entropy Loss
LSTM	LSTM
MaxPooling	Max-Pooling Layer Factory
mb_as_sequences	Minibatch Data As Sequences
mb_stream_info	Minibatch Stream Info
mb_stream_infos	Minibatch Stream Infos
MinibatchData	MinibatchData
MinibatchSource	Minibatch Source
MinibatchSourceFromData	MinibatchSourceFromData
module_is_unreleased	Module Is Unreleased
mpi_communicator	New MPI Communicator
native_user_function	Create Native UserFunction
NDArrayView	Create an NDArrayView Instance
ndcg_at_1	NDCG at 1
next_minibatch	Next Minibatch
on_train_cross_validation_end	On Training Cross Validation End
op_abs	Absolute Value
op_alias	Alias
op_argmax	Argmax Across Axis
op_argmin	Argmin Across Axis
op_assign	Assign
op_associative_multi_arg	Associative Multi-Arg
op_batch_normalization	Batch Normalization
op_ceil	Ceiling
op_clip	Clip
op_combine	Combine
op_constant	It creates a constant tensor initialized from a numpy array
op_convolution_transpose	Convolution Transpose
op_convolution	Convolution
op_cos	Element-wise Cosine
op_dim_mean_variance_normalize	Per-dimension Mean-variance Normalization
op_dropout	Dropout
op_element_divide	Element-wise Division
op_element_max	Element Max
op_element_min	Element Min
op_element_select	Element Select
op_element_times	Element Times
op_elu	Elu
op_equal	Equal Comparison
op_exp	Element-wise Exponential
op_floor	Floor
op_forward_backward	Forward-Backward
op_gather	Gather
op_greater_equal	Element-wise Greater Equal Comparison
op_greater	Element-wise Greater Comparison
op_hardmax	Hardmax
op_input_variable	Create input for network
op_labels_to_graph	Labels To Graph
op_leaky_relu	Leaky Relu
op_less_equal	Element-wise Less Equal Comparison
op_less	Element-wise Less Comparison
op_log_add_exp	Log Add Exp
op_log	Element-wise Natural Log
op_minus	Minus
op_negate	Element-wise Negation
op_not_equal	Element-wise Not Equal Comparison
op_one_hot	Create One-Hot Encoding
op_optimized_rnnstack	Optimized RNN Stack
op_output_variable	Output Variable
op_param_relu	Parametric ReLU
op_parameter	Parameter
op_placeholder	Placeholder
op_plus	Addition of Two Tensors
op_pooling	Pooling
op_pow	Power Computation
op_random_sample_inclusion_frequency	Random Sample Inclusion Frequency
op_random_sample	Random Sample
op_reciprocal	Element-wise Reciprocal
op_reconcile_dynamic_axes	Reconcile Dynamic Axes
op_reduce_log_sum_exp	Reduce Max Across Axis
op_reduce_max	Reduce Max Across Axis
op_reduce_mean	Reduce Mean Across Axis
op_reduce_min	Reduce Minimum Across Axis
op_reduce_prod	Reduce Prod Across Axis
op_reduce_sum	Reduce Sum Across Axis
op_relu	Rectified Linear Units Operation
op_reshape	Reshape
op_roipooling	Region of Interest Pooling
op_round	Element-wise Rounding
op_sigmoid	Element-wise Sigmoid
op_sin	Element-wise Sine
op_slice	Slice
op_softmax	Softmax
op_softplus	Softplus
op_splice	Concatenate Across Axis
op_sqrt	Element-wise Square-root
op_square	Element-wise Square
op_stop_gradient	Stop Gradient
op_swap_axes	Swap Axes
op_tanh	Hyperbolic tan
op_times_transpose	One Element Times Another Transposed Element
op_times	Matrix Product
op_to_sequence_like	To Sequence Like
op_to_sequence	To Sequence
op_transpose	Transpose
op_unpooling	Unpooling
Parameter	Parameter
PastValueWindow	Past Value Window
printer_end_progress_print	Printer - End Progress Pring
printer_log	Printer - Log
printer_on_training_update_end	Printer - On Training Update End
printer_on_write_distributed_sync_update	Printer - On Write Distributed Sync Update
printer_on_write_test_summary	Printer - On Write Test Summary
printer_on_write_test_update	any writer
printer_on_write_training_summary	Printer - On Write Training Summary
printer_on_write_training_update	Printer - Training Update on Write
printer_write	Printer - Write
ProgressPrinter	Create Progress Printer
rand_bernoulli_like	Random Bernoulli Like
rand_bernoulli	Random Bernoulli Distribution
rand_gumbel_like	Random Gumbel Like Distribution
rand_gumbel	Random Gumbel Distribution
rand_normal_like	Random Normal Like Distribution
rand_normal	Random Normal Distribution
rand_uniform_like	Random Uniform Like Distribution
rand_uniform	Random Uniform Distribution
Record	Record
Recurrence	Recurrence
RecurrenceFrom	Recurrence From
register_native_user_function	Register Native UserFunction
register_udf_deserialize_callback	Register UDF Deserialize Callback
reset_learning_rate	Reset Learner Learning Rate
ResNetBlock	ResNet Block
restore_mb_from_checkpoint	Restore Minibatch From Checkpoint
restore_trainer_from_checkpoint	Restore Trainer From Checkpoint
RnnArgs	RNN Variable Arguments
RnnAttr	RNN Variable Attributes
RRNStep	RNNStep
save_as_legacy_model	Save As Legacy Model
save_trainer_checkpoint	Save Trainer Checkpoint
seq_broadcast_as	Broadcast Sequence As
seq_delay	Delay Sequence
seq_first	First Element of Sequence
seq_future_value	Sequence Future Value
seq_gather	Sequence Gather
seq_input_variable	Sequence Network Input Variable
seq_is_first	Sequence Is First
seq_is_last	Sequence Is Last
seq_last	Get Last Sequence Element
seq_past_value	Get Past Sequence Value
seq_reduce_max	Reduce Sequence Max
seq_reduce_sum	Reduce Sequence Element Sum
seq_scatter	Sequence Scatter
seq_slice	Sequence Slice
seq_softmax	Sequence Softmax
seq_unpack	Sequence Unpack
seq_where	Sequence Where
sequence_to_cntk_text_format	Convert Sequence to CNTK Text Format
Sequential	Sequential Higher-Order Wrapper for Layer Definitions
SequentialClique	Sequential Clique
sess_minibatch_size_schedule	Create a Minibatch Size Schedule
sess_training_session	Create Training Session Object
set_checked_mode	Set Checked Mode
set_computation_network_trace_level	Set Computation Network Trace Level
set_excluded_devices	Set Excluded Devices
set_global_option	Set Global Option
set_logging_trace_level	Set Logging Trace Level
Stabilizer	Stabilizer
start_profiler	Start Profiler
stop_profiler	Stop Profiler
StreamConfiguration	Stream Configuration
StreamDef	StreamDef
StreamDefs	StreamDefs
StreamInformation	StreamInformation
summarize_test_progress	Summarize Evaluator Test Progress
summarize_training_progress	Summarize Training Progress
tensorboard_close	Close Tensorboard
tensorboard_flush	Flush Tensorboard
tensorboard_write_value	TensorBoard Write Value
TensorBoardProgressWriter	New TensorBoard Progress Writer
TensorOpsMixin	TensorOpsMixin
test_minibatch	Test Minibatch
TestConfig	New Test Configuration
TraceLevel	Trace Level
train_minibatch	Train Minibatch
train_on_session	Train On TrainingSession
Trainer	Trainer
TrainingSession	New Training Configuration
TrainingSummaryProgressCallback	Training Summary Progress Callback
transform_color	Color Transform
transform_crop	Crop Transform
transform_mean	Mean Transform
transform_scale	Scale Transform
try_set_default_device	Try Set Default Device
UnfoldFrom	Unfold From
unknown_dynamic_axes	Unknown Dynamic Axes
UntestedBranchError	Untested Branch Error
updated_record_with	Updated Record With
use_default_device	Use Default Device
user_function	User Defined Function
userfunc_clone	Clone UserFunction
userfunc_deserialize	Deserialize UserFunction
userfunc_infer_outputs	Infer Outputs of UserFunction
userfunc_serialize	Serialize UserFunction
UserFunction	User Function
UserLearner	UserLearner
usermb_next_minibatch	UserMinibatch Next Minibatch
UserMinibatchSource	UserMinibatchSource
value_as_matrix	Value As Matrix
value_as_sequences	Get Value As Sequence of Matrices
value_create	Create a Value Object
value_one_hot	Value as One Hot
Value	New Value Instance
Variable	Variable
VariableMixin	Variable Mixin
VarInfo	Variable Information
visualize_network	Visualize Network Architecture
WorkerDescriptor	New Distributed Worker Descriptor

-->
